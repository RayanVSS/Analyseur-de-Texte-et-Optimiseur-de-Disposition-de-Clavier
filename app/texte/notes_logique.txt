                    INTRODUCTION À LA LOGIQUE INFORMATIQUE



                                            SYLVAIN SCHMITZ

                                        Université de Paris, France



                                           Contenu des notes
    Ce cours fournit une introduction à la logique informatique. L’accent est mis sur l’utilisation
de la logique pour modéliser des problèmes, et les résoudre ensuite à l’aide de solveurs comme
les solveurs SAT et les solveurs SMT, dont on voit aussi les principes de fonctionnement. Le cours
revisite la logique propositionnelle vue en cours d’« outils logiques » (OL4), et introduit la logique
du premier ordre. Le programme général est :
        — Logique propositionnelle : syntaxe et sémantique. Conséquences et équivalences
          logiques. Formes normales, forme clausale. Modélisation, solveurs SAT, recherche
          de modèle, algorithme DPLL. Recherche de preuve, calcul des séquents proposi-
          tionnel.
        — Logique du premier ordre : syntaxe et sémantique. Formes normales, skolémisa-
          tion. Théories logiques, interprétations normales, élimination des quantificateurs.
          Modélisation, solveurs SMT. Recherche de preuve, calcul des séquents du premier
          ordre.
Les (sous-)sections dont le titre est précédé d’une astérisque « * » et grisées dans le texte apportent
des compléments qui ne seront pas traités en cours.
Partie 1. Introduction                                                                               5
  1. Contexte et motivations                                                                         5
     1.1. Logique philosophique                                                                      5
     1.2. Logique mathématique                                                                       5
     1.3. Logique informatique                                                                       6
        1.3.1. Circuits logiques                                                                     6
        1.3.2. Complexité algorithmique                                                              6
        1.3.3. Problèmes « combinatoires »                                                           7
        1.3.4. Programmation logique                                                                 7
        1.3.5. Bases de données                                                                      7
        1.3.6. Vérification de programmes                                                            8
     1.4. Des nombreuses logiques                                                                    8

Partie 2. Logique classique propositionnelle                                                         9
  2. Syntaxe                                                                                         9
     2.1. Arbres de syntaxe abstraite                                                                9
        2.1.1. Représentation en Java                                                               10
        2.1.2. Représentation en OCaml                                                              11
     2.2. Syntaxe concrète                                                                          12

                © 2019–2021 Sylvain Schmitz
                licensed under Creative Commons License CC-BY-SA
                                                        1
2                                    INTRODUCTION À LA LOGIQUE


    3.     Sémantique                                                            13
         3.1. Valeurs de vérité                                                  13
            3.1.1. Interprétations                                               13
            3.1.2. Sémantique                                                    13
            3.1.3. Implémentation de la sémantique en Java                       15
            3.1.4. Implémentation de la sémantique en OCaml                      15
            3.1.5. Tables de vérité                                              16
            3.1.6. Étendre la syntaxe                                            17
            3.1.7. Complétude fonctionnelle                                      17
         3.2. Satisfiabilité et validité                                         18
    4.     Conséquences et équivalences logiques                                 20
         4.1. Conséquences logiques                                              20
         4.2. Équivalences logiques                                              21
         4.3. Substitutions propositionnelles                                    22
            4.3.1. Implémentation des substitutions propositionnelles en Java    22
            4.3.2. Implémentation des substitutions propositionnelles en OCaml   23
            4.3.3. Lemme de substitution propositionnelle                        23
         4.4. Équivalences usuelles                                              24
    5.     Formes normales                                                       26
         5.1. Forme normale négative                                             26
            5.1.1. Implémentation des formes normales négatives en Java          27
         5.2. Forme clausale                                                     28
            5.2.1. Forme clausale logiquement équivalente                        28
            5.2.2. Forme clausale équi-satisfiable                               30
            5.2.3. Format DIMACS                                                 31
            5.2.4. Implémentation de la forme clausale en Java                   32
         5.3. Forme normale disjonctive                                          34
    6.     Modélisation                                                          36
         6.1. Utilisation de solveurs SAT                                        36
            6.1.1. Utilisation de MiniSAT                                        36
            6.1.2. Utilisation de Sat4j dans un programme Java                   36
         6.2. Exemple de modélisation : coloration de graphe                     37
         6.3. Exemple de modélisation : dépendances logicielles                  39
    7.     Satisfiabilité et recherche de modèle                                 44
         7.1. Recherche de modèle par énumération                                44
            7.1.1. Implémentation de la recherche par énumération en Java        46
         7.2. Recherche de modèle par simplification                             47
            7.2.1. Simplification de formes clausales                            47
            7.2.2. Recherche par simplification                                  48
            7.2.3. Correction et complétude                                      49
            7.2.4. Implémentation de la recherche par simplification en Java     50
         7.3. Algorithme de Davis, Putnam, Logemann et Loveland                  51
            7.3.1. Correction et complétude                                      52
            7.3.2. Algorithme DPLL                                               53
            7.3.3. Implémentation d’un DPLL récursif en Java                     54
    8.     Validité et recherche de preuve                                       56
         8.1. Calcul des séquents propositionnel                                 56
         8.2. Recherche de preuve                                                58
            8.2.1. Inversibilité et algorithme de recherche de preuve            60
            8.2.2. Implémentation de la recherche de preuve en Java              62
         8.3. Correction et complétude                                           64
                                 INTRODUCTION À LA LOGIQUE                      3


  9. * Clauses de HoRn                                                        66
    9.1. Modèle minimal                                                       67
       9.1.1. Les fonctions fS                                                67
       9.1.2. Itérations de la fonction fS                                    68
    9.2. HoRnSAT                                                              68
       9.2.1. Conséquences logiques d’un ensemble de clauses de HoRn          69
       9.2.2. Algorithme naïf                                                 69
       9.2.3. Algorithme en temps linéaire                                    71
       9.2.4. Implémentation de l’algorithme en temps linéaire en Java        72
       9.2.5. Implémentation de l’algorithme en temps linéaire en OCaml       74
    9.3. Exemple de modélisation : accessibilité dans un graphe orienté       75

Partie 3. Logique classique du premier ordre                                   78
  10. Structures                                                               78
     10.1. Signatures                                                          78
     10.2. Interprétations                                                     78
     10.3. Représentation des interprétations en OCaml                         80
  11. Syntaxe                                                                  82
     11.1. Formules                                                            82
     11.2. Variables libres et variables liées                                 83
     11.3. Syntaxe en OCaml                                                    83
       11.3.1. Syntaxe abstraite en OCaml                                      83
       11.3.2. Syntaxe concrète en OCaml                                       84
       11.3.3. Variables libres et variables liées en OCaml                    84
  12. Sémantique                                                               85
     12.1. Sémantique                                                          85
     12.2. Modèles, satisfiabilité et validité                                 85
     12.3. Implémentation de la sémantique en OCaml                            86
     12.4. Exemples de formules                                                87
  13. Substitutions                                                            91
     13.1. Lemme de substitution                                               91
     13.2. α-renommages                                                        92
     13.3. Implémentation des substitutions en OCaml                           94
  14. Formes normales                                                          95
     14.1. Forme normale négative                                              95
       14.1.1. Implémentation de la forme normale négative en OCaml            96
     14.2. Forme prénexe                                                       97
       14.2.1. Implémentation de la forme prénexe en OCaml                     98
     14.3. Skolémisation                                                       99
       14.3.1. Implémentation de la skolémisation en OCaml                    101
     14.4. * Forme clausale                                                   101
       14.4.1. Implémentation de la forme clausale en OCaml                   101
     14.5. * Modèles de HeRbRand                                              103
  15. Théories et modèles                                                     105
     15.1. Théories logiques                                                  105
       15.1.1. Théories de structures                                         106
       15.1.2. Théories axiomatiques                                          106
       15.1.3. Interprétations normales                                       107
       15.1.4. Cohérence, complétude et décidabilité                          111
     15.2. Élimination des quantificateurs et décidabilité                    112
       15.2.1. Implémentation en OCaml de l’élimination des quantificateurs   113
4                                   INTRODUCTION À LA LOGIQUE


        15.2.2. Théorie des ordres linéaires denses non bornés                                114
        15.2.3. Théorie de l’arithmétique linéaire rationnelle                                117
      15.3. * Indécidabilité                                                                  118
        15.3.1. Indécidabilité de la théorie de l’arithmétique élémentaire                    118
        15.3.2. Indécidabilité des équations diophantiennes                                   119
        15.3.3. Théorèmes d’incomplétude                                                      120
    16. Satisfiabilité modulo théorie                                                         121
      16.1. Utilisation de solveurs SMT                                                       121
        16.1.1. Principes de base des solveurs SMT                                            121
        16.1.2. Élimination des quantificateurs                                               122
        16.1.3. SMT-LIB                                                                       123
        16.1.4. Théories usuelles                                                             126
      16.2. Exemple de modélisation : nombre de McNuggets                                     126
      16.3. Exemple de modélisation : apprentissage d’automates séparateurs                   127
      16.4. Exemple de modélisation : synthèse d’invariant de programme                       130
      16.5. * Exemple de modélisation : pavage du plan                                        134
    17. Calcul des séquents                                                                   139
      17.1. Correction                                                                        141
      17.2. * Règles admissibles                                                              142
        17.2.1. α-congruence syntaxique                                                       142
        17.2.2. Substitution syntaxique                                                       143
        17.2.3. Affaiblissement                                                               144
        17.2.4. Axiome étendu                                                                 145
        17.2.5. Inversibilité syntaxique                                                      145
        17.2.6. Contraction                                                                   146
      17.3. * Complétude                                                                      148
        17.3.1. Lemme de HintiKKa                                                             148
        17.3.2. Théorème de complétude                                                        149
      17.4. * Élimination des coupures                                                        150

Références                                                                                    154
    Quelques ouvrages sur la logique                                                          154
    Quelques textes fondateurs                                                                154
    Autres ouvrages                                                                           156
    Autres références                                                                         156

   Ces notes de cours ne remplacent pas une lecture approfondie d’ouvrages. Je recommande par-
ticulièrement le livre de Jacques DupaRc (2015) pour débuter. Le livre de John HaRRisson (2009)
se concentre plutôt sur le raisonnement automatique et illustre tous ses concepts par du code
OCaml, ce qui correspond à l’approche quelque peu « utilitariste » que j’adopte dans ces notes.
Pour aller plus loin, les livres de Jean Goubault-LaRRecq et Ian MacKie (1997) et de René David,
Karim NouR et Christophe Raffalli (2003) sont de bonnes références.
   Une partie de ces notes est inspirée des notes de cours du « MOOC » Introduction à la logique
informatique par David Baelde, Hubert Comon et Étienne Lozes 1, ainsi que des transparents du
cours de Logique de Delia KesneR 2, des notes du cours Outils logiques de Ralf TReinen 3 et celles
de Roberto Amadio 4.
   1. Voir les pages https://www.fun-mooc.fr/courses/ENSCachan/20004S02/session02/about         et
https://www.fun-mooc.fr/courses/ENSCachan/20009/session01/about
   2. https://www.irif.fr/~kesner/enseignement/licence/logique/
   3. https://www.irif.fr/~kesner/enseignement/ol3/poly.pdf
   4. https://cel.archives-ouvertes.fr/cel-00163821
                                          INTRODUCTION À LA LOGIQUE                                  5


Partie 1. Introduction
        La logique, du grec λογική / logikê, est un terme dérivé de λόγος / lógos — si-
        gnifiant à la fois « raison », « langage » et « raisonnement » — est, dans une
        première approche, l’étude des règles formelles que doit respecter toute argu-
        mentation correcte.
           Elle est depuis l’Antiquité l’une des grandes disciplines de la philosophie […].
        En outre, on a assisté depuis le XIXe siècle au développement fulgurant d’une ap-
        proche mathématique de la logique. Sa convergence opérée avec l’informatique
        depuis la fin du XXe siècle lui a donné un regain de vitalité. 5

                                       1. Contexte et motivations
1.1. Logique philosophique. La motivation des philosophes antiques comme ARistote est de
déterminer si un raisonnement est concluant. Par exemple, le raisonnement suivant est concluant :
« Tous les hommes sont mortels, or SocRate est un homme, donc SocRate est mortel » ; en effet,
  (1) d’une part les deux prémisses « Tous les humains sont mortels » et « SocRate est humain »
      sont vraies, et
  (2) d’autre part, l’inférence de la conclusion « SocRate est mortel » à partir des prémisses est
      valide.
Les deux ingrédients (1) et (2) ci-dessus d’un raisonnement concluant sont indépendants. Ainsi,
   — « Toutes les souris sont vertes, or Yoda est une souris, donc Yoda est vert » est un raison-
      nement valide mais non concluant car au moins une prémisse est fausse, tandis que
   — « Tous les humains sont mortels, or SocRate est mortel, donc SocRate est humain » n’est
      pas concluant car l’inférence n’est pas valide – on parle alors de raisonnement fallacieux
      ou de non sequitur.
Remarquons en passant que les conclusions de ces deux raisonnements non concluants sont bien
vraies : nous examinons ici le raisonnement, et non sa conclusion.
   La logique s’intéresse à l’ingrédient (2) ci-dessus, c’est-à-dire à formaliser ce qui constitue un
raisonnement valide. En termes modernes, on écrirait de nos jours une formule logique dans un
langage formel, par exemple en logique du premier ordre :
                                                              
                              (∀x . H(x) ⇒ M (x)) ∧ H(s) ⇒ M (s)                                   (1)
où « H(x) » et « M (x) » dénotent respectivement que x est humain et que x est mortel, et « s »
dénote SocRate ; cette formule est bien valide.
    Ceci ne constitue qu’un minuscule aperçu de la logique en tant que discipline philosophique,
qui est un sujet actif de recherche ; d’ailleurs, une excellente source d’information en logique est
la Stanford Encyclopedia of Philosophy 6.

1.2. Logique mathématique. La nécessité d’employer un langage clair, à l’abri d’ambiguïtés,
pour écrire et démontrer des énoncés mathématiques est reconnue depuis l’Antiquité et par
exemple la géométrie d’Euclide. La logique en tant que discipline mathématique prend son essor
au XIXe siècle grâce aux travaux de mathématiciens tels que Boole, de MoRgan et FRege.
   Cela amène à la « crise des fondements » de la fin du XIXe siècle, quand des paradoxes re-
mettent en question l’utilisation naïve des ensembles. Une version vulgarisée d’un de ces pa-
radoxes, due à Russell, est connue comme le paradoxe du barbier : imaginons une ville où un
barbier rase tous les hommes qui ne se rasent pas eux-mêmes (et seulement ceux-là) ; est-ce que
ce barbier se rase lui-même ? Si l’on suppose que ce barbier soit un homme, que la réponse soit

  5. Article Logique de Wikipédia en français.
  6. https://plato.stanford.edu/
6                                    INTRODUCTION À LA LOGIQUE


oui ou non, on aboutit à une contradiction : ce barbier n’existe pas. La version ensembliste du pa-
radoxe est la suivante : on définit y def
                                      = {x | x 6∈ x} la classe des ensembles qui ne se contiennent
pas eux-mêmes ; est-ce que y ∈ y ? Si l’on suppose que y est un ensemble, on aboutit à la contra-
diction y ∈ y ⇔ y 6∈ y. Le XXe siècle voit ainsi plusieurs tentatives pour formaliser la logique
et les mathématiques, mais les limitations de ces approches apparaîtront bientôt grâce à GÖdel,
TuRing et ChuRch – vous en apprendrez plus en M1 en cours de « calculabilité et complexité ».

1.3. Logique informatique. Tout comme la logique permet de formaliser les énoncés mathé-
matiques (en voyant ces énoncés comme des formules de la logique), on peut comprendre l’infor-
matique via le prisme de la logique. Cette vision de l’informatique est incroyablement fructueuse.
Un lien formel très fort existe en particulier entre programmes du côté informatique et preuves
du côté logique – ceci est connu comme l’isomorphisme de CuRRy-HowaRd – qui se retrouve au
cœur du fonctionnement d’assistants de preuve comme Coq ; vous pourrez en apprendre plus
dans le cours de M1 de « preuves assistées par ordinateur » ou dans les cours sur la logique
linéaire ou la théorie des types au MPRI.

   Le point de vue de ce cours est cependant plutôt de voir la logique via le prisme de l’infor-
matique. Les formules de la logique sont des objets très simples d’un point de vue informatique,
à savoir des arbres. Les formules peuvent être manipulées par des programmes pour résoudre
automatiquement quantité de problèmes.

1.3.1. Circuits logiques. Les circuits logiques qui composent les processeurs de nos ordinateurs
sont des réalisations matérielles des formules de la logique propositionnelle. Par exemple, le cir-
cuit ci-dessous représente la formule propositionnelle (P ∧ (Q ∧ ¬R)) ∨ R.
                P

                Q

                R



Raisonner sur les formules de la logique propositionnelle permet ainsi de raisonner sur les cir-
cuits : déterminer leur fonctionnalité, dire si deux circuits sont équivalents, minimiser la taille
d’un circuit, etc. Ce sujet sera approfondi en M1 dans le cours de « circuits et architecture ».

1.3.2. Complexité algorithmique. En cours de M1 de « calculabilité et complexité », vous appren-
drez que des problèmes logiques fournissent les exemples emblématiques de problèmes informa-
tiques difficiles : SAT, la satisfiabilité des formules propositionnelles, est complet pour une classe
de complexité appelée NP, et il en est de même pour d’autres classes de complexité (c.f. table 1).

             Table 1. Complexité algorithmique de quelques problèmes de logique.

                                      Problème Complexité
                                      QBF          PSPACE
                                      SAT          NP
                                      HornSAT      P
                                      2SAT         NL
                                        INTRODUCTION À LA LOGIQUE                                 7


1.3.3. Problèmes « combinatoires ». Le point précédent signifie que quantité de problèmes infor-
matiques peuvent être résolus en les réduisant à des problèmes logiques. L’intérêt est que nous
disposons de logiciels extrêmement optimisés pour résoudre ces problèmes logiques, en particu-
lier des solveurs SAT 7. On parle même de « révolution SAT » car les performances actuelles de
ces solveurs permettent de résoudre des problèmes qui paraissaient hors de portée.
    En guise d’illustration, nous verrons entre autres comment résoudre des grilles de sudoku
comme celle ci-dessous en faisant appel à un solveur SAT. 8
                                                        9   8   7   6    5   4   3   2   1
                                    3       8 5         2   4   6   1    7   3   9   8   5
                        1       2                       3   5   1   9    2   8   7   4   6
                            5       7                   1   2   8   5    3   7   6   9   4
                        4               1               6   3   4   8    9   2   1   5   7
                    9                                   7   9   5   4    6   1   8   3   2
               5                            7 3         5   1   9   2    8   6   4   7   3
                        2       1                       4   7   2   3    1   9   5   6   8
                                4              9        8   6   3   7    4   5   2   1   9

1.3.4. Programmation logique. Dans la lignée du point précédent, le besoin en informatique de
résoudre des problèmes qui peuvent s’exprimer sous la forme de contraintes (par exemple pour le
sudoku, chaque ligne, colonne, et chacun des carrés 3 × 3 doit avoir exactement une occurrence
de chaque nombre de 1 à 9) est tel que des langages de programmation spécialisés ont été déve-
loppés. Dans un langage comme Prolog ou Mozart/Oz, le programmeur fournit les contraintes du
problème, et laisse le système trouver les valeurs des inconnues qui répondent au problème. Ce
paradigme de programmation, différent de la programmation impérative et de la programmation
fonctionnelle, sera étudié dans le cours de M1 « programmation logique et par contraintes ».
1.3.5. Bases de données. En bases de données, le théorème de Codd relie les opérations que l’on
peut effectuer sur une base de données relationnelle (l’algèbre relationnelle) aux requêtes que
l’ont peut écrire (le calcul relationnel, c’est-à-dire la logique du premier ordre). Le langage SQL
fournit une autre façon d’écrire des requêtes du calcul relationnel. Par exemple, la requête
 SELECT Vols.depart
 FROM Vols JOIN Aeroports ON Vols.arrivee = Aeroports.nom
 WHERE Aeroports.pays = 'FR'

sur la base de données D ci-dessous retourne les codes des aéroports depuis lesquels on peut
rejoindre la France, à savoir les aéroports ’ATL’ et ’AMS’.
                    Aeroports                                                Vols
                   nom    pays                                          depart arrivee
                   ’ATL’    ’US’                                        ’ATL’    ’CDG’
                   ’PEK’    ’CN’                                        ’LAX’    ’ATL’
                   ’LAX’    ’US’                                        ’ORY’    ’FRA’
                   ’CDG’    ’FR’                                        ’CDG’    ’PEK’
                   ’AMS’    ’NL’                                        ’AMS’    ’ORY’
                   ’FRA’    ’DE’                                        ’AMS’    ’ATL’
                   ’ORY’    ’FR’                                        ’PEK’    ’LAX’

   7. Par exemple, MiniSat (http://minisat.se/), Glucose (https://www.labri.fr/perso/lsimon/
glucose/) ou Sat4j (http://www.sat4j.org/) ; vous pouvez aussi tester logictools en ligne (http:
//logictools.org/).
   8. Voir par exemple https://blag.cedeela.fr/sudoku-msat/ pour une démonstration en ligne.
8                                                   INTRODUCTION À LA LOGIQUE


  Cette requête peut s’écrire comme une formule φ(depart) en logique du premier ordre, définie
comme :
      φ(depart) def
                = ∃arrivee∃nom∃pays . Vols(depart, arrivee) ∧ Aeroports(nom, pays)
                                                                                       ∧ arrivee = nom ∧ pays = ′ FR′                 (2)
Répondre à une telle requête SQL sur une base de données D comme celle ci-dessus revient
à évaluer la formule logique sur la structure associée à D. Optimiser les requêtes SQL revient
trouver des formules équivalentes.
1.3.6. Vérification de programmes. Les programmes et systèmes informatiques sont sujets à quan-
tité d’erreurs. Une façon de s’assurer qu’ils ont bien le fonctionnement voulu est d’écrire une
spécification formelle du comportement attendu ; naturellement, ces spécifications sont écrites à
l’aide de formules logiques. Par exemple, si on examine les événements successifs d’un système
composé d’un client et d’un serveur, on pourrait vérifier qu’à chaque instant t où le client fait une
requête (Requete(t)), il y a un instant t′ plus tard où le serveur accède à la demande (Acces(t′ )) ;
en logique du premier ordre,
                                         ∀t . Requete(t) ⇒ ∃t′ . t ≤ t′ ∧ Acces(t′ )                                                  (3)
Ce genre de spécifications sera étudié dans le cours de M2 « modélisation et spécification », où
vous verrez aussi comment s’assurer automatiquement qu’un système satisfait sa spécification.
   Une autre approche est plutôt basée sur les « preuves assistées par ordinateur ». Par exemple,
on pourrait souhaiter démontrer que le code suivant calcule r = n! pour un argument n :
     int i = 0;
     int r = 1;
     while (i != n) {
       i++;
       r *= i;
     }

   Une approche bien connue pour cela est d’annoter le code avec des pré-conditions et des post-
relations : chaque instruction I du code est annotée comme un triplet de HoaRe {φ} I {ψ} où
φ et ψ sont des formules logiques portant sur les valeurs des variables du programme. Voici une
preuve en logique de HoaRe que le code ci-dessus est correct, c’est-à-dire que s’il termine alors
r = n!.
                                                                                                         aff
                                                                   {r(i + 1) = (i + 1)!} i++ {ri = i!}
                                                                                                         csq                           aff
                                                                         {r = i!} i++ {ri = i!}               {ri = i!} r*=i {r = i!}
                                                                                                                                       seq
                                                                                          {r = i!} i++;r*=i {r = i!}
                                                              init                                                        csq
                              {i = 0} int r=1 {r = 1 ∧ i = 0}                         {r = i! ∧ i 6= n} i++;r*=i {r = i!}
                                                              csq                                                                  while
                                  {i = 0} int r=1 {r = i!}                   {r = i!} while(i!=n){i++;r*=i} {r = i! ∧ i = n}
                        init
    {>} int i=0 {i = 0}                            {i = 0} int r=1;while(i!=n){i++;r*=i} {r = i! ∧ i = n}
                                                                                                                seq
                        {>} int i=0;int r=1;while(i!=n){i++;r*=i} {r = i! ∧ i = n}


1.4. Des nombreuses logiques. Afin de répondre à des besoins de modélisation formelle et de
raisonnement formel, que ce soit en philosophie, mathématiques ou informatique, de nombreuses
logiques ont été définies et de nouvelles sont constamment développées : logique modale, tempo-
relle, de description, d’ordre supérieur, intuitioniste, linéaire, de séparation, hybride, infinitaire,
etc.
   Ce cours est l’occasion d’étudier deux logiques classiques, qui sont à la base de toutes les
autres : la logique propositionnelle, que vous avez déjà rencontrée en cours d’« outils logiques »
en L2, et la logique du premier ordre, que vous avez utilisée en mathématiques sans le savoir depuis
des années.
                                    INTRODUCTION À LA LOGIQUE                                               9


Partie 2. Logique classique propositionnelle
    Il existe quantité de logiques employées en informatique, mathématiques et philosophie. La
logique la plus simple, qui sert de base aux développement de la plupart des autres logiques, est
la logique propositionnelle, aussi appelée « calcul des propositions ». Dans cette logique, une
« proposition » dénote un énoncé qui peut être vrai ou faux, comme « il pleut aujourd’hui » ou
« 1 + 1 = 2 ». La logique propositionnelle permet de combiner de telles propositions, traitées
comme des « variables propositionnelles », au moyen de connecteurs logiques pour construire
des énoncés plus complexes appelés « formules ». Cette logique est aussi celle employée dans les
solveurs SAT, qui permettent de résoudre en pratique des problèmes informatiques difficiles en
les encodant comme des formules propositionnelles.
    Commençons, afin de fixer les notations employées dans ces notes, par définir la syntaxe et la
sémantique de la logique propositionnelle.

                                             2. Syntaxe

   Résumé. Étant donné un ensemble dénombrable P0 de propositions, les formules propo-
   sitionnelles sont des arbres dont les feuilles sont des propositions et les nœuds internes
   des connecteurs logiques. Ainsi, une formule propositionnelle est un arbre de la forme

                              P    ou    ¬     ou       ∨       ou       ∧

                                         φ          φ       ψ        φ       ψ

   où P ∈ P0 et φ et ψ sont des formules propositionnelles.

2.1. Arbres de syntaxe abstraite. Soit P0 un ensemble infini dénombrable de symboles de                          (DupaRc, 2015, sec. 1.2), (David,
propositions (aussi appelés « variables propositionnelles »). La syntaxe de la logique proposi-                 NouR et Raffalli, 2003, sec. 1.2.6),
tionnelle est définie par la syntaxe abstraite                                                                  (Goubault-LaRRecq et MacKie, 1997,
                                                                                                                sec. 2.1), (HaRRisson, 2009, sec. 2.1)
                 φ ::= P | ¬φ | φ ∨ φ | φ ∧ φ                                    (formules propositionnelles)
où P ∈ P0 .
   Concrètement, cela signifie qu’une formule propositionnelle est un arbre fini, dont les feuilles
sont étiquetées par des propositions tirées de P0 , et dont les nœuds internes sont étiquetés soit
par ¬ (pour « non ») et ont exactement un nœud enfant, soit par ∨ (pour « ou ») ou ∧ (pour
« et ») et ont exactement deux nœuds enfants. Par exemple, la figure 1 décrit une formule pro-
positionnelle φex où P et Q sont des propositions de P0 .


                                              = ∧
                                          φex def

                                                    ∨       P

                                               P        ¬

                                                        Q

                            FiguRe 1. Une formule propositionnelle.

   L’intérêt de travailler avec des arbres de syntaxe abstraite est que ceux-ci se prêtent très
bien aux définitions et aux algorithmes par récurrence. Par exemple, on peut définir l’ensemble
10                                  INTRODUCTION À LA LOGIQUE


fp(φ) ⊆ P0 des propositions qui apparaissent au moins une fois dans une formule proposition-
nelle φ :
                  fp(P ) def
                         = {P } ,                         fp(¬φ) def
                                                                 = fp(φ) ,
               fp(φ ∨ ψ) def
                         = fp(φ) ∪ fp(ψ)               fp(φ ∧ ψ) def
                                                                 = fp(φ) ∪ fp(ψ).
Dans l’exemple de la figure 1, fp(φex ) = {P, Q}.

2.1.1. Représentation en Java. On peut représenter les formules propositionnelles en Java de ma-
nière naturelle à l’aide d’une classe abstraite et de sous-classes pour chacun des types de nœuds
comme ci-dessous. À noter que l’on utilise ici l’ensemble des objets de type String en guise
d’ensemble de propositions P0 .
     Formule
     public abstract class Formule {
         // sous-classes
         public static class Et extends Formule {
               protected Formule phi1; // sous-formule gauche
               protected Formule phi2; // sous-formule droite
               public Et (Formule phi1, Formule phi2) {
                        this.phi1 = phi1;
                        this.phi2 = phi2;
               }
               // méthodes
                  ..            pour formules ∧
               // .
         }
         public static class Ou extends Formule {
               protected Formule phi1; // sous-formule gauche
               protected Formule phi2; // sous-formule droite
               public Ou (Formule phi1, Formule phi2) {
                        this.phi1 = phi1;
                        this.phi2 = phi2;
               }
               // méthodes
                   ..           pour formules ∨
               // .
         }
         public static class Non extends Formule {
               protected Formule phi1; // sous-formule
               public Non (Formule phi1) {
                        this.phi1 = phi1;
               }
               // méthodes
                    ..          pour formules ¬
               // .
         }
         public static class Proposition extends Formule {
               protected String nom; // nom de la proposition
               public Proposition (String nom) {
                        this.nom = nom;
               }
               // méthodes
                     ..         pour propositions
               // .
         }
         // méthodes
            ..              de la classe abstraite
         // .
     }
                                    INTRODUCTION À LA LOGIQUE                                   11


Avec ce code, on peut construire la formule propositionnelle de la figure 1 par

 Formule phi = new Et
     (new Ou
          (new Proposition("P"),
           new Non(new Proposition("Q"))),
      new Proposition("Q"));


  Les choses se gâtent quelque peu quand on souhaite implémenter des méthodes sur les for-
mules propositionnelles. Par exemple, pour calculer l’ensemble fp(φ), l’idée naturelle est d’im-
porter java.util.*, de déclarer une méthode abstraite de la classe Formule
 Formule
 public abstract Set<String> getPropositions();

et de l’implémenter dans chacune des sous-classes. Par exemple :
 Formule.Et, Formule.Ou
 public Set<String> getPropositions() {
     Set<String> propositions = phi1.getPropositions();
     propositions.addAll(phi2.getPropositions());
     return propositions;
 }
 Formule.Non
 public Set<String> getPropositions() {
     return phi1.getPropositions();
 }
 Formule.Proposition
 public Set<String> getPropositions() {
     Set<String> propositions = new TreeSet<String>();
     propositions.add(nom);
     return propositions;
 }

   On voit là un défaut de notre représentation Java, qui disperse le code des différents cas dans
plusieurs locations des fichiers sources.

2.1.2. Représentation en OCaml. Un autre de langage de programmation que vous allez découvrir
cette année dans le cours de « programmation fonctionnelle » est OCaml. Ce langage s’avère
bien mieux adapté au style de programmes que l’ont souhaite écrire en logique. Par exemple, les
formules propositionnelles peuvent utiliser le type abstrait ci-dessous (on utilise ici l’ensemble
des chaînes de caractères comme ensemble de propositions P0 ).
 type formule     = Proposition of string
            |     Non of formule
            |     Et of formule * formule
            |     Ou of formule * formule

La formule propositionnelle de la figure 1 se construit par
 let phi = Et (Ou (Proposition "P", Non (Proposition "Q")),
               Proposition "P")

   Écrire des programmes récursifs en OCaml sur une telle représentation est très aisé. Voici par
exemple un programme qui calcule fp(φ) (en utilisant une fonction auxiliaire enleve_duplicats
de type 'a list -> 'a list qui retourne une liste sans duplicats) :
                             12                                  INTRODUCTION À LA LOGIQUE


                                  let   rec liste_propositions = function
                                    |   Proposition p   -> [p]
                                    |   Non phi         -> liste_propositions phi
                                    |   Et (phi1, phi2) -> liste_propositions phi1 @ liste_propositions phi2
                                    |   Ou (phi1, phi2) -> liste_propositions phi1 @ liste_propositions phi2
                                  let   propositions phi = enleve_duplicats (liste_propositions phi)

 (DupaRc, 2015, sec. 1.4)   2.2. Syntaxe concrète. Cependant, dessiner des arbres à chaque fois que l’on veut écrire une
                             formule propositionnelle est plutôt laborieux. On utilise plutôt une écriture « linéaire » en in-
                             troduisant des parenthèses de manière judicieuse. Par exemple, la formule propositionnelle de
                             la figure 1 s’écrit φex def
                                                     = ((P ∨ ¬Q) ∧ P ). On se permet généralement des facilités d’écritures,
                             comme (P ∨ ¬Q) ∧ P pour φex – où l’on a enlevé les parenthèses extérieures –, ou P ∧ Q ∧ R
                             pour ((P ∧ Q) ∧ R) ou (P ∧ (Q ∧ R)) – car les opérateurs ∧ et ∨ sont associatifs (voir section 4).
                                 La syntaxe concrète d’une formule propositionnelle s’implémente très aisément par un pro-
                             gramme récursif ; par exemple, en OCaml :
                                  let rec string_of_formule phi =
                                    match phi with
                                    | Proposition p   -> p
                                    | Non phi1        -> "¬" ^ string_of_formule phi1
                                    | Et (phi1, phi2) ->
                                      "(" ^ string_of_formule phi1 ^ " � " ^ string_of_formule phi2 ^ ")"
                                    | Ou (phi1, phi2) ->
                                      "(" ^ string_of_formule phi1 ^ " � " ^ string_of_formule phi2 ^ ")"
                                     INTRODUCTION À LA LOGIQUE                                      13


                                          3. SÉmantie

   Résumé. Soit B def = {0, 1} l’ensemble des valeurs de vérité, où 0 désigne « faux » et 1
   désigne « vrai ». Étant donnée une interprétation I : P0 → B, la sémantique JφKI d’une
   formule propositionnelle est une valeur de vérité, qui ne dépend en réalité que des propo-
   sitions qui apparaissent dans φ (propriété 3.3). On note « I Z= φ » si JφKI = 1.
       Ainsi, on peut aussi voir JφK comme une fonction booléenne qui prend en argument les
   valeurs de vérité de ses propositions et retourne une valeur de vérité, et pour laquelle on
   peut écrire une tables de vérité. Inversement, pour toute fonction booléenne f , il existe une
   formule propositionnelle φ telle que f = JφK (théorème 3.8 de complétude fonctionnelle).
      Une formule propositionnelle φ est satisfiable s’il existe une interprétation I telle que
   JφKI = 1. Elle est valide (noté « Z= φ ») si pour toute interprétation I, on a JφKI = 1.

3.1. Valeurs de vérité. On note B def   = {0, 1} pour l’ensemble des valeurs de vérité : l’intuition
est que 1 dénote la valeur « vrai » et 0 la valeur « faux ». On définit aussi trois opérations
not : B → B et and, or: B2 → B définies par not 1 = 0 or 0 = 0 and 0 = 1 and 0 = 0 and 1 = 0
et not 0 = 1 or 1 = 1 or 0 = 0 or 1 = 1 and 1 = 1 (voir la table 2). On appelle aussi B muni des
trois opérations not , or et and « l’algèbre de Boole ».

Remarque 3.1. En français, le mot « ou » est ambigu, dans la mesure où il peut être compris               (DupaRc, 2015, sec. 2.3)
de manière inclusive (A ou B ou les deux) ou exclusive (A ou B mais pas les deux). Dans l’usage
courant, les deux cas A et B sont souvent implicitement exclusifs (« Je me lève à sept ou huit
heures selon les jours »). Le « or » logique est en revanche inclusif.

3.1.1. Interprétations. Une interprétation est une fonction (aussi appelée une « valuation pro-           (DupaRc, 2015, sec. 2.1)
positionnelle ») I: P0 → B qui associe une valeur de vérité P I ∈ B pour chaque proposition               On peut aussi voir une interprétation
                                                                                                         comme un sous-ensemble
P ∈ P0 . Si I est une interprétation et P est une proposition, on écrit I[1/P ] (resp. I[0/P ]) pour     I=def
                                                                                                               {P ∈ P0 | P I = 1} de
l’interprétation qui associe 1 à P (resp. 0) et QI à Q pour tout Q 6= P .                                propositions dans 2P0 ; les deux points
                                                                                                         de vue sont bien sûr équivalents.


3.1.2. Sémantique. La sémantique JφKI ∈ B d’une formule propositionnelle φ dans une inter-                (DupaRc, 2015, sec. 2.2),
                                                                                                         (Goubault-LaRRecq et MacKie, 1997,
prétation I est définie inductivement par                                                                def. 2.8), (HaRRisson, 2009, sec. 2.2)

JP KI def
      = PI ,    J¬φKI def
                      = not JφKI ,     Jφ ∨ ψKI def
                                                = JφKI or JψKI ,        Jφ ∧ ψKI def
                                                                                 = JφKI and JψKI .

   On dit que I satisfait φ (ou que I est un « modèle » de φ), noté I Z= φ, si JφKI = 1 ; cette
écriture peut être définie de manière équivalente par

                      I Z= P                             si P ∈ I ,
                      I Z= ¬φ                            si I 6Z= φ ,
                      I Z= φ ∨ ψ                         si I Z= φ ou I Z= ψ ,
                       Z φ∧ψ
                      I=                                 si I Z= φ et I Z= ψ .

                        = {I ∈ BP0 | I Z= φ} l’ensemble des interprétations qui satisfont φ.
On définit aussi Sat(φ) def                                                                               On peut aussi définir la sémantique
                                                                                                         d’une formule propositionnelle via un
                                                                                                         jeu d’évaluation ; voir (DupaRc, 2015,
  Exemple 3.2. Considérons à nouveau la formule propositionnelle φex = (P ∨ ¬Q) ∧ P de                   sec. 2.7).
  la figure 1, et l’interprétation I qui associe P I = 0 à P , QI = 0 à Q, et RI = 1 à toutes les
                                14                                     INTRODUCTION À LA LOGIQUE


                                     propositions R ∈ P0 différentes de P et Q. La sémantique Jφex KI se calcule comme suit :
                                                            J(P ∨ ¬Q) ∧ P KI = JP ∨ ¬QKI and JP KI
                                                                                 = (JP KI or J¬QKI ) and JP KI
                                                                                 = (P I or J¬QKI ) and JP KI
                                                                                 = (0 or J¬QKI ) and JP KI
                                                                                 = (0 or not JQKI ) and JP KI
                                                                                 = (0 or not QI ) and JP KI
                                                                                 = (0 or not 0) and JP KI
                                                                                 = (0 or 1) and JP KI
                                                                                 = 1 and JP KI
                                                                                 = 1 and P I
                                                                                 = 1 and 0
                                                                                 =0.
                                     À noter que l’on aurait pu atteindre ce résultat bien plus vite en écrivant
                                                            J(P ∨ ¬Q) ∧ P KI = JP ∨ ¬QKI and JP KI
                                                                                 = JP ∨ ¬QKI and P I
                                                                                 = JP ∨ ¬QKI and 0
                                                                                 =0,
                                     sans se préoccuper d’évaluer JP ∨ ¬QK . I


                                   On peut observer que la valeur de vérité de φ ne dépend que de l’interprétation des proposi-
                                tions de fp(φ) : si P 6∈ fp(φ), alors pour toute interprétation I, JφKI[1/P ] = JφKI[0/P ] . Cela se
                                démontre par induction structurelle sur φ comme suit.
                                                                                                                             ′
 (HaRRisson, 2009, thm. 2.2)   Propriété 3.3. Pour toute formule propositionnelle φ et interprétations I et I ′ , si P I = P I pour
                                                                              ′
                                toute proposition P ∈ fp(φ), alors JφKI = JφKI .
                                Démonstration. Par induction structurelle sur φ.
                                                                                             ′
                                   Pour le cas de base φ = P , on a P ∈ fp(φ) donc P I = P I par hypothèse sur I et I ′ , et on a
                                bien
                                                                                   ′       ′
                                                                  JP KI = P I = P I = JP KI .
                                                                                                                   ′
                                   Pour l’étape d’induction, si φ = ¬ψ, on a fp(φ) = fp(ψ), donc P I = P I pour toute proposi-
                                tion P ∈ fp(ψ) et on peut appliquer l’hypothèse d’induction à la sous-formule ψ : on a bien
                                                                                               ′        ′
                                                                               i.h.
                                                              J¬ψKI = not JψKI =    not JψKI = J¬ψKI .
                                                                                                   ′
                                Si φ = ψ ∨ ψ ′ , on a fp(φ) = fp(ψ) ∪ fp(ψ ′ ), donc P I = P I pour toute proposition P ∈ fp(ψ)
                                ou P ∈ fp(ψ ′ ) et on peut appliquer l’hypothèse d’induction aux deux sous-formules ψ et ψ ′ : on
                                a bien
                                                                                          ′          ′             ′
                                                   Jψ ∨ ψ ′ KI = JψKI or Jψ ′ KI =
                                                                                 i.h.
                                                                                      JψKI or Jψ ′ KI = Jψ ∨ ψ ′ KI .
                                Enfin, le cas où φ = ψ ∧ ψ ′ est similaire au précédent.                                        □
                                   La propriété 3.3 signifie que, pour une interprétation I et une formule propositionnelle φ,
                                seules les valeurs de vérité P I pour P ∈ fp(φ) influencent la sémantique JφKI . On pourrait
                                donc aussi employer des interprétations partielles I: P0 ↛ B pour peu que leur domaine dom(I)
                                contienne les propositions de fp(φ).
                                           INTRODUCTION À LA LOGIQUE                                               15


    Introduisons quelques notations supplémentaires pour ces interprétations partielles. Pour des
propositions distinctes P1 , . . . , Pn et des valeurs de vérité b1 , . . . , bn , on note [b1 /P1 , . . . , bn /Pn ]
                                                                                     [b /P ,...,bn /Pn ] def
pour l’interprétation partielle de domaine fini {P1 , . . . , Pn } telle que Pj 1 1                      = bj pour
tout 1 ≤ j ≤ n. Pour deux interprétations partielles I et I , on dit que I ′ étend I ou que I est
                                                                    ′

la restriction de I ′ à dom(I), et on écrit I v I ′ , si dom(I) ⊆ dom(I)′ et pour toute proposition
                          ′
P ∈ dom(I), P I = P I .

  Exemple 3.4. Comme vu dans l’exemple 3.2, on a Jφex KI = 0 pour toute interprétation I qui
  étend l’interprétation partielle [0/P, 0/Q].

3.1.3. Implémentation de la sémantique en Java. Revenons à notre implémentation des formules
propositionnelles en Java commencée en section 2.1.1. Une interprétation I pourrait naturel-
lement être représentée comme un objet de type Function<String,Boolean> (du package
java.util.function). Mais au vu de ce qui précède, nous pouvons nous contenter d’inter-
prétations partielles de domaine fini, qui peuvent être représentées comme des objets de type
Map<String,Boolean>. L’objectif est donc d’implémenter la méthode abstraite suivante de la
classe Formule :
  Formule
  public abstract boolean evalue(Map<String,Boolean> interpretation);

Dans les différentes sous-classes, on pourrait écrire pour cela                                                          Avec ce code, il faut vérifier que
                                                                                                                        fp(φ) ⊆ dom(I) avant d’exécuter
  Formule.Et                                                                                                            evalue, par exemple via une assertion
  public boolean evalue(Map<String,Boolean> interpretation) {                                                           interpretation.keySet()
                                                                                                                        .containsAll(
      return phi1.evalue(interpretation)
                                                                                                                        getPropositions());
          && phi2.evalue(interpretation);
  }
  Formule.Ou
  public boolean evalue(Map<String,Boolean> interpretation) {
      return phi1.evalue(interpretation)
          || phi2.evalue(interpretation);
  }
  Formule.Non
  public boolean evalue(Map<String,Boolean> interpretation) {
      return !phi1.evalue(interpretation);
  }
  Formule.Proposition
  public boolean evalue(Map<String,Boolean> interpretation) {
      return interpretation.get(nom).booleanValue();
  }

3.1.4. Implémentation de la sémantique en OCaml. Revenons maintenant à notre implémenta-
tion des formules propositionnelles en OCaml de la section 2.1.2. Dans ce cas, nous verrons
une interprétation comme une fonction de type string -> bool. Une interprétation partielle
de domaine fini peut s’implémenter en levant une exception ; voici un exemple de code pour
[0/P, 0/Q] :
  let i = function
      "P" -> false
    | "Q" -> false
    | p -> failwith ("Proposition "^p^" non interpretee")

L’évaluation d’une formule propositionnelle se fait récursivement :
                             16                                         INTRODUCTION À LA LOGIQUE


                                  let rec evalue phi interpretation =
                                    match phi with
                                      Et(phi1, phi2) -> (evalue phi1 interpretation)
                                        && (evalue phi2 interpretation)
                                    | Ou(phi1, phi2) -> (evalue phi1 interpretation)
                                        || (evalue phi2 interpretation)
                                    | Non phi1       -> not (evalue phi1 interpretation)
                                    | Proposition p -> interpretation(p)

 (DupaRc, 2015, sec. 2.8)   3.1.5. Tables de vérité. Les opérateurs not , or et and sont des fonctions booléennes, c’est-à-dire
                             des fonctions f : Bn → B pour un certain n > 0. Une façon de présenter de telles fonctions est
                             sous la forme de tables de vérité, où chaque ligne indique les valeurs possibles des arguments
                             x1 , . . . , xn de la fonction ainsi que la valeur de f (x1 , . . . , xn ) ; voir la table 2 pour les tables de
                             vérité de not , or et and.
                                                     Table 2. Les tables de vérité des fonctions not , or et and.

                                                                        x1       x2    x1 or x2        x1   x2   x1 and x2
                                                x1     not x1
                                                                        1        1          1           1   1       1
                                                1        0              1        0          1           1   0       0
                                                0        1              0        1          1           0   1       0
                                                                        0        0          0           0   0       0

                                Soit φ une formule propositionnelle. Par la propriété 3.3, la satisfaction de φ ne dépend que
                             de l’interprétation des propositions de fp(φ). On peut ainsi voir φ comme définissant une fonc-
                             tion des interprétations partielles I ∈ Bfp(φ) dans B : JφK(I) def
                                                                                             = JφKI . C’est donc une fonction
                             booléenne B → B à n = |fp(φ)| variables, et on peut en donner la table de vérité. Cependant,
                                          n

                             plutôt que de seulement donner la table de vérité de JφK, il peut être pratique de donner par la
                             même occasion la table de vérité de chacune de ses sous-formules.
                                         Table 3. La table de vérité de la formule propositionnelle φex de la figure 1.

                                                                P   Q       ¬Q        P ∨ ¬Q      (P ∨ ¬Q) ∧ P
                                                                1   1        0          1              1
                                                                1   0        1          1              1
                                                                0   1        0          0              0
                                                                0   0        1          1              0


                                  Exemple 3.5. Pour la formule propositionnelle φex de la figure 1, Jφex K est une fonction à deux
                                  variables qui représentent les valeurs de JP KI et JQKI . La formule propositionnelle φex a pour
                                  sous-formules P , Q, ¬Q, P ∨ ¬Q, ainsi que (P ∨ ¬Q) ∧ P . La table de vérité correspondante
                                  est donnée dans la table 3.
                                  Les deux colonnes « ¬Q » et « P ∨ ¬Q » contiennent des calculs intermédiaires. La colonne
                                  « ¬Q » est obtenue en appliquant not à la colonne Q ; la colonne « P ∨¬Q » l’est en appliquant
                                  or aux colonnes P et ¬Q ; enfin, la colonne « (P ∨ ¬Q) ∧ P » est obtenue en appliquant and
                                  aux colonnes P ∨ ¬Q et P . À noter que la sémantique Jφex KI = 0 calculée dans l’exemple 3.2
                                  pour I étendant [0/P, 0/Q] correspond à la dernière ligne de la table.
                                  On peut remarquer dans cette table que les colonnes « P » et « (P ∨ ¬Q) ∧ P » contiennent
                                  les mêmes valeurs de vérité : ces deux formules propositionnelles sont dites fonctionnellement
                                  équivalentes, car elles définissent les mêmes fonctions JP K = J(P ∨ ¬Q) ∧ P K.
                                          INTRODUCTION À LA LOGIQUE                                          17


3.1.6. Étendre la syntaxe. D’autres opérations booléennes que not , or et and pourraient être                      (DupaRc, 2015, sec. 2.11)
                                                                                2
utilisées dans la syntaxe des formules propositionnelles. Par exemple, il y a 22 = 16 fonctions
booléennes à deux arguments, dont les fonctions indiquées dans la table 4.

         Table 4. Les tables de vérité des fonctions booléennes xor (« ou exclusif »),
         impl (« implique »), equiv (« si et seulement si ») et nand (« non et »).

                  x1     x2    x1 xor x2       x1 impl x2       x1 equiv x2       x1 nand x2
                   1     1           0               1                 1                 0
                   1     0           1               0                 0                 1
                   0     1           1               1                 0                 1
                   0     0           0               1                 1                 1

   Pour chacune de ces fonctions, on pourrait étendre la syntaxe abstraite des formules proposi-
tionnelles pour s’autoriser à les utiliser :
                         φ ::= · · · | φ ⊕ φ | φ ⇒ φ | φ ⇔ φ | φ ↑ φ ,
en étendant de même la sémantique par
            Jφ ⊕ ψKI def
                     = JφKI xor JψKI ,                           Jφ ⇒ ψKI def
                                                                          = JφKI impl JψKI ,
           Jφ ⇔ ψKI def
                    = JφKI equiv JψKI ,                             Jφ ↑ ψK def
                                                                            = JφKI nand JψKI .
Remarque 3.6. Comme mentionné dans la remarque 3.1, le « ou exclusif » xor correspond au sens
souvent implicite du mot « ou » en français (A ou B mais pas les deux).
    L’implication impl correspond approximativement à « si A alors B » ou « A implique B ».                        (DupaRc, 2015, sec. 2.3)
Mais en français usuel, ces locutions établissent souvent un lien de causalité implicite entre A et
B, comme dans « S’il pleut, alors je prends mon parapluie. ». Cela rend aussi une phrase comme
« S’il pleut et que je mets mon pull bleu, alors il pleut. » assez étrange, alors que (P ∧ B) ⇒ P
est une formule propositionnelle tout à fait raisonnable. L’implication en français courant peut
aussi prendre un sens exclusif, comme dans « S’il reste ici, je m’en vais. », qu’on formaliserait en
R ⊕ ¬V où R dénote « il reste ici » et V « je m’en vais ».
3.1.7. Complétude fonctionnelle. Pour les applications de la logique propositionnelle, par exemple                 (DupaRc, 2015, sec. 2.12)
pour les expressions booléennes dans les langages de programmation ou de circuits logiques, il
serait pour le moins souhaitable que toutes les fonctions booléennes soient exprimables comme
la sémantique JφK d’une formule propositionnelle φ. Une solution serait, pour chaque fonction
booléenne f : Bn → B, d’étendre la syntaxe abstraite des formules propositionnelles par
                                          φ ::= · · · | f (φ, . . . , φ)
et leur sémantique par
                              Jf (φ1 , . . . , φn )KI def
                                                      = f (Jφ1 KI , . . . , Jφn KI ) .
    Fort heureusement, il n’est pas nécessaire d’enrichir la syntaxe et la sémantique des formules
propositionnelles par une infinité de cas – ce qui serait un obstacle pour leur implémentation !
En effet, toutes les fonctions booléennes peuvent être exprimées à l’aide des seules not , or et and
(et des fonctions de projection) en les composant de manière appropriée.

  Exemple 3.7. Les fonctions de la table 4 s’expriment comme suit :
         x1 xor x2 = (x1 or x2 ) and not (x1 and x2 ) ,                    x1 impl x2 = not x1 or x2 ,
      x1 equiv x2 = (not x1 or x2 ) and (not x2 or x1 ) ,                  x1 nand x2 = not (x1 and x2 ) .
                                          18                                          INTRODUCTION À LA LOGIQUE


                                             Intuitivement, les fonctions booléennes définissables comme des sémantiques JφK de formules
                                          propositionnelles sont justement les fonctions exprimables à l’aide des seules not , or et and ; par
                                          exemple, impl = J¬P1 ∨ P2 K. On obtient donc le résultat suivant.
                                          Théorème 3.8 (complétude fonctionnelle). Pour tout n > 0 et toute fonction booléenne f : Bn →
                                          B, il existe une formule propositionnelle φ sur n propositions P1 , . . . , Pn telle que f = JφK.
                                          Démonstration. Soit f une fonction booléenne Bn → B pour un certain n > 0. Si n = 1, alors
                                          il y a quatre fonctions booléennes de B dans B, qui sont toutes exprimables à l’aide de formules
                                          propositionnelles :
                                              — la fonction identité est JP1 K,
                                              — la fonction négation J¬P1 K,
                                              — la fonction constante 1 est JP1 ∨ ¬P1 K et
                                              — la fonction constante 0 est JP1 ∧ ¬P1 K.
 Cette expression pour f est appelée     Si n > 1, alors
sa forme normale disjonctive
complète ; voir la section 5.3.
                                                                                           _
                                                                           f =J                          φ(b1 ,...,bn ) K
                                                                                        (b1 ,...,bn )∈Bn :f (b1 ,...,bn )=1

                                          pourvu que chaque formule propositionnelle φ(b1 ,...,bn ) soit telle que Jφ(b1 ,...,bn ) KI = 1 si et
                                          seulement si pour tout 1 ≤ i ≤ n, PiI = bi . De telles formules propositionnelles φ(b1 ,...,bn )
                                          s’écrivent comme des conjonctions
                                                                                   ^
                                                                φ(b1 ,...,bn ) def
                                                                               =     ℓ(b1 ,...,bn ),i
                                                                                       1≤i≤n

                                          où les littéraux ℓ(b1 ,...,bn ),i sont définis par
                                                                                          (
                                                                                      def   Pi     si bi = 1
                                                                     ℓ(b1 ,...,bn ),i =                                                       □
                                                                                            ¬Pi    si bi = 0.

                                               Exemple 3.9. Appliquons la preuve du théorème 3.8 de complétude fonctionnelle à la fonction
                                               equiv définie dans la table 4. Il y a deux valuations de (x1 , x2 ) telles que x1 equiv x2 = 1, à
                                               savoir (1, 1) et (0, 0). Les deux formules propositionnelles associées sont φ(1,1) def
                                                                                                                                   = P1 ∧ P2 et
                                               φ(0,0) def
                                                      = ¬P1 ∧ ¬P2 , et on a bien equiv = J(P1 ∧ P2 ) ∨ (¬P1 ∧ ¬P2 )K.

 (DupaRc, 2015, sec. 2.9), (HaRRisson,   3.2. Satisfiabilité et validité. Une formule propositionnelle φ est satisfiable s’il existe un mo-
2009, sec. 2.3)
                                          dèle de φ, c’est-à-dire s’il existe une interprétation I telle que I Z= φ. Elle est valide, noté Z= φ,
                                          si pour toute interprétation I, I Z= φ. Clairement, une formule propositionnelle valide est en
                                          particulier satisfiable, mais l’inverse n’est pas toujours vrai.
                                              En termes des tables de vérité de la section 3.1.5, une formule propositionnelle est donc sa-
                                          tisfiable si et seulement s’il existe au moins une entrée 1 dans sa colonne, et elle est valide si et
                                          seulement si sa colonne est entièrement constituée de 1. On voit dans la table 3 que la formule
                                          propositionnelle φex de la figure 1 est satisfiable mais pas valide.
                                              En termes d’ensemble de modèles, rappelons que Sat(φ) def     = {I ∈ BP0 | I Z= φ} dénote
                                          l’ensemble des interprétations qui satisfont φ. Alors φ est satisfiable si Sat(φ) 6= ∅, tandis qu’elle
                                          est valide si Sat(φ) = BP0 est l’ensemble de toutes les interprétations possibles.

                                               Exemple 3.10 (loi de PeiRce). La formule propositionnelle φ def  = ((P ⇒ Q) ⇒ P ) ⇒ P
                                               est une variante du tiers exclu, et est valide en logique classique propositionnelle. En effet,
                                               soit I une interprétation quelconque. Si I Z= P , alors I Z= φ. Sinon, I Z= P ⇒ Q donc
                                               I 6Z= (P ⇒ Q) ⇒ P et donc I Z= φ.
                                       INTRODUCTION À LA LOGIQUE                                         19


Propriété 3.11 (dualité entre satisfiabilité et validité). Une formule propositionnelle φ n’est pas
satisfiable si et seulement si ¬φ est valide ; elle n’est pas valide si et seulement si ¬φ est satisfiable.
Démonstration. Pour le premier énoncé, φ n’est pas satisfiable (aussi dite « contradictoire »)
  — si et seulement si, pour toute interprétation I, I 6Z= φ,
  — si et seulement si, pour toute interprétation I, I Z= ¬φ,
  — si et seulement si, ¬φ est valide.
Pour le second énoncé, φ n’est pas valide (aussi dite « falsifiable »)
  — si et seulement si, il existe une interprétation I telle que I 6Z= φ,
  — si et seulement si, il existe une interprétation I telle que I Z= ¬φ,
  — si et seulement si, ¬φ est satisfiable.                                                    □
   Pour un ensemble de formules propositionnelles S et une interprétation I, on écrit I Z= S si
I Z= ψ pour tout ψ ∈ S. Un ensemble S est insatisfiable s’il n’existe pas d’interprétation I telle
que I Z= S.

  Exemple 3.12 (ensemble insatisfiable). Soit l’ensemble F de formules propositionnelles sui-
  vant :
                 {P ∨ Q ∨ ¬R, Q ∨ R, ¬P ∨ ¬Q ∨ R, ¬P ∨ ¬R, P ∨ ¬Q} .
  Soit I une interprétation. Supposons tout d’abord que I Z= P . Si I Z= R, alors I 6Z= ¬P ∨ ¬R ;
  sinon si I Z= Q alors I 6Z= ¬P ∨ ¬Q ∨ R et sinon I 6Z= Q ∨ R. Supposons maintenant I 6Z= P . Si
  I Z= Q, alors I Z=
                   6 P ∨ ¬Q ; sinon si I Z= R alors I 6Z= P ∨ Q ∨ ¬R et sinon I 6Z= Q ∨ R.
                             20                                     INTRODUCTION À LA LOGIQUE


                                                        4. ConsÉences et Éivalences logies

                                  Résumé. Une formule propositionnelle φ est une conséquence logique d’une formule pro-
                                  positionnelle ψ (noté « ψ Z= φ ») si pour toute interprétation I, si I Z= ψ alors I Z= φ.
                                  C’est le cas si et seulement si la formule propositionnelle ψ ⇒ φ est valide, si et seulement
                                  si JψK ≤ JφK (lemmes 4.2 et 4.3). Les formules propositionnelles φ et ψ sont logiquement
                                  équivalentes si ψ Z= φ et φ Z= ψ ; c’est le cas si et seulement si ψ ⇔ φ est valide, si et
                                  seulement si JψK = JφK.
                                     Une substitution propositionnelle est une fonction τ de domaine fini qui associe à toute
                                  proposition P ∈ P0 une formule propositionnelle τ (P ) ; par extension, φτ est la formule
                                  propositionnelle dans laquelle toutes les occurrences de chaque proposition P ont été
                                  remplacées par τ (P ).
                                     On dénote par Iτ l’interprétation qui associe pour toute proposition P ∈ P0 la valeur
                                  de vérité P Iτ def
                                                  = Jτ (P )KI ; alors le lemme 4.7 de substitution propositionnelle dit que
                                  Jφτ K = JφK . Cela implique en particulier que si φ est valide, alors φτ l’est aussi, et
                                       I        Iτ

                                  permet de démontrer de nombreuses équivalences usuelles.

                                Comme nous l’avons vu dans l’exemple 3.5, il peut y avoir plusieurs formules propositionnelles
                             avec la même sémantique. Le but de cette section est de mieux comprendre ce phénomène.

 (DupaRc, 2015, sec. 2.5)   4.1. Conséquences logiques. Si S est un ensemble de formules propositionnelles et φ est une
                             formule propositionnelle, on dit que φ est une conséquence logique de S et on écrit S Z= φ si pour
                             toute interprétation I telle que I Z= S on a I Z= φ – autrement dit, si pour toute interprétation I,
                             I Z= S implique I Z= φ.
                             Propriété 4.1. Soit φ une formule propositionnelle. Alors φ est valide si et seulement si ∅ Z= φ,
                             c’est-à-dire φ est une conséquence logique de l’ensemble vide.
                             Démonstration. On a ∅ Z= φ
                               — si et seulement si, pour toute interprétation I, si I satisfait toutes les formules de l’ensemble
                                 vide, alors I Z= φ,
                               — si et seulement si, pour toute interprétation I, on a I Z= φ,
                               — si et seulement si, φ est valide.                                                              □

                                Dans le cas d’un ensemble S = {ψ} constitué d’une seule formule propositionnelle ψ, on
                             notera plus simplement ψ Z= φ et on dira que φ est une conséquence logique de ψ. Si on écrit
                                    = {I ∈ BP0 | I Z= φ} pour l’ensemble des interprétations qui satisfont une formule
                             Sat(φ) def
                             propositionnelle φ, ψ Z= φ revient à Sat(ψ) ⊆ Sat(φ). On peut relier cette notion à la validité
                             d’une seule formule propositionnelle comme suit.
                             Lemme 4.2 (déduction). Soit S un ensemble de formules propositionnelles, et φ et ψ deux formules
                             propositionnelles. Alors S ∪ {ψ} Z= φ si et seulement si S Z= ψ ⇒ φ. En particulier quand S = ∅,
                             ψ Z= φ si et seulement si ψ ⇒ φ est valide.
                             Démonstration. On a S ∪ {ψ} Z= φ
                               — si et seulement si, pour toute interprétation I, si I satisfait toutes les formules proposition-
                                 nelles de S ∪ {ψ}, alors I Z= φ,
                               — si et seulement si, pour toute interprétation I, si I satisfait toutes les formules proposition-
                                 nelles de S, et si de plus I Z= ψ, alors I Z= φ,
                               — si et seulement si, pour toute interprétation I, si I satisfait toutes les formules proposition-
                                 nelles de S, alors I Z= ψ ⇒ φ,
                               — si et seulement si, S Z= ψ ⇒ φ.
                                     INTRODUCTION À LA LOGIQUE                                    21


Par suite, le cas où S = ∅ découle de la propriété 4.1.                                           □
    Une autre façon de comprendre les conséquences logiques est de définir un pré-ordre à l’aide
des sémantiques fonctionnelles JφK. On considère pour cela l’ordre 0 < 1 sur les valeurs de
vérités, et on dit que ψ est fonctionnellement plus petite que φ, noté JψK ≤ JφK, si pour toute
interprétation I, JψKI ≤ JφKI . D’après cette définition, deux formules propositionnelles φ et ψ
sont fonctionnellement équivalentes, c’est-à-dire telles que JφK = JψK, si et seulement si JφK ≤ JψK
et JψK ≤ JφK.
    On peut visualiser le pré-ordre fonctionnel sous la forme d’un treillis comme celui de la fi-
gure 2. Dans cette figure, on donne pour chacun des 16 cas possibles sur deux propositions P et Q
les valeurs de vérité des formules propositionnelles pour les interprétations partielles [1/P, 1/Q],
[1/P, 0/Q], [0/P, 1/Q] et [0/P, 0/Q], dans cet ordre. Chaque élément du treillis est illustré par
un exemple de formule propositionnelle avec cette sémantique ; il y en a bien sûr d’autres, comme
P ∧ ¬Q pour 0100 ou ¬P ∨ ¬Q pour 0111, ou comme vu dans l’exemple 3.5, (P ∨ ¬Q) ∧ P pour
1100. Dans ce treillis, JψK ≤ JφK s’il existe un chemin pointillé qui monte de JψK à JφK.

                                               1111
                                               P ∨ ¬P


                     1110               1101            1011            0111
                     P ∨Q              Q⇒P              P ⇒Q          ¬(P ∧ Q)



              1100       1010          1001             0110         1010      0011
                P         Q           P ⇔Q              P ⊕Q         ¬Q          ¬P



                     1000               0100            0010            0001
                     P ∧Q            ¬(P ⇒ Q)      ¬(Q ⇒ P )          ¬(P ∨ Q)


                                               0000
                                               P ∧ ¬P


          FiguRe 2. Le treillis du pré-ordre fonctionnel sur deux propositions P et Q.


Lemme 4.3 (pré-ordre fonctionnel). Soient φ et ψ deux formules propositionnelles. Alors ψ Z= φ
si et seulement si JψK ≤ JφK.
Démonstration. On a ψ Z= φ
  — si et seulement si, pour toute interprétation I, si I Z= ψ alors I Z= φ,
  — si et seulement si, pour toute interprétation I, si JψKI = 1 alors JφKI = 1,
  — si et seulement si, pour toute interprétation I, JψKI ≤ JφKI ,
  — si et seulement si, JψK ≤ JφK.                                                                □
4.2. Équivalences logiques. On dit que deux formules propositionnelles φ et ψ sont logique-             (DupaRc, 2015, sec. 2.4)
ment équivalentes si ψ Z= φ et φ Z= ψ, c’est-à-dire si, pour toute interprétation I, I Z= ψ si et
seulement si I Z= φ. En terme d’ensemble de modèles, cela revient à demander Sat(ψ) = Sat(φ).
Par le lemme 4.2 de déduction, cela se produit si et seulement si ψ ⇔ φ est une formule propo-
sitionnelle valide. Par le lemme 4.3 de pré-ordre fonctionnel, cela se produit si et seulement si φ
et ψ sont fonctionnellement équivalentes, c’est-à-dire si et seulement si JφK = JψK.
                                              22                                       INTRODUCTION À LA LOGIQUE


                                                  Comme nous allons le voir, l’équivalence logique permet de remplacer une formule propo-
                                              sitionnelle, qui représente par exemple une expression booléenne d’un programme ou un cir-
                                              cuit logique, par une autre formule propositionnelle équivalente potentiellement plus efficace
                                              à évaluer ; ainsi, dans l’exemple 3.5, la formule propositionnelle P est plus facile à évaluer que
                                              (P ∨ ¬Q) ∧ P .
                                                  Il est donc très utile de savoir dire si deux formules propositionnelles φ et ψ sont logiquement
                                              équivalentes ou non. Cela peut se faire à l’aide de tables de vérité
                                                  — d’après le lemme 4.2 de déduction, en vérifiant si φ ⇔ ψ est valide, ou
                                                  — d’après le lemme 4.3 de pré-ordre fonctionnel, en vérifiant si JφK = JψK.

                                                   Exemple 4.4. Appliquons les lemmes 4.2 et 4.3 à l’équivalence entre ¬(P ∨ Q) et ¬P ∧ ¬Q.
                                                   La table de vérité correspondante est donnée dans la table 5 ci-dessous.
                                                   On vérifie dans cette table que la troisième colonne (¬(P ∨ Q)) et la cinquième colonne (¬P ∧
                                                   ¬Q) sont identiques, donc ces deux formules propositionnelles sont logiquement équivalentes
                                                   par le lemme 4.3 de pré-ordre fonctionnel. La sixième colonne (¬(P ∨ Q) ⇔ ¬P ∧ ¬Q) ne
                                                   contient que des 1, donc cette formule propositionnelle est valide, ce qui montre aussi que les
                                                   deux formules propositionnelles sont logiquement équivalentes par le lemme 4.2 de déduction.


                                                          Table 5. Table de vérité de ¬(P ∨ Q), ¬P ∧ ¬Q et ¬(P ∨ Q) ⇔ ¬P ∧ ¬Q.

                                                         P    Q     P ∨Q   ¬(P ∨ Q)       ¬P    ¬Q    ¬P ∧ ¬Q      ¬(P ∨ Q) ⇔ ¬P ∧ ¬Q
                                                          1   1      1          0          0     0         0                   1
                                                          1   0      1          0          0     1         0                   1
                                                          0   1      1          0          1     0         0                   1
                                                          0   0      0          1          1     1         1                   1

                                                 Cette approche via les tables de vérité a l’inconvénient de nécessiter de tester toutes les inter-
                                              prétations des propositions de fp(φ) ∪ fp(ψ), soit un nombre exponentiel de possibilités. Nous
                                              verrons des techniques qui permettent souvent de n’explorer qu’une toute petite partie de cet
                                              espace de recherche. En attendant, nous allons voir une approche qui s’applique bien à de petites
                                              formules propositionnelles et des raisonnements « à la main ».
 (DupaRc, 2015, sec. 2.6),                   4.3. Substitutions propositionnelles. Une substitution propositionnelle (aussi appelée une
(Goubault-LaRRecq et MacKie, 1997,
def. 2.4), (David, NouR et Raffalli,
                                              « transduction propositionnelle ») est une fonction τ qui associe à chaque proposition P ∈ P0
2003, def. 4.6.4), (HaRRisson, 2009, p. 41)   une formule propositionnelle τ (P ), de tel sorte que son domaine dom(τ ) def          = {P ∈ P0 |
                                              τ (P ) 6= P } soit fini. On écrit [φ1 /P1 , . . . , φn /Pn ] pour la substitution propositionnelle de do-
                                              maine {P1 , . . . , Pn } où les Pi sont distinctes et qui associe φi à Pi . Toute substitution proposi-
                                              tionnelle se relève en une fonction des formules propositionnelles dans les formules proposition-
                                              nelles :
                                                   P τ def
                                                       = τ (P ) ,   (¬φ)τ def
                                                                          = ¬(φτ ) ,     (φ ∨ ψ)τ def
                                                                                                  = (φτ ) ∨ (ψτ ) ,    (φ ∧ ψ)τ def
                                                                                                                                = (φτ ) ∧ (ψτ ) .

                                                   Exemple 4.5. Considérons la formule propositionnelle ψ = (P ∧ Q), ainsi que la substitution
                                                   propositionnelle τ = [(P ∨ ¬Q)/P, P /Q]. Alors ψτ = (P ∨ ¬Q) ∧ P .

                                              4.3.1. Implémentation des substitutions propositionnelles en Java. En Java, une substitution propo-
                                              sitionnelle peut être représentée comme un objet de type Map<String,Formule>. Par exemple,
                                              la substitution propositionnelle τ de l’exemple 4.5 se code par
                                                   Map<String,Formule> tau = new HashMap<String,Formule>();
                                                   tau.put("P", new Proposition("Q"));
                                     INTRODUCTION À LA LOGIQUE                                 23


 tau.put("Q", new Ou(new Proposition("P"),
                     new Non(new Proposition("Q"))));

   Pour implémenter l’application d’une substitution propositionnelle, on déclare tout d’abord
que Formule est Cloneable. L’application d’une substitution propositionnelle se fera en ap-
pelant la méthode substitue() suivante :
 Formule
 public abstract Formule substitue(Map<String,Formule> tau);

Son implémentation dans les sous-classes est très simple :
 Formule.Et
 public Formule substitue(Map<String,Formule> tau) {
     return new Et(phi1.substitue(tau), phi2.substitue(tau));
 }
 Formule.Ou
 public Formule substitue(Map<String,Formule> tau) {
     return new Ou(phi1.substitue(tau), phi2.substitue(tau));
 }
 Formule.Non
 public Formule substitue(Map<String,Formule> tau) {
     return new Non(phi1.substitue(tau));
 }
                                                                                                     Si on ne faisait pas appel à clone()
 Formule.Proposition                                                                                ici, on obtiendrait une formule
  public Formule                                                                                    propositionnelle qui n’est plus un arbre
                                                                                                    mais un graphe dirigé acyclique
 substitue(Map<String,Formule> tau) { return (tau.containsKey(nom))?                                enraciné. Ça ne serait pas
   tau.get(nom).clone(): new Proposition(nom); }                                                    nécessairement un problème : pourquoi ?

4.3.2. Implémentation des substitutions propositionnelles en OCaml. Une substitution proposition-
nelle se représente en OCaml comme une fonction de type string -> formule. Par exemple,
la substitution propositionnelle τ de l’exemple 4.5 se code par
 let tau   = function
     "P"   -> Proposition "Q"
   | "Q"   -> Ou (Proposition "P", Non (Proposition "Q"))
   | p     -> Proposition p

Voici un code qui implémente l’application d’une substitution propositionnelle :
 let rec substitue phi       tau =
   match phi with
     Et(phi1, phi2) ->       Et(substitue phi1 tau, substitue phi2 tau)
   | Ou(phi1, phi2) ->       Ou(substitue phi1 tau, substitue phi2 tau)
   | Non phi1       ->       Non(substitue phi1 tau)
   | Proposition p ->        tau p

4.3.3. Lemme de substitution propositionnelle. Pour une interprétation I et une substitution pro-
positionnelle τ , on définit l’interprétation Iτ comme associant P Iτ def
                                                                      = Jτ (P )KI à chaque propo-
sition P de P0 .

  Exemple 4.6. Soit I une interprétation qui étend [0/P, 0/Q] et τ = [(P ∨¬Q)/P, P /Q]. Alors
  P Iτ = JP ∨ ¬QKI = 1 et QIτ = JP KI = 0.

Lemme 4.7 (substitution propositionnelle). Pour toute formule propositionnelle φ, toute substi-      (Goubault-LaRRecq et MacKie, 1997,
                                                                                                    thm. 2.10), (HaRRisson, 2009, thm. 2.3)
tution propositionnelle τ et toute interprétation I, Jφτ KI = JφKIτ .
                                 24                                     INTRODUCTION À LA LOGIQUE


                                 Démonstration. Par induction structurelle sur φ. Pour le cas de base où φ = P ∈ P0 ,




                                                            Jφτ KI = JP τ KI = Jτ (P )KI = JP KIτ = JφKIτ .




                                 Pour l’étape d’induction où φ = ¬ψ,




                                                                                        h.i.
                                            Jφτ KI = J(¬ψ)τ KI = J¬(ψτ )KI = not Jψτ KI =    not JψKIτ = J¬ψKIτ = JφKIτ .




                                 Pour l’étape d’induction où φ = φ′ ∨ ψ,




                                 Jφτ KI = J(φ′ ∨ψ)τ KI = J(φ′ τ )∨(ψτ )KI = Jφ′ τ KI orJψτ KI =
                                                                                              h.i.
                                                                                                   Jφ′ KIτ orJψKIτ = Jφ′ ∨ψKIτ = JφKIτ.




                                 L’étape d’induction où φ = φ′ ∧ ψ est similaire.                                                   □

                                      Exemple 4.8. Considérons comme dans les exemples 4.5 et 4.6 une interprétation I qui étend
                                      [0/P, 0/Q], la substitution propositionnelle τ = [(P ∨ ¬Q)/P, P /Q], et la formule proposi-
                                      tionnelle ψ = (P ∧ Q). Alors d’un côté Jψτ KI = J(P ∨ ¬Q) ∧ P K[0/P,0/Q] = 0, et de l’autre
                                      JψKIτ = JP ∧ QK[1/P,0/Q] = 0.

 (HaRRisson, 2009, cor. 2.4)    Corollaire 4.9. Soit φ une formule propositionnelle valide et τ une substitution propositionnelle.
                                 Alors φτ est valide.



                                 Démonstration. Par le lemme 4.7 de substitution propositionnelle, pour toute interprétation I,
                                 Jφτ KI = JφKIτ . Or, comme φ est valide, JφKIτ = 1.                                         □

                                      Exemple 4.10. Voyons tout de suite une application de la corollaire 4.9. Nous avons vu dans
                                      l’exemple 4.4 que ¬(P ∨ Q) ⇔ (¬P ∧ ¬Q) est valide. Dès lors, pour toutes formules proposi-
                                      tionnelles φ et ψ, on peut appliquer la substitution propositionnelle [φ/P, ψ/Q] et déduire que
                                      ¬(φ ∨ ψ) ⇔ (¬φ ∧ ¬ψ) est valide – autrement dit, que ¬(φ ∨ ψ) et ¬φ ∧ ¬ψ sont logiquement
                                      équivalentes.

 (HaRRisson, 2009, pp. 44–46)   4.4. Équivalences usuelles. En appliquant le même raisonnement que dans l’exemple 4.10, on
                                 a plus généralement les équivalences logiques suivantes.
                                      INTRODUCTION À LA LOGIQUE                                       25


   Résumé. Pour toutes formules propositionnelles φ, ψ, et ψ ′ , les formules suivantes sont
   valides (c’est-à-dire que les formules de part et d’autre du signe ⇔ sont logiquement équi-
   valentes) :
                       (φ ∨ φ) ⇔ φ ,                                          (idempotence de ∨)
                       (φ ∨ ψ) ⇔ (ψ ∨ φ) ,                                  (commutativité de ∨)
                                 ′               ′
               ((φ ∨ ψ) ∨ ψ ) ⇔ (φ ∨ (ψ ∨ ψ ))                                 (associativité de ∨)
                       (φ ∧ φ) ⇔ φ ,                                          (idempotence de ∧)
                       (φ ∧ ψ) ⇔ (ψ ∧ φ) ,                                  (commutativité de ∧)
                                 ′               ′
               ((φ ∧ ψ) ∧ ψ ) ⇔ (φ ∧ (ψ ∧ ψ ))                                 (associativité de ∧)
                          ¬¬φ ⇔ φ ,                                             (double négation)
                             ′                           ′
               (φ ∧ (ψ ∨ ψ )) ⇔ ((φ ∧ ψ) ∨ (φ ∧ ψ )) ,                 (distributivité de ∧ sur ∨)
                             ′                           ′
               (φ ∨ (ψ ∧ ψ )) ⇔ ((φ ∨ ψ) ∧ (φ ∨ ψ )) ,                 (distributivité de ∨ sur ∧)
                     ¬(φ ∨ ψ) ⇔ (¬φ ∧ ¬ψ) ,                       (dualité de de MoRgan pour ∨)
                     ¬(φ ∧ ψ) ⇔ (¬φ ∨ ¬ψ) ,                       (dualité de de MoRgan pour ∧)
                      (φ ⇒ ψ) ⇔ (¬φ ∨ ψ) ,                            (définition de l’implication)
                      (φ ⇒ ψ) ⇔ (¬ψ ⇒ ¬φ) ,                                       (contraposition)
                                 ′                   ′
              ((φ ∧ ψ) ⇒ ψ ) ⇔ (φ ⇒ (ψ ⇒ ψ )) .                                     (curryfication)

  Ces équivalences logiques sont aussi très utiles pour simplifier des formules propositionnelles.
On repose pour cela sur la propriété suivante.
Corollaire 4.11. Soit φ une formule propositionnelle, et τ et τ ′ deux substitutions propositionnelles
telles que, pour toute proposition P ∈ P0 , τ (P ) soit logiquement équivalente à τ ′ (P ). Alors φτ est
logiquement équivalente à φτ ′ .
Démonstration. Pour montrer que φτ et φτ ′ sont logiquement équivalentes, on va montrer que
pour toute interprétation I ∈ BP0 , Jφτ KI = Jφτ ′ KI .
   Par hypothèse, pour toute proposition P ∈ P0 , τ (P ) et τ ′ (P ) sont logiquement équivalentes.
Cela signifie que pour toute interprétation I et toute proposition P , par définition de Iτ et Iτ ′ ,
                                     ′
P Iτ = Jτ (P )KI = Jτ ′ (P )KI = P Iτ , c’est-à-dire que pour toute interprétation I, Iτ = Iτ ′ sont
une seule et même interprétation. On en déduit par le lemme 4.7 de substitution propositionnelle
                                         ′
que Jφτ KI = JφKIτ = Jφτ ′ KI = JφKIτ .                                                           □

  Exemple 4.12. Voici une illustration : on souhaite montrer que (P ⇒ Q) ⇒ P est logi-
  quement équivalente à P . Les deux substitutions propositionnelles [(P ⇒ Q)/P, P /Q] et
  [(¬P ∨ Q)/P, P /Q] sont bien telles que (P ⇒ Q) ⇔ (¬P ∨ Q) (par définition de l’impli-
  cation) et P ⇔ P est immédiat. En appliquant la corollaire 4.11 à la formule propositionnelle
  φ = (P ⇒ Q), on en déduit que (P ⇒ Q) ⇒ P est logiquement équivalente à (¬P ∨Q) ⇒ P .
  Puis, par des raisonnements similaires, par définition de l’implication, elle est logiquement
  équivalente à ¬(¬P ∨ Q) ∨ P , puis par dualité de de MoRgan pour ∨, à (¬¬P ∧ ¬Q) ∨ P , par
  double négation, à (P ∧ ¬Q) ∨ P , par commutativité de ∨, à P ∨ (P ∧ ¬Q), par distributivité de
  ∨ sur ∧, à (P ∨ P ) ∧ (P ∨ ¬Q), par idempotence de ∨, à P ∧ (P ∨ ¬Q), par commutativité de
  ∧, à (P ∨ ¬Q) ∧ P , qui comme nous l’avons vu dans l’exemple 3.5 est logiquement équivalente
  à P.
                                        26                                     INTRODUCTION À LA LOGIQUE


                                                                                5. FoRmes noRmales

                                             Résumé. On peut mettre n’importe quelle formule propositionnelle sous forme normale
                                             négative en « poussant » les négations vers les feuilles par application de la double néga-
                                             tion et des dualités de de MoRgan ; la formule propositionnelle obtenue est logiquement
                                             équivalente et de la forme

                                                            P        ou        ¬         ou         ∨       ou         ∧
                                                                               P
                                                                                                φ       ψ          φ       ψ

                                             où P ∈ P0 et φ et ψ sont des formules propositionnelles sous forme normale négative.
                                             Les formules propositionnelles de la forme « P » ou « ¬P » sont appelées des littéraux.
                                             On note « φ̄ » pour la forme normale négative de ¬φ.
                                                Une formule propositionnelle est sous forme normale conjonctive si elle s’écrit comme
                                                                                 ^       _
                                                                                             ℓi,j
                                                                                   1≤i≤m 1≤j≤ni

                                             où les ℓi,j sont des littéraux. On peut mettre une formule propositionnelle sous forme
                                             normale conjonctive à partir d’une formule propositionnelle sous forme normale négative
                                             en « poussant » les disjonctions vers le bas par application de la distributivité de ∨ sur ∧.
                                             Une formule propositionnelle est sous forme normale disjonctive si elle s’écrit comme
                                                                                    _      ^
                                                                                                ℓi,j
                                                                                   1≤i≤m 1≤j≤ni

                                             où les ℓi,j sont des littéraux. On peut mettre une formule propositionnelle sous forme
                                             normale disjonctive à partir d’une formule propositionnelle sous forme normale négative
                                             en « poussant » les conjonctions vers le bas par application de la distributivité de ∧ sur ∨.
                                             Les formules propositionnelles sous forme normale conjonctive ou disjonctive obtenues
                                             ainsi sont logiquement équivalentes à la formule d’origine mais potentiellement de taille
                                             exponentielle (exemple 5.5).
                                                On préfère en pratique construire des formules propositionnelles sous forme normale
                                             conjonctive équi-satisfiables avec la formule d’origine (section 5.2.2) ; cette opération a un
                                             coût linéaire dans le pire des cas.
                                                Il existe un format de fichier standard pour écrire des formules propositionnelles sous
                                             forme normale conjonctive : le format DIMACS.

                                           Nous avons vu dans la section précédente qu’il existe de nombreuses manières d’écrire des
                                        formules propositionnelles logiquement équivalentes (c.f. section 4). Parmi toutes ces formules
                                        propositionnelles équivalentes, certaines seront plus faciles à traiter ; par exemple, la formule
                                        propositionnelle P est plus facile à évaluer que la formule propositionnelle (P ∨ ¬Q) ∧ P . En
                                        particulier, les algorithmes de recherche de modèle ou de recherche de preuve que nous verrons
                                        par la suite travaillent sur des formules propositionnelles avec une syntaxe restreinte – on parle
                                        alors de forme normale.

 (David, NouR et Raffalli, 2003,       5.1. Forme normale négative. Une formule propositionnelle est sous forme normale négative
sec. 2.6), (Goubault-LaRRecq et
MacKie, 1997, def. 2.38), (HaRRisson,
                                        si elle respecte la syntaxe abstraite
2009, sec. 2.5)
                                                ℓ ::= P | ¬P                                                                        (littéraux)
                                                φ ::= ℓ | φ ∨ φ | φ ∧ φ            (formules propositionnelles sous forme normale négative)
                                    INTRODUCTION À LA LOGIQUE                                   27


où P est une proposition de P0 . En d’autres termes, les négations ne peuvent apparaître que
devant des formules atomiques. Par exemple, la formule propositionnelle φex = (P ∨ ¬Q) ∧ P
de la figure 1 est sous forme normale négative.
   La mise sous forme normale négative procède en « poussant » les négations dans l’arbre de
syntaxe abstraite de la formule propositionnelle vers les feuilles.
Définition 5.1 (forme normale négative). Pour une formule propositionnelle φ, on notera nnf(φ)
sa forme normale négative obtenue inductivement par
            nnf(P ) def
                    =P ,                               nnf(¬P ) def
                                                                = ¬P ,
       nnf(φ ∨ ψ) def
                  = nnf(φ) ∨ nnf(ψ) ,            nnf(¬(φ ∨ ψ)) def
                                                               = nnf(¬φ) ∧ nnf(¬ψ) ,
       nnf(φ ∧ ψ) def
                  = nnf(φ) ∧ nnf(ψ) ,            nnf(¬(φ ∧ ψ)) def
                                                               = nnf(¬φ) ∨ nnf(¬ψ) ,
                                                      nnf(¬¬φ) def
                                                               = nnf(φ) .
On notera aussi en général
                                          φ def
                                            = nnf(¬φ)
pour la forme normale négative de la négation de φ, appelée la formule duale de φ.
   À noter que les définitions dans la colonne de gauche de la définition 5.1 sont celles pour des
formules propositionnelles qui n’ont pas de symbole « ¬ » à leur racine, tandis que celles de
la colonne de droite s’occupent des différents cas de formules propositionnelles enracinées par
« ¬ ». En termes algorithmiques, cette mise sous forme normale négative se fait en temps linéaire.
Par les deux lois de dualité de de MoRgan pour ∨ et pour ∧ et par la loi de double négation, la
mise sous forme normale négative préserve la sémantique des formules propositionnelles : φ et
nnf(φ) sont équivalentes.

  Exemple 5.2. La loi de PeiRce ((P ⇒ Q) ⇒ P ) ⇒ P s’écrit ¬(¬(¬P ∨ Q) ∨ P ) ∨ P en
  syntaxe non étendue. Sa forme normale négative est
               nnf(¬(¬(¬P ∨ Q) ∨ P ) ∨ P ) = nnf(¬(¬(¬P ∨ Q) ∨ P )) ∨ P
                                               = (nnf(¬¬(¬P ∨ Q)) ∧ ¬P ) ∨ P
                                               = ((¬P ∨ Q) ∧ ¬P ) ∨ P .
  Sa formule duale est
                          ¬(¬(¬P ∨ Q) ∨ P ) = nnf(¬(¬(¬(¬P ∨ Q) ∨ P ) ∨ P ))
                                               = nnf(¬¬(¬(¬P ∨ Q) ∨ P )) ∧ ¬P
                                               = nnf(¬(¬P ∨ Q) ∨ P ) ∧ ¬P
                                               = (nnf(¬(¬P ∨ Q)) ∨ P ) ∧ ¬P
                                               = ((nnf(¬¬P ) ∧ ¬Q) ∨ P ) ∧ ¬P
                                               = ((P ∧ ¬Q) ∨ P ) ∧ ¬P .

5.1.1. Implémentation des formes normales négatives en Java. Comme d’habitude, nous déclarons         L’implémentation des formes
des méthodes abstraites dans Formule :                                                               normales négatives en OCaml sera faite
                                                                                                     en TP du cours de « programmation
 Formule
                                                                                                     fonctionnelle ».
 public abstract Formule getNNF();
 public abstract Formule getDualNNF();

   La première méthode implémente la colonne de gauche de la définition 5.1, tandis que la se-
conde implémente la colonne de droite. Plus précisément, voici leurs implémentations dans les
sous-classes de Formule :
                                         28                                       INTRODUCTION À LA LOGIQUE


                                              Formule.Et
                                              public Formule      getNNF() {
                                                  return new      Et(phi1.getNNF(), phi2.getNNF());
                                              }
                                              public Formule      getDualNNF() {
                                                  return new      Ou(phi1.getDualNNF(), phi2.getDualNNF());
                                              }
                                              Formule.Ou
                                              public Formule      getNNF() {
                                                  return new      Ou(phi1.getNNF(), phi2.getNNF());
                                              }
                                              public Formule      getDualNNF() {
                                                  return new      Et(phi1.getDualNNF(), phi2.getDualNNF());
                                              }
                                              Formule.Non
                                              public Formule getNNF() {
                                                  return phi1.getDualNNF();
                                              }
                                              public Formule getDualNNF() {
                                                  return phi1.getNNF();
                                              }
                                              Formule.Proposition
                                              public Formule      getNNF() {
                                                  return new      Proposition(nom);
                                              }
                                              public Formule      getDualNNF() {
                                                  return new      Non (new Proposition(nom));
                                              }

                                         5.2. Forme clausale. Une formule propositionnelle en forme normale négative n’a que des opé-
                                         rateurs ∨ et ∧ en guise de nœuds internes, sauf potentiellement des ¬ juste au-dessus des pro-
                                         positions. En utilisant les lois de distributivité, on peut encore normaliser ces formules propo-
                                         sitionnelles pour imposer que tous les ∧ soient au-dessus des ∨ (forme normale conjonctive)
                                         ou vice-versa (forme normale disjonctive). La forme clausale est ensuite simplement une écriture
                                         « ensembliste » d’une formule propositionnelle sous forme normale conjonctive, et est largement
                                         employée dans les algorithmes de recherche de modèle et de recherche de preuve.
                                             Nous allons voir deux techniques pour mettre une formule propositionnelle sous forme nor-
                                         male conjonctive. La première est très simple et s’appuie sur la loi de distributivité de ∨ sur ∧
                                         et construit une formule propositionnelle logiquement équivalente. Cependant, elle peut avoir
                                         un coût prohibitif en pratique, et nous verrons ensuite une technique qui construit une formule
                                         propositionnelle équi-satisfiable, au sens suivant :
                                         Définition 5.3 (équi-satisfiable). Soit φ et ψ deux formules propositionnelles. Elles sont équi-
                                         satisfiables si φ est satisfiable si et seulement si ψ est satisfiable – autrement dit, ∃I . I Z= φ si et
                                         seulement si ∃I ′ . I ′ Z= ψ.
 (DupaRc, 2015, sec. 2.10.2), (David,   5.2.1. Forme clausale logiquement équivalente. Soit φ une formule propositionnelle en forme
NouR et Raffalli, 2003, sec. 7.4.2)
                                         normale négative. En utilisant de manière répétée la loi de distributivité de ∨ sur ∧, on « pousse »
                                         les disjonctions vers le bas et on obtient une mise sous forme normale conjonctive cnf(φ) pour
                                         toute φ en forme normale négative. Le cas le plus important de cette transformation est le suivant :
                                                           cnf(φ ∨ (ψ ∧ ψ ′ )) def
                                                                               = cnf((ψ ∧ ψ ′ ) ∨ φ) = cnf(φ ∨ ψ) ∧ cnf(φ ∨ ψ ′ ) .
                                                                                                     def



                                         À noter que la formule φ est dupliquée lors de cette transformation. Cela explique que la mise
                                         sous forme normale conjonctive peut avoir un coût exponentiel (voir l’exemple 5.5 ci-dessous).
                                       INTRODUCTION À LA LOGIQUE                                         29


Une formule propositionnelle sous forme normale conjonctive s’écrit donc sous la forme
                                       ^     _
                                                  ℓi,j
                                           1≤i≤m 1≤j≤ni

                                                             W
où les ℓi,j sont des littéraux. Les sous-formules Ci def
                                                     =           1≤j≤ni ℓi,j   sont appelées les clauses de
la formule.
k-CNF. Quand les clauses sont des disjonctions d’au plus k littéraux, on dit que la formule est
sous forme « k-CNF ». Par exemple, la formule propositionnelle φex = (P ∨ ¬Q) ∧ P de la
figure 1 est déjà sous forme normale conjonctive : cnf(φex ) = φex . Elle est composée de deux
clauses : P ∨ ¬Q et P ; comme ces deux clauses contiennent chacune au plus deux littéraux, c’est
une formule en 2-CNF.
Forme clausale, forme k-clausale. Par les lois d’idempotence de ∨, de commutativité de ∨ et
d’associativité de ∨, chaque clause peut-être vue comme un ensemble de littéraux, pour lequel
les notations ensemblistes ∈ et ⊆ s’appliquent ; par exemple, la clause P ∨ Q ∨ ¬R peut être
vue comme l’ensemble de littéraux {P, Q, ¬R}. De même, par les lois d’idempotence de ∧, de
commutativité de ∧ et d’associativité de ∧, on peut voir une formule propositionnelle en forme
normale conjonctive comme un ensemble de clauses.
   Pour une formule propositionnelle φ donnée, on note Cl(φ) l’ensemble des clauses de cnf(φ)
(où chaque clause est vue comme un ensemble) ; on appelle cela sa forme clausale. Pour la formule
propositionnelle φex = (P ∨ ¬Q) ∧ P de la figure 1, Cl(φex ) = {{P, ¬Q}, {P }}. L’ensemble de
formules de l’exemple 3.12 peut aussi être vu comme une forme clausale

                 {{P, Q, ¬R}, {Q, R}, {¬P, ¬Q, R}, {¬P, ¬R}, {P, ¬Q}} .

Quand les clauses contiennent au plus k littéraux, on parle aussi de forme k-clausale.

  Exemple 5.4. Comme vu dans l’exemple 5.2, la formule duale de la loi de PeiRce ((P ⇒ Q) ⇒
  P ) ∧ ¬P s’écrit ((P ∧ ¬Q) ∨ P ) ∧ ¬P . La mise sous forme conjonctive produit (P ∨ P ) ∧
  (¬Q ∨ P ) ∧ ¬P et donc la forme clausale {{P, P }, {¬Q, P }, {¬P }}.

  Exemple 5.5. La mise sous forme normale conjonctive peut avoir un coût exponentiel du
  fait des duplications de formules. Par exemple, la formule propositionnelle en forme normale
  disjonctive (P1 ∧ Q1 ) ∨ (P2 ∧ Q2 ) ∨ (P3 ∧ Q3 ) a pour forme normale conjonctive
             (P1 ∨ P2 ∨ P3 ) ∧ (P1 ∨ P2 ∨ Q3 ) ∧ (P1 ∨ Q2 ∨ P3 ) ∧ (P1 ∨ Q2 ∨ Q3 )
           ∧ (Q1 ∨ P2 ∨ P3 ) ∧ (Q1 ∨ P2 ∨ Q3 ) ∧ (Q1 ∨ Q2 ∨ P3 ) ∧ (Q1 ∨ Q2 ∨ Q3 ) .
  Cela correspond à la forme clausale
                   {{P1 , P2 , P3 }, {P1 , P2 , Q3 }, {P1 , Q2 , P3 }, {P1 , Q2 , Q3 },
                    {Q1 , P2 , P3 }, {Q1 , P2 , Q3 }, {Q1 , Q2 , P3 }, {Q1 , Q2 , Q3 }} .
                    W                                                           V         W
  Sa généralisation 1≤i≤n Pi ∧ Qi a pour forme normale conjonctive J⊆{1,...,n} 1≤i≤n ℓJ,i
  où ℓJ,i = Pi si i ∈ J et ℓJ,i = Qi sinon ; c’est une formule contenant 2n clauses, chacune
  contenant n littéraux.
    En conclusion, la mise sous forme normale conjonctive à l’aide de la distributivité de ∨ sur
∧ produit une formule logiquement équivalente et est facile à utiliser sur de petits exemples « à
la main », mais l’exemple 5.5 montre que cette transformation a un coût exponentiel, ce qui la
rend inutilisable sur les formules propositionnelles que l’on souhaite manipuler en pratique. Ce
problème a une solution : calculer une formule sous forme normale conjonctive équi-satisfiable
à la place d’une formule logiquement équivalente ; c’est ce que nous allons voir maintenant.
                                              30                                       INTRODUCTION À LA LOGIQUE


 (PeRifel, 2014, prop. 3-Z),                 5.2.2. Forme clausale équi-satisfiable. En général, étant donnée une formule propositionnelle φ
(Goubault-LaRRecq et MacKie, 1997,
exo. 2.23), (David, NouR et Raffalli,
                                              en forme normale négative, on peut construire en temps linéaire une formule équi-satisfiable
2003, def. 7.4.15), (CaRton, 2008, p. 191),   sous forme clausale.
(HaRRisson, 2009, sec. 2.8)                      Pour chaque sous-formule φ′ de φ, on introduit pour cela une proposition fraîche Qφ′ 6∈ fp(φ)
                                              et on définit la formule propositionnelle
                                                                                  
                                                                                  P
                                                                                                 si φ′ = P ,
                                                                                  
                                                                                  ¬P             si φ′ = ¬P ,
                                                                          ψφ′ def
                                                                                =
                                                                                  Qφ1 ∨ Qφ2 si φ′ = φ1 ∨ φ2 ,
                                                                                  
                                                                                  
                                                                                  
                                                                                     Qφ1 ∧ Qφ2 si φ′ = φ1 ∧ φ2 .
                                                                                                         V
 Dans le cadre de la mise sous forme         La formule propositionnelle désirée est alors ψ def
                                                                                               = Qφ ∧ φ′ sous-formule de φ (Qφ′ ⇒ ψφ′ ). Cette
clausale, cette transformation est parfois
appelée « transformation de Tseitin »,        formule propositionnelle a deux propriétés remarquables :
qui historiquement ne suppose pas φ                (1) elle est facile à mettre sous forme 3-CNF : c’est en effet une conjonction où les implications
sous forme normale négative et utilise
des équivalences Qφ′ ⇔ ψφ′ au lieu                     peuvent être mises sous forme normale conjonctive en utilisant la définition de l’implica-
des implications Qφ′ ⇒ ψφ′ .                           tion et au besoin la distributivité de ∨ sur ∧ : par exemple
                                                                                                                                     
                                                                 (Qφ1 ∧φ2 ⇒ ψφ1 ∧φ2 ) ⇔ (¬Qφ1 ∧φ2 ∨ Qφ1 ) ∧ (¬Qφ1 ∧φ2 ∨ Qφ2 )
                                                       et
                                                               (Qφ1 ∨φ2 ⇒ ψφ1 ∨φ2 ) ⇔ (¬Qφ1 ∨φ2 ∨ Qφ1 ∨ Qφ2 ) .
                                                (2) sa représentation arborescente est de taille linéaire en la taille de la formule φ : il y a une
                                                    implication Qφ′ ⇒ ψφ′ par sous-formule φ′ de φ, et chacune de ces implications est de
                                                    taille bornée par une constante.
                                                                                                                  V
                                              Proposition 5.6. Les formules propositionnelles φ et ψ def= Qφ ∧ φ′ sous-formule de φ (Qφ′ ⇒ ψφ′ )
                                              sont équi-satisfiables.
                                              Démonstration. Supposons φ satisfaite par une interprétation I. On étend cette interprétation en
                                              associant, pour chaque sous-formule φ′ , Jφ′ KI à la proposition Qφ′ : I ′ def = I[Jφ′ KI /Qφ′ ]φ′ sous-formule de φ .
                                                               ′
                                              Montrons que I Z= ψ et donc que ψ est satisfiable. Il suffit de montrer que chacune des clauses
                                              de ψ est satisfaite par I ′ .
                                                 Tout d’abord, comme I Z= φ, I ′ Z= Qφ . Puis on montre par analyse de cas que, pour toute
                                              sous-formule φ′ , on a I ′ Z= Qφ′ ⇒ ψφ′ .
                                                 — cas φ′ = P : on veut montrer que I ′ Z= QP ⇒ P . Supposons pour cela que I ′ Z= QP . Alors
                                                    par définition de I ′ , I Z= P . Toujours par définition de I ′ , I ′ Z= P comme désiré.
                                                 — cas φ′ = ¬P : on veut montrer que I ′ Z= Q¬P ⇒ ¬P . Supposons pour cela que I ′ Z= Q¬P .
                                                    Alors par définition de I ′ , I Z= ¬P . Toujours par définition de I ′ , I ′ Z= ¬P comme désiré.
                                                 — cas φ′ = φ1 ∧ φ2 : on veut montrer que I ′ Z= Qφ′ ⇒ Qφ1 ∧ Qφ2 . Supposons pour cela
                                                    que I ′ Z= Qφ′ . Alors par définition de I ′ , I Z= φ′ , donc I Z= φ1 et I Z= φ2 . Toujours par
                                                    définition de I ′ , on a donc I ′ Z= Qφ1 et I ′ Z= Qφ2 comme désiré.
                                                 — cas φ′ = φ1 ∨ φ2 : on fait une analyse similaire.
                                                   Inversement, supposons ψ satisfaite par une interprétation I ′ . On montre par induction sur
 La preuve de la proposition 5.6             les sous-formules φ′ de φ que I ′ Z= Qφ′ implique I ′ Z= φ′ ; comme I ′ Z= Qφ on aura bien I ′ Z= φ
montre en fait que si ψ est satisfiable,
alors elle l’est par une extension d’une
                                              et donc φ satisfiable.
interprétation qui satisfait φ.                    Pour les cas de base φ′ = P (resp. φ′ = ¬P ), on a par hypothèse I ′ Z= QP ⇒ P (resp.
                                              I ′ Z= Q¬P ⇒ ¬P ) et donc I ′ Z= QP implique I Z= P (resp. I ′ Z= ¬P ). Pour l’étape d’induction,
                                                   — si φ′ = φ1 ∧ φ2 , I ′ Z= Qφ′ implique I ′ Z= Qφ1 et I ′ Z= Qφ2 (car par hypothèse I ′ Z= Qφ′ ⇒
                                                      (Qφ1 ∧ Qφ2 )), qui implique I ′ Z= φ1 et I ′ Z= φ2 (par hypothèse d’induction), qui implique
                                                      I ′ Z= φ′ ;
                                                   — si φ′ = φ1 ∨ φ2 , on fait une analyse similaire.                                             □
                                       INTRODUCTION À LA LOGIQUE                                       31


Corollaire 5.7. Pour toute formule propositionnelle, on peut construire en temps déterministe li-
néaire une formule équi-satisfiable sous forme 3-CNF.

  Exemple
  W          5.8. Reprenons la formule propositionnelle de l’exemple 5.5 pour n = 3 : la formule
    1≤i≤3 P i ∧ Qi est représentée dans la figure 3, où l’on a annoté chacune des sous-formules
  avec des noms de propositions en orange.

                                                       R123
                                                   ∨

                                   R1                             R23
                                        ∧                     ∨

                                  P1        Q 1 R2                       R3
                                                  ∧                     ∧

                                              P2         Q2       P3        Q3
                                                                   W
                FiguRe 3. La formule propositionnelle                   1≤i≤3    Pi ∧ Qi annotée.

  Une formule propositionnelle en forme normale conjonctive équi-satisfiable (légèrement sim-
  plifiée par rapport à la transformation ci-dessus) est
                                                         ^
       R123 ∧ (¬R123 ∨ R1 ∨ R23 ) ∧ (¬R23 ∨ R2 ∨ R3 ) ∧      (¬Ri ∨ Pi ) ∧ (¬Ri ∨ Qi ) ,
                                                                        1≤i≤3

  que l’on peut simplifier en
                                               ^
                       (R1 ∨ R2 ∨ R3 ) ∧                (¬Ri ∨ Pi ) ∧ (¬Ri ∨ Qi ) .
                                              1≤i≤3

  La forme clausale correspondante est
   {{R1 , R2 , R3 }, {¬R1 , P1 }, {¬R1 , Q1 }, {¬R2 , P2 }, {¬R2 , Q2 }, {¬R3 , P3 }, {¬R3 , Q3 }} .

5.2.3. Format DIMACS. Les solveurs SAT emploient un format de fichier standard pour les for-
mules propositionnelles en forme clausale, appelé « format DIMACS » du nom du Center for
Discrete Mathematics and Theoretical Computer Science qui avait organisé les premières compéti-
tions internationales. Voici par exemple comment représenter la forme clausale de l’exemple 5.8
en format DIMACS :
 example-5-8.cnf
 c exemple 5.8 en format DIMACS
 c    table des propositions
 c    R₁ P₁ Q₁ R₂ P₂ Q₂ R₃ P₃ Q₃
 c    1 2 3 4 5 6 7 8 9
 c
 p cnf 9 7
   1 4 7 0
 -1 2 0
 -1 3 0
 -4 5 0
 -4 6 0
 -7 8 0
 -7 9 0

   Le fichier commence par cinq lignes de commentaires, qui débutent par le caractère « c ». En
format DIMACS, les propositions sont représentées par des entiers strictement positifs, et on a
32                                  INTRODUCTION À LA LOGIQUE


ajouté en commentaire comment les noms des propositions de l’exemple 5.8 ont été numérotés
pour faciliter la lecture de l’exemple (mais rien n’impose de le faire). La sixième ligne est le
véritable début du fichier, qui commence par « p cnf » suivi de deux nombres :
   — « 9 » correspond au nombre de propositions utilisées dans la forme clausale ;
   — « 7 » correspond au nombre de clauses.
Les clauses occupent les lignes suivantes. Chaque clause se termine par le caractère « 0 », et
consiste en une séquence de nombres entiers non nuls : un nombre positif n désigne la proposition
numérotée par n, tandis qu’un nombre négatif −n désigne la négation de cette proposition. Par
exemple, à la huitième ligne, « -1 » correspond à ¬R1 , tandis que « 2 » correspond à P1 .

5.2.4. Implémentation de la forme clausale en Java. Voyons comment implémenter la mise sous
forme clausale équi-satisfiable en Java. Dans l’esprit du format DIMACS, nous travaillons mainte-
nant avec une représentation des littéraux comme des entiers. Nous allons représenter une clause
comme un objet de la classe Collection<Integer>. Voici une classe pour les clauses.
     Clause
     import java.util.*;
     public class Clause extends HashSet<Integer> {
         public Clause () {
             super();
         }
               ..
         // .
     }

Une forme clausale peut être représentée comme un objet de Collection<Clause>. Voici une
implémentation possible.
     DIMACS
     import java.util.*;
     public class DIMACS {
         protected int nprops;                  // nombre de propositions
         private Map<String,Integer> propnames; // nom de proposition 7→ entier
         private Collection<Clause> clauses;    // ensemble de clauses
         public DIMACS (int nprops, Map<String,Integer> propnames) {
             this.nprops = nprops;
             this.propnames = propnames;
             this.clauses = new HashSet<Clause>();
         }
         public boolean add(Clause c) {
             return clauses.add(c);
         }
               ..
         // .
     }

   Pour construire un objet de la classe DIMACS depuis une formule propositionnelle, nous allons
travailler sur une formule en forme normale négative. On suppose pour cela et que l’on dispose
des deux méthodes suivantes.
     Formule
     protected abstract int setid(int n, Map<String,Integer> p);
     protected int getid() { /* ... */ }

La première méthode attribue des entiers strictement positifs distincts à chaque nœud interne de
la formule, ainsi qu’à chaque occurrence d’une même proposition ; de plus, la table p est mise à
jour pour se souvenir de quel nom de proposition est associé à quel entier. La seconde retourne
simplement l’entier associé au nœud courant.
                                    INTRODUCTION À LA LOGIQUE                                         33

                                                                            V
  L’étape suivante est de construire la formule propositionnelle ψ = Qφ ∧       φ′ sous-formule de φ (Qφ
                                                                                                           ′   ⇒
ψφ′ ), ce qui est fait par la méthode getDIMACS ci-dessous.
 Formule
 protected abstract void addSousClauses(DIMACS clauses);
 public DIMACS getDIMACS () {
     // passage sous forme normale négative
     Formule nnf = this.getNNF();
     // table qui associera un entier > 0 à chaque proposition
     Map<String,Integer> propnames = new HashMap<String,Integer>();
     // chaque nœud de `nnf' reçoit un entier non nul
     int nprops = nnf.setid(0, propnames);
     // ensemble initialement vide de clauses
     DIMACS dimacs = new DIMACS(nprops, propnames);
                 ∧
     // ajout de   φ′ sous-formule de φ (Qφ ⇒ ψφ )
                                           ′    ′

     nnf.addSousClauses(dimacs);
     // ajout de la clause Qφ
     Clause c = new Clause();
     c.add(Integer.valueOf(nnf.getid()));
     dimacs.add(c);
     return dimacs;
 }

L’idée ici estV
              que Formule.addSousClauses(clauses) ajoute à clauses les clauses de la
conjonction φ′ sous-formule de φ (Qφ′ ⇒ ψφ′ ), et est implémentée différemment selon le type de la
sous-formule φ′ .
 Formule.Et
 protected void addSousClauses(DIMACS clauses) {
     // φ0 = φ1 ∧ φ2
     phi1.addSousClauses(clauses);
     phi2.addSousClauses(clauses);
     // clause ¬Qφ′ ∨ Qφ1
     Set<Integer> c1 = new Clause();
     c1.add(Integer.valueOf(-this.getid()));
     c1.add(Integer.valueOf(phi1.getid()));
     // clause ¬Qφ′ ∨ Qφ2
     Clause c2 = new Clause();
     c2.add(Integer.valueOf(-this.getid()));
     c2.add(Integer.valueOf(phi2.getid()));
     // ajout des nouvelles clauses
     clauses.add(c1);
     clauses.add(c2);
 }
 Formule.Ou
 protected void addSousClauses(DIMACS clauses) {
     // φ0 = φ1 ∨ φ2
     phi1.addSousClauses(clauses);
     phi2.addSousClauses(clauses);
     // clause ¬Qφ′ ∨ Qφ1 ∨ Qφ2
     Clause c = new Clause();
     c.add(Integer.valueOf(-this.getid()));
     c.add(Integer.valueOf(phi1.getid()));
     c.add(Integer.valueOf(phi2.getid()));
     // ajout de la nouvelle clause
                                34                                   INTRODUCTION À LA LOGIQUE


                                         clauses.add(c);
                                     }
                                     Formule.Non
                                     protected void addSousClauses(DIMACS clauses) {
                                         // φ0 = ¬P
                                         // rien à faire
                                     }
                                     Formule.Proposition
                                     protected void addSousClauses(DIMACS clauses) {
                                         // φ0 = P
                                         // rien à faire
                                     }

                                   Enfin, voici une implémentation de toString() qui retourne une chaîne de caractères au
                                format DIMACS.
                                     Clause
                                     public String toString() {
                                         String ret = "";
                                         for (Integer i : this)
                                             ret += i + " ";
                                         return ret + "0";
                                     }
                                     DIMACS
                                     public String toString() {
                                         String out = "";
                                         // commentaires de début du fichier : table des numéros de propositions
                                         out += "c table des propositions\nc   ";
                                         for (Map.Entry<String,Integer> e : propnames.entrySet()) {
                                             String sid = e.getValue().toString();
                                             out += e.getKey();
                                             for (int i = 0; i < sid.length() - e.getKey().length(); i++)
                                                 out += " ";
                                             out += " ";
                                         }
                                         out += "\nc   ";
                                         for (Map.Entry<String,Integer> e : propnames.entrySet()) {
                                             String sid = e.getValue().toString();
                                             out += sid;
                                             for (int i = 0; i < e.getKey().length() - sid.length(); i++)
                                                 out += " ";
                                             out += " ";
                                         }
                                         // en-tête avec les nombres de propositions et de clauses
                                         out += "\np cnf "+ nprops +" "+ this.size() + "\n";
                                         // ajout des clauses au format DIMACS
                                         for (Clause c : clauses)
                                             ret += c + "\n";
                                         return out;
                                     }

 (DupaRc, 2015, sec. 2.10.1)   5.3. Forme normale disjonctive. Toujours en utilisant la distributivité, on obtient une mise
                                sous forme normale disjonctive dnf(φ) pour toute φ en forme normale négative ; le cas le plus
                                important de cette transformation est

                                              dnf(φ ∧ (ψ ∨ ψ ′ )) def
                                                                  = dnf((ψ ∨ ψ ′ ) ∧ φ) = dnf(φ ∧ ψ) ∨ dnf(φ ∧ ψ ′ ) .
                                                                                        def
                                       INTRODUCTION À LA LOGIQUE                                       35

                                                  W          V
Le résultat est une formule propositionnelle 1≤i≤m 1≤j≤ni ℓi,j où les ℓi,j sont des littéraux.
   Étant donnée une telle formule, déterminer si elle est satisfiable peut être effectuéVen temps li-
néaire (en supposant un hachage parfait des noms de propositions) : une conjonction 1≤j≤ni ℓi,j
de littéraux est en effet satisfiable si et seulement si elle ne contient pas à la fois une proposition P
et sa négation ¬P .                                                                                          Une alternative pour calculer une
                                                                                                            forme normale disjonctive d’une
   Comme la mise sous forme normale conjonctive, cette transformation peut avoir un coût ex-                formule φ est de calculer sa table de
ponentiel. Cependant, et contrairement à ce que nous venons de voir pour la forme normale                   vérité et d’en déduire sa forme normale
conjonctive en section 5.2.2, on ne peut pas espérer avoir un algorithme en temps polynomial                disjonctive complète comme cela avait
                                                                                                            été fait dans la preuve du théorème 3.8
pour calculer une formule propositionnelle sous forme normale disjonctive équi-satisfiable avec             de complétude fonctionnelle ; voir
une formule donnée en entrée (sous réserve que P 6= NP, une notion qui sera vue en cours de                 l’exercice 3 du TD n°3. Cette forme
« calculabilité et complexité » en M1), puisque résoudre la satisfiabilité de cette forme normale           complète est canonique : deux formules
                                                                                                            logiquement équivalentes ont la même
disjonctive se fait ensuite en temps polynomial.                                                            forme normale disjonctive complète. La
                                                                                                            forme normale disjonctive complète est
                                                                                                            assez peu utile en pratique puisque le
                                                                                                            calcul de la table de vérité prend
                                                                                                            systématiquement un temps exponentiel
                                                                                                            en le nombre de propositions |fp(φ)|.
36                                       INTRODUCTION À LA LOGIQUE


                                            6. ModÉlisation

      Résumé. De nombreux problèmes informatiques peuvent être exprimés comme la sa-
      tisfiabilité d’une formule propositionnelle. Les solveurs SAT sont des logiciels dédiés à
      ce problème, qui prennent en entrée une formule propositionnelle sous forme normale
      conjonctive (écrite au format DIMACS), et cherchent à répondre si la formule est satis-
      fiable ou non.

6.1. Utilisation de solveurs SAT. Les solveurs SAT sont des programmes qui déterminent si
une formule propositionnelle φ donnée est satisfiable ou non, et si oui, fournissent une interpré-
tation I qui satisfait la formule, c’est-à-dire telle que I Z= φ. Les solveurs SAT prennent en entrée
une forme clausale Cl(φ) au format DIMACS (c.f. section 5.2.3).

6.1.1. Utilisation de MiniSAT. MiniSAT (http://minisat.se/) est un solveur SAT facile à ins-
taller puisqu’il existe des paquets pour distributions GNU/Linux. Une invocation sur le fichier DI-
MACS de la section 5.2.3 est « minisat exemple-5-8.cnf exemple-5-8.modele ». Dans
le cas où l’ensemble de clauses fourni en entrée est satisfiable, une interprétation partielle est
retournée :
     example-5-8.modele
     SAT
     -1 2 3 -4 5 6 7 8 9 0

L’interprétation est retournée sous la forme d’une clause DIMACS, où les propositions associées
à 1 apparaissent comme des entiers positifs et celles associées à 0 comme des entiers négatifs. En
l’occurrence, l’interprétation en termes de l’exemple 5.8 est
                      [0/R1 , 1/P1 , 1/Q1 , 0/R2 , 1/P2 , 1/Q2 , 1/R3 , 1/P3 , 1/Q3 ] .
En terme de la formule originale de l’exemple 5.5, nous avons vu dans la preuve de la propo-
sition 5.6 qu’il suffit d’ignorer les propositions fraîches ajoutées par la mise sous forme équi-
satisfiable ; l’interprétation partielle suivante est donc un modèle de (P1 ∧ Q1 ) ∨ (P2 ∧ Q2 ) ∨
(P3 ∧ Q3 ) :
                               [1/P1 , 1/Q1 , 1/P2 , 1/Q2 , 1/P3 , 1/Q3 ] .

6.1.2. Utilisation de Sat4j dans un programme Java. Sat4j (http://www.sat4j.org/) est un sol-
veur SAT plus récent écrit en Java, qui intègre les heuristiques utilisées par de nombreux sol-
veurs comme MiniSAT et Glucose. Il peut être appelé directement depuis un programme Java
qui construit les clauses successives comme des objets de type int[]. Voici comment appeler
Sat4j depuis notre classe DIMACS :
     DIMACS
     import org.sat4j.minisat.*;
     import org.sat4j.specs.*;
     import org.sat4j.core.*;
        ..
     // .
             private int[] interpretation;
             public int[] modele() {
                 return interpretation;
             }
             public boolean satisfiable() {
                 ISolver solver = SolverFactory.newDefault();
                 // initialisation du solver
                 solver.newVar(nprops);
                 solver.setExpectedNumberOfClauses(clauses.size());
                                           INTRODUCTION À LA LOGIQUE                                               37


              try {
                  for (Clause c : clauses) // ajout des clauses
                      solver.addClause(new VecInt(c.stream()
                          .mapToInt(i->i).toArray()));
                  IProblem problem = solver;
                  boolean ret = problem.isSatisfiable();
                  if (ret)
                      interpretation = problem.model();
                  return ret;
              } catch (ContradictionException e) {
                  return false;
              } catch (TimeoutException e) {
                  System.err.println("timeout!");
                  return false;
              }
        }




                           NT                                                       NT
                                         QLD
                                                                                                  QLD
            WA
                                                                   WA
                             SA
                                           NSW                                      SA                NSW

                                         VIC                                                       VIC

                                            TAS                                                      TAS



                 FiguRe 4. La carte des territoires de l’Australie9 et le graphe associé.
6.2. Exemple de modélisation : coloration de graphe. Les solveurs SAT sont particulière-
ment utiles pour des problèmes combinatoires pour lesquels on ne connaît pas d’algorithme effi-
cace dans le pire des cas – et on soupçonne même qu’il n’existe pas de tels algorithmes. Il s’avère
en effet que les solveurs SAT permettent de résoudre ces problèmes dans les cas qui apparaissent
en pratique.
   Notre problème est le suivant : est-il possible de colorier la carte de l’Australie (voir la carte 9)
avec seulement trois couleurs, disons rouge, vert et bleu, de telle sorte que deux territoires adja-
cents aient des couleurs différentes ? Ce problème est en réalité un problème de coloriage d’un
graphe non orienté comme illustré à droite de la figure 4 : peut-on associer une couleur à chaque
sommet du graphe, de telle sorte que deux sommets adjacents n’aient pas la même couleur ? La
réponse est « oui » et un tel coloriage est donné dans la figure 5.
   Notre objectif est cependant de trouver automatiquement une telle solution pour n’importe
quel graphe fini non orienté. Voyons comment procéder pour notre exemple.

    9. Auteur de la carte à gauche de la figure 4 : Lokal_Profil, licence [CC BY-SA 3.0], via Wikimedia Commons. Les
territoires sont : Western Australia (WA), Northern Territory (NT), South Australia (SA), Queensland (QLD), New South
Wales (NSW), Victoria (VIC) et Tasmania (TAS) ; on a ignoré le petit territoire de la capitale.
38                                       INTRODUCTION À LA LOGIQUE




                           NT                                              NT
                                       QLD
                                                                                       QLD
               WA
                                                             WA
                             SA
                                         NSW                                SA             NSW

                                       VIC                                              VIC

                                         TAS                                              TAS



          FiguRe 5. Un coloriage de la carte des territoires de l’Australie9 et du graphe associé.

Choix des propositions. Nous travaillons avec des propositions Pv,c où v est un sommet du graphe,
c’est-à-dire un territoire dans {WA, NT, SA, QLD, NSW, VIC, TAS} et c est une couleur dans
{R, V, B}. Cela signifie qu’une interprétation I de ces propositions décrira une relation incluse
dans V × C : pour chaque paire (v, c), I va indiquer si le sommet v du graphe est colorié par la
couleur c.
   Voici le préambule d’un fichier au format DIMACS où on a indiqué en commentaire quel entier
strictement positif est associé à chacune des paires (v, c) ∈ V × C.
     coloriage.cnf
     c table des propositions
     c WA,R WA,V WA,B NT,R NT,V NT,V            SA,R SA,V SA,B QLD,R QLD,V QLD,B
     c 1     2    3    4    5   6               7    8    9    10    11    12
     c NSW,R NSW,V NSW,B VIC,R VIC,V            VIC,B TAS,R TAS,V TAS,B
     c 13      14   15    16   17               18     19   20    21
     p cnf 21 55

    Nous allons maintenant construire une formule propositionnelle qui sera satisfiable si et seule-
ment s’il existe un coloriage du graphe. Toutes les interprétations I des propositions de la forme
Pv,c pour v ∈ {WA, NT, SA, QLD, NSW, VIC, TAS} et c ∈ {R, V, B} ne sont pas des coloriages.
Plusieurs conditions doivent en effet être remplies.
Au moins une couleur par sommet. Nous ne devons pas laisser un territoire de l’Australie non colo-
rié. Cela correspond à vérifier que pour chaque territoire v ∈ {WA, NT, SA, QLD, NSW, VIC, TAS},
au moins l’une des propositions parmi Pv,R , Pv,V et Pv,B est vraie dans I, soit la formule pro-
positionnelle Pv,R ∨ Pv,V ∨ Pv,B . Voici les clauses correspondantes au format DIMACS.
     coloriage.cnf
     c    au   moins une couleur par sommet
      1    2    3 0
      4    5    6 0
      7    8    9 0
     10   11   12 0
     13   14   15 0
     16   17   18 0
     19   20   21 0
                                         INTRODUCTION À LA LOGIQUE                                   39


Au plus une couleur par sommet. En effet, par exemple, le territoire de New South Wales ne peut
pas être colorié à la fois en rouge et en vert. Cela correspond à vérifier que, pour chaque territoire
v ∈ {WA, NT, SA, QLD, NSW, VIC, TAS} et pour chaque paire de couleurs distinctes c 6= c′
issues de {R, V, B}, on n’ait pas à la fois Pv,c et Pv,c′ vraies dans I. Cela correspond à la formule
propositionnelle ¬(Pv,c ∧ Pv,c′ ), qui est équivalente à la clause ¬Pv,c ∨ ¬Pv,c′ . Voici les clauses
correspondantes au format DIMACS pour WA, NT et SA.
 coloriage.cnf
 c     au plus une couleur par sommet
     -1 -2 0
     -1 -3 0
     -2 -3 0
     -4 -5 0
     -4 -6 0
     -5 -6 0
     -7 -8 0
     -7 -9 0
     -8 -9 0

   Avec ces deux types de clauses combinées, on garantit en fait qu’il existe une fonction entre
les sommets du graphe et les couleurs.
Couleurs distinctes pour sommets adjacents. Enfin, nous devons vérifier que pour toute paire (u, v)
de territoires adjacents, leurs couleurs associées sont distinctes, c’est-à-dire que I vérifie ¬(Pu,c ∧
Pv,c ) pour tout arête (u, v) et toute couleur c ; cela s’écrit sous forme clausale comme ¬Pu,c ∨
¬Pv,c . Par exemple, pour les arêtes (WA, NT), (WA, SA) et (NT, SA), on aura au format DIMACS :
 coloriage.cnf
 c  pas la même couleur sur deux sommets adjacents
 c  arête (WA,NT)
  -1 -4 0
  -2 -5 0
  -3 -6 0
 c arête (WA,SA)
  -1 -7 0
  -2 -8 0
  -3 -9 0
 c arête (NT,SA)
  -4 -7 0
  -5 -8 0
  -6 -9 0

   En général, pour un graphe fini non orienté G = (V, E) et un ensemble de couleurs C, le
graphe est coloriable si et seulement si la formule propositionnelle suivante est satisfiable :
         ^ _                 ^ ^                            ^ ^                        
                  Pv,c ∧            (¬Pv,c ∨ ¬Pv,c′ ) ∧                (¬Pu,c ∨ ¬Pv,c ) .       (4)
          v∈V c∈C            v∈V c̸=c′                         (u,v)∈E c∈C

6.3. Exemple de modélisation : dépendances logicielles. Voici un problème concret en in-
formatique : comment assurer que toutes les dépendances d’un logiciel soient correctement ins-
tallées et configurées ? Cela touche les programmes installés sur un système, par exemple via
un gestionnaire de paquets comme apt sur les systèmes Debian Linux et apparentés (comme
Ubuntu), mais aussi les bibliothèques nécessaires pour compiler du code, par exemple via autoconf
pour C/C++, maven pour Java, opam pour OCaml, pip pour Python, etc. Des problèmes sur-
gissent assez vite avec tous ces systèmes du fait de conflits entre certaines versions de dépen-
dances qui ne peuvent pas être installées simultanément ; on parle couramment de « dependency
hell ».
                              40                                  INTRODUCTION À LA LOGIQUE


 (Mancinelli et al., 2006)      Comme nous allons le voir, on peut résoudre ces problèmes de dépendances à l’aide d’un
                              modélisation en logique propositionnelle et d’un solveur SAT ; c’est d’ailleurs ce qui est fait au
                              sein du logiciel Eclipse à l’aide de Sat4j pour la gestion des plugins.
                                 Voici un scénario concret de problème de dépendances avec le système apt. Ce genre de
                              problèmes peut cependant survenir avec la plupart des systèmes de gestion de dépendances. Si
                              vous avez un système Linux basé sur Debian, vous pouvez même tester ce scénario en ajoutant les
                              deux lignes suivantes à /etc/apt/sources.list avant de lancer sudo apt-get update :
                                   /etc/apt/sources.list
                                   deb [trusted=yes] https://www.irif.fr/~schmitz/teach/2020_lo5/debs ./
                                   deb [trusted=yes] https://www.irif.fr/~schmitz/teach/2020_lo5/debs-old ./

                                 Un paquet logiciel Debian contient des méta-informations ; voici par exemple les informations
                              du paquet foo disponible aux adresses ci-dessus :
                                   apt-cache show foo
                                   Package: foo
                                   Version: 1.0
                                   Architecture: all
                                   Maintainer: anon
                                   Depends: bar (>= 2.1), baz | qux
                                   Filename: ./foo-1.0.deb
                                   Size: 704
                                   MD5sum: b898166d798077e84317686d66d259e5
                                   SHA1: e4c056543faf48b4ba97fd2b113fd05397ea8a7d
                                   SHA256: 591489045bf2ce5bc7c5d09cb3e9dd6416939ee23a38f4cd3ecba80889d717f7
                                   Description: dummy foo-1.0 package
                                   Description-md5: c777289cc850cccf5b3b07c9c31902f2

                              Ce qui nous intéresse est le nom du paquet (foo), sa version (1.0), et ses dépendances (bar (>=
                              2.1), baz | qux) : le paquet foo dans sa version 1.0 dépend du paquet bar dans une version
                              supérieure ou égale à 2.1, et soit du paquet baz soit du paquet qux, sans contrainte de version.
                                 À noter qu’un même paquet peut être disponible en plusieurs versions :
                                   apt-cache show quxx
                                   Package: quxx
                                   Version: 1.4
                                   Architecture: all
                                   Maintainer: anon
                                   Conflicts: quz
                                   Filename: ./quxx-1.4.deb
                                   Size: 664
                                   MD5sum: ce56ed662469facfc2af728e75262849
                                   SHA1: f1a91faf93a68b8eb626032607d148b494731124
                                   SHA256: b7c4498b4b16c84e9315cf2ecea613ec11d943564ff2ef7d0c8b762fe10eced2
                                   Description: dummy quxx-1.4 package
                                   Description-md5: 0d88c6b67d64002702518fb93a4ebfee

                                   Package: quxx
                                   Version: 1.3
                                   Architecture: all
                                   Maintainer: anon
                                   Filename: ./quxx-1.3.deb
                                   Size: 680
                                   MD5sum: 3553398d7d504fd1993c719436709f68
                                   SHA1: c3bac75a683808f515656eaa3cf6460d71ab933b
                                        INTRODUCTION À LA LOGIQUE                                41


 SHA256: f58ac7d4ad72bf47b2ed4afaf97f9770f048076cf17ef53dae523cd8d66ac25a
 Description: dummy quxx-1.3 package
 Description-md5: 94ff5e3c00228e821c8163972d5fae10

Ici, quxx existe en version 1.3 et en version 1.4. Ces paquets n’ont pas de dépendances, mais
quxx version 1.4 est en conflit avec quz : il ne peut pas être installé en même temps qu’aucune
version de quz. Notons que les dépendances et conflits peuvent varier d’une version à l’autre d’un
même paquet. La figure 6 résume les dépendances (en orange) et conflits (en rouge pointillé) entre
les paquets de notre scénario.

                                               foo
                                                   1.0


                                   ≥ 2.1                       |

                             bar                         baz           qux
                             2.1                         2.2        1.4    1.3



                               = 2.1               = 2.2           ≥ 1.4   ≥ 1.3


                                         quz                          quxx
                                       2.1   2.2                    1.4    1.3



          FiguRe 6. Les dépendances (en orange) et conflits (en rouge) entre paquets.

   Si on essaie d’installer foo, on obtient un message d’erreur qui nous renseigne assez peu :
 sudo apt-get install --dry-run foo
 The following packages have unmet dependencies:
  foo : Depends: bar (>= 2.1) but it is not going to be installed
 E: Unable to correct problems, you have held broken packages.

   Si on analyse la situation à l’aide du graphe de la figure 6, on peut voir que, pour pouvoir
installer foo, on doit installer bar, et que ce dernier exige l’installation de quz dans sa ver-
sion 2.1. On doit aussi installer baz ou qux. Le paquet baz exige l’installation de quz dans
sa version 2.2 : ceci est incompatible avec quz-2.1 qui est une version différente du même
paquet, donc on ne peut pas installer bar et baz en même temps. Il reste donc qux, mais on
voit qu’il dépend de quxx qui dans sa version 1.4 est en conflit avec quz, donc on ne peut pas
installer bar et qux-1.4 en même temps. Ceci explique le message d’erreur d’apt. Il y aurait
cependant une solution si on se permettait d’installer des paquets dans des versions qui ne sont
pas les plus récentes : installer bar-2.1, quz-2.1, qux-1.3 et quxx-1.3.

   Voyons maintenant comment modéliser notre scénario en logique propositionnelle. Formel-
lement, on dispose d’un ensemble de paquets versionnés
D def
  = {foo-1.0, bar-2.1, baz-2.2, qux-1.3, qux-1.4, quxx-1.3, quxx-1.4, quz-2.1, quz-2.2}
et on cherche une solution, c’est-à-dire un sous-ensemble E ⊆ D tel que E contienne foo-1.0
le paquet que nous voulons installer, et tel que les dépendances et conflits de la figure 6 soient
respectés.
Choix des propositions. Nous allons utiliser des propositions Qp pour chaque paquet versionné
p ∈ D. Une interprétation I de ces propositions définit alors le sous-ensemble {p | QIp =
1} ⊆ D. Les contraintes que nous allons écrire assureront ensuite que foo-1.0 appartienne au
sous-ensemble ainsi défini et que les dépendances et conflits soient respectés.
   Voici le préambule d’un fichier au format DIMACS où on a indiqué en commentaire quel entier
strictement positif est associé à chaque paquet versionné p ∈ D.
42                                   INTRODUCTION À LA LOGIQUE


     dependances.cnf
     c Table des propositions : une proposition par version de paquet
     c foo-1.0 bar-2.1 baz-2.2 qux-1.3 qux-1.4 quz-2.1 quz-2.2 quxx-1.3 quxx-1.4
     c    1       2       3       4       5       6       7        8        9
     c
     p cnf 9 12

   Nous allons maintenant écrire une formule propositionnelle qui sera satisfaite par une inter-
prétation I si et seulement si I définit une solution.
Le paquet foo-1.0 appartient à la solution. On garantit cela à l’aide de la formule Qfoo-1.0 . En
format DIMACS :
     dependances.cnf
     c on souhaite installer foo-1.0
     1 0

Dépendances. Dans les cas les plus simples, pour chaque dépendance p → p′ indiquée en orange
dans la figure 6, on va ajouter une contrainte de la forme Qp ⇒ Qp′ : si p est installé, alors on
doit aussi installer p′ . Cela donne par exemple la formule Qfoo-1.0 ⇒ Qbar-2.1 .
    De manière générale, une dépendance peut mener à une disjonction de paquets versionnés, et
la contrainte logique correspondante est alors une implication d’une disjonction des propositions
correspondantes ; par exemple Qfoo-1.0 ⇒ (Qbaz-2.2 ∨ Qqux-1.3 ∨ Qqux-1.4 ).
    Ces deux contraintes peuvent être mises sous forme normale conjonctive comme ¬Qfoo-1.0 ∨
Qbar-2.1 et ¬Qfoo-1.0 ∨Qbaz-2.2 ∨Qqux-1.3 ∨Qqux-1.4 ; voici leur traduction au format DIMACS :
     dependances.cnf
     c foo-1.0 dépend de : bar (>= 2.1), baz | qux
     -1 2 0
     -1 3 4 5 0

Les autres dépendances sont traitées de manière similaire.
Conflits déclarés. Il y a un conflit déclaré dans la figure 6 : quxx-1.4 est en conflit avec quz. On
peut modéliser cela par la formule Qqux-1.4 ⇒ ¬(Qquz-2.1 ∨Qquz-2.2 ) : si on installe quxx-1.4,
alors aucune version de quz ne peut être installée. Cette formule est logiquement équivalente à
la formule (¬Qqux-1.4 ∨ ¬Qquz-2.1 ) ∧ (¬Qqux-1.4 ∨ ¬Qquz-2.2 ) sous forme normale conjonctive,
et voici sa traduction au format DIMACS :
     dependances.cnf
     c quxx-1.4 est en conflit avec : quz
     -9 -6 0
     -9 -7 0

Conflits entre versions d’un même paquet. Enfin, il faut ajouter les conflits implicites : deux ver-
sions différentes d’un même paquet ne peuvent pas coexister. Par exemple, pour qux, cela re-
vient à la formule propositionnelle ¬(Qqux-1.3 ∧ Qqux-1.4 ), qui est logiquement équivalente à
¬Qqux-1.3 ∨ ¬Qqux-1.4 sous forme normale conjonctive ; voici sa traduction au format DIMACS :
     dependances.cnf
     c on ne peut pas avoir deux versions de qux
     -4 -5 0

Des contraintes similaires doivent être écrites pour quxx et quz.




   Si on appelle un solveur SAT comme MiniSAT sur le fichier DIMACS complet, celui-ci trouve
un modèle
                                    INTRODUCTION À LA LOGIQUE                            43


 dependances.modele
 SAT
 1 2 -3 4 -5 6 -7 8 -9 0

Cette interprétation satisfait nos dépendances et conflits et correspond à la solution
                      {foo-1.0, bar-2.1, qux-1.3, quxx-1.3, quz-2.1} .
La commande sudo apt-get install quxx=1.3 qux=1.3 quz=2.1 bar=2.1 foo
fonctionne maintenant et permet d’installer foo.
                                              44                                         INTRODUCTION À LA LOGIQUE


                                                                             7. SatisfiabilitÉ et RecheRche de modÈle

                                                    Résumé. Une manière d’implémenter un solveur SAT est d’utiliser l’algorithme DPLL
                                                    dû à Davis, Putnam, Logemann et Loveland. Cet algorithme travaille par simplification
                                                    d’ensembles de clauses : la simplification d’un ensemble de clauses par un littéral ℓ élimine
                                                    les clauses qui contiennent ℓ et retire ℓ̄ des clauses restantes. L’algorithme DPLL simplifie
                                                    en priorité par les littéraux unitaires (ℓ est unitaire s’il existe une clause qui ne contient que
                                                    ce littéral) et les littéraux purs (ℓ est pur si le littéral ℓ̄ n’apparaît nulle part dans l’ensemble
                                                    de clauses).

 Voir (Knuth, 2008, sec. 7.1.1),                  Le problème de satisfiabilité est le problème de décision suivant.
(Knuth, 2015, sec. 7.2.2.2) et (KRoening
et StRichman, 2016, ch. 2) pour une           Problème (SAT).
présentation des aspects algorithmiques         entrée : une formule propositionnelle φ
du problème de satisfiabilité, et (PeRifel,
2014, thm. 3-V), (ARoRa et BaRaK, 2009,         question : φ est-elle satisfiable ?
thm. 2.10), (PapadimitRiou, 1993,
thm. 8.2), (CaRton, 2008, thm. 4.19) ou
                                                 Ce problème est résolu par les solveurs SAT ; de plus, si la réponse au problème est positive,
(Lassaigne et Rougemont, 2004,                ces solveurs fournissent une interprétation partielle I telle que I Z= φ.
thm. 11.1) sur sa complexité et en               Dans de nombreuses utilisations de SAT, telles que les modélisations de la section 6, on suppose
particulier le théorème de CooK–Levin.
                                              de plus que la formule φ est sous forme clausale, voire k-clausale pour un certain k fixé, auquel
                                              cas on parlera plutôt de « kSAT ». Comme vu dans le corollaire 5.7, SAT et 3SAT sont deux
                                              problèmes essentiellement équivalents.


                                              7.1. Recherche de modèle par énumération. On peut résoudre automatiquement le pro-
                                              blème SAT : puisque par la propriété 3.3, il suffit de trouver une interprétation partielle de do-
 On ne connaît pas d’algorithme pour         maine fp(φ) qui satisfait φ, on peut simplement énumérer les 2|fp(φ)| interprétations possibles.
SAT qui travaille en temps polynomial
dans le pire des cas – on soupçonne
                                              En termes de tables de vérité, cela revient à construire la table de φ et de tester si au moins une
même qu’un tel algorithme en temps            ligne met φ à 1.
sous-exponentiel n’existe pas, ce qui est
appelé l’« exponential time                        Exemple 7.1. Reprenons la forme clausale de l’exemple 3.12
hypothesis ».
                                                                   F = {{P, Q, ¬R}, {Q, R}, {¬P, ¬Q, R}, {¬P, ¬R}, {P, ¬Q}} .
                                                   Sa table de vérité est donnée dans la table 6.

                                                                  Table 6. La table de vérité de l’ensemble de clauses de l’exemple 3.12.

                                                             P      Q   R   {P, Q, ¬R}     {Q, R}    {¬P, ¬Q, R}      {¬P, ¬R}      {P, ¬Q}     F
                                                              1     1   1        1            1             1              0            1       0
                                                              1     1   0        1            1             0              1            1       0
                                                              1     0   1        1            1             1              0            1       0
                                                              1     0   0        1            0             1              1            1       0
                                                              0     1   1        1            1             1              1            0       0
                                                              0     1   0        1            1             1              1            0       0
                                                              0     0   1        0            1             1              1            1       0
                                                              0     0   0        1            0             1              1            1       0

                                                   On voit dans cette table que chaque ligne, c’est-à-dire chaque interprétation partielle de do-
                                                   maine {P, Q, R}, contient au moins une entrée 0 pour une des clauses de F . Par conséquent,
                                                   la colonne pour F ne contient que des 0 : cette forme clausale est insatisfiable.

                                                 Plutôt que d’écrire explicitement la table de vérité, on peut aussi représenter les interprétations
                                              partielles de domaine fp(φ) sous la forme d’un arbre : pour chaque proposition P ∈ fp(φ), on
                                          INTRODUCTION À LA LOGIQUE                                      45


branche sur les deux choix I Z= ¬P et I Z= P . L’arbre correspondant pour l’exemple 7.1 est donné
dans la figure 7.



                                     ¬P                               P


              ¬Q               Q                                          ¬Q              Q



    ¬R        R                ¬R           R               ¬R            R                ¬R      R


{Q, R}       {P, Q, ¬R}    {P, ¬Q}          {P, ¬Q}      {Q, R}           {¬P, ¬R}   {¬P, ¬Q, R}   {¬P, ¬R}




                   FiguRe 7. Un arbre de recherche de modèle pour l’exemple 7.1.



   Chaque branche de l’arbre décrit une interprétation partielle sous la forme d’une liste de lit-
téraux, et l’on a décoré chaque feuille de l’arbre par une clause non satisfaite par cette interpré-
tation ; par exemple, la branche la plus à gauche étiquetée par ¬P, ¬Q, ¬R correspond à l’inter-
prétation partielle [0/P, 0/Q, 0/R] (qui est la dernière ligne de la table 6), et cette interprétation
ne satisfait pas la clause {Q, R}.


   Cette représentation sous forme d’arbre de recherche a deux intérêts :
   — d’une part, elle est moins longue à écrire à la main qu’une table de vérité,
   — d’autre part, elle suggère un algorithme récursif qui explore l’arbre pour tester si une for-
       mule sous forme clausale est satisfiable ou non : chaque nœud interne de l’arbre correspond
       à un appel récursif d’une fonction pour tester la satisfiabilité, et aux feuilles on vérifie s’il
       existe au moins une clause satisfaite par l’interprétation partielle pour cette branche.
   À noter que, dans le cas de formules propositionnelles sous forme clausale, il est très aisé de
vérifier si une clause C est satisfaite ou non par une interprétation : I Z= C si et seulement s’il
existe ℓ ∈ C tel que I Z= ℓ. Cela suggère le pseudo-code suivant pour évaluer la valeur de vérité
d’une clause C sous une interprétation I :

  Fonction evalueclause(C, I )
   1 pour tous les ℓ ∈ C faire
   2     si I Z= ℓ alors retourner 1
    3    retourner 0

Par suite, pour une formule propositionnelle sous forme clausale, c’est-à-dire un ensemble de
clauses F , I Z= F si et seulement si ∀C ∈ F , I Z= C :

  Fonction evalueclausal(F , I )
   1 pour tous les C ∈ F faire
   2     si not evalueclause(C, I) alors retourner 0
    3    retourner 1

   Le pseudo-code qui suit décrit l’algorithme récursif suggéré par les arbres de recherche, qui
prend en entrée un ensemble de clauses F et une interprétation partielle I de domaine initiale-
ment vide.
                                        46                                    INTRODUCTION À LA LOGIQUE


                                             Fonction satisfiable(F , I )
                                              1 si dom(I) = fp(F ) alors
                                              2     retourner evalueclausal(F, I)
                                              3    sinon
                                               4      choisir P ∈ fp(F ) \ dom(I)
                                               5      retourner satisfiable(F, I[1/P ]) or satisfiable(F, I[0/P ])

 L’implémentation de la recherche de   7.1.1. Implémentation de la recherche par énumération en Java.
modèle par énumération en OCaml sera    Propositions et littéraux. Dans l’esprit du format DIMACS, chaque proposition Pi va être associée
vue en TP du cours « programmation
fonctionnelle ».
                                        à un entier i>0 ; le littéral Pi est alors représenté par l’entier i et le littéral ¬Pi par l’entier -i.
                                        Interprétations. Une interprétation est I maintenant représentée comme un tableau d’entiers ;
                                        si nprops est le nombre de propositions, alors interpretation sera un tableau de longueur
                                        nprops. L’index dans ce tableau d’un littéral ℓ représenté par un objet l de type Integer est
                                        fourni par la méthode suivante.
                                             public static int index(Integer l) {
                                                 int i = l.intValue();
                                                 return (i > 0)? i-1: -i-1;
                                             }

                                        Pour un littéral ℓ représenté par un objet l de type Integer, I Z= ℓ se vérifie en testant si
                                        interpretation[index(l)] == l.intValue().
                                        Clauses. Rappelons que nous représentons les clauses comme des objets de type Clause, lequel
                                        implémente Collection<Integer>. Une interprétation I est un modèle d’une clause C si et
                                        seulement si c’est un modèle d’au moins un littéral ℓ de C : I Z= C si et seulement si ∃ℓ ∈ C.I Z= ℓ.
                                        Nous pouvons implémenter cela dans notre classe Clause par la méthode suivante.
                                             Clause
                                             public boolean evalue(int[] interpretation) {
                                                 return this.stream().anyMatch(
                                                     l -> interpretation[index(l)] == l.intValue());
                                             }

                                        Solveur SAT naïf. Voici enfin le code d’un solveur SAT naïf qui implémente la recherche de mo-
                                        dèle par énumération. Ce solveur a accès aux trois champs suivants.
                                             SolveurNaif
                                             protected int nprops;
                                             private Collection<Clause> clauses;
                                             private int[] interpretation;

                                           La méthode satisfiable construit successivement – via des appels récursifs – toutes les
                                        interprétations possibles des propositions, et retourne vrai dès qu’elle trouve un modèle.
                                             SolveurNaif
                                             private boolean satisfiable(int i) {
                                                 // interprétation de toutes les propositions
                                                 if (i == nprops)
                                                     // est-ce que toutes les clauses sont satisfaites ?
                                                     return clauses.stream().allMatch(c-> c.evalue(interpretation));
                                                 else {
                                                     // branchement :
                                                     // - tente de mettre la ième proposition à 1
                                                     interpretation[i] = i+1;
                                                     if (satisfiable(i+1))
                                     INTRODUCTION À LA LOGIQUE                                     47


                 return true;
             // - restaure l'interprétation
             for (int j = i+1; j < nprops; j++)
                 interpretation[j] = j+1;
             // - tente de mettre la ième proposition à 0
             interpretation[i] = -i-1;
             return satisfiable(i+1);
     }
 }
 public boolean satisfiable() {
     return satisfiable(0);
 }

   Cette implémentation naïve d’un solveur SAT suffit pour des petits exemples, mais prend plus
d’une seconde sur ma machine pour résoudre le problème de coloriage de la section 6.2.

7.2. Recherche de modèle par simplification. Un défaut de l’algorithme par énumération
de la section précédente est qu’il attend d’avoir construit une interprétation partielle de do-
maine fp(φ) avant de tester si les clauses sont satisfaites. Pourtant, il est parfois possible de
répondre plus tôt : par exemple, dans l’arbre de la figure 7, le nœud atteint en suivant le chemin
¬P, Q correspond à une interprétation partielle [0/P, 1/Q] qui ne satisfait pas la clause {P, ¬Q},
quel que soit le choix de l’interprétation de la proposition R.
   Cependant, évaluer toutes les clauses C d’une formule à chaque nœud interne de l’arbre d’in-
terprétation partielle I telle que fp(C) ⊆ dom(I) serait coûteux. À la place, l’idée de la recherche
de modèle par simplification est d’évaluer « partiellement » l’ensemble des clauses au fur et à
mesure de l’exploration de l’arbre.

7.2.1. Simplification de formes clausales. La recherche de modèle par simplification simplifie un
ensemble de clauses propositionnelles S jusqu’à obtenir une clause vide – auquel cas S n’était pas
satisfiable – ou un ensemble vide de clauses – auquel cas S était satisfiable. Soit S un ensemble
de clauses. On définit la simplification de S par un littéral ℓ comme l’ensemble de clauses
                                                                    
                    S[>/ℓ] def
                            = {C | (C ∪ {ℓ}) ∈ S ou ℓ 6∈ C ∈ S et ℓ 6∈ C}

où l’on a éliminé les clauses de S contenant ℓ et simplifié les clauses de S de la forme C ∪ {ℓ} en
leur enlevant ℓ. Par exemple,
                         {{P, Q}, {¬P, R}, {P, ¬P }}[>/P ] = {{R}} ,
                        {{P, Q}, {¬P, R}, {P, ¬P }}[>/¬P ] = {{Q}} .

La simplification revient effectivement à substituer > à ℓ et ⊥ à ℓ dans toutes les clauses de S et à
simplifier le résultat en utilisant les équivalences logiques φ ∨ > ⇔ >, φ ∨ ⊥ ⇔ φ et φ ∧ > ⇔ φ.
La simplification d’un ensemble F de clauses par un littéral ℓ s’écrit en pseudo-code comme suit.

  Fonction simplifie(F , ℓ)
       ′
   1 F := ∅
   2 pour tous les C ∈ F faire
   3     si ℓ 6∈ C alors F ′ := F ′ ∪ {C \ {ℓ}}
    4   retourner F ′

   Pour une interprétation I, on note I[1/ℓ] pour l’interprétation qui associe 1 à P si ℓ = P , 0
à P si ℓ = ¬P , et QI à toute proposition Q 6∈ fp(ℓ).
48                                               INTRODUCTION À LA LOGIQUE


7.2.2. Recherche par simplification. Comme son nom l’indique, la recherche par simplification vise
à trouver une interprétation qui satisfait toutes les clauses d’un ensemble F de clauses, en testant
successivement si F [>/P ] ou F [>/¬P ] est satisfiable ; voir la figure 8 (où les littéraux colorés
en orange sont impactés par la prochaine simplification).

                                   {{P , Q, ¬R}, {Q, R}, {¬P , ¬Q, R}, {¬P , ¬R}, {P , ¬Q}}
                                           ¬P                                     P

                 {{Q, ¬R}, {Q, R}, {¬Q}}                                              {{Q, R}, {¬Q, R}, {¬R}}
                  ¬Q                   Q                                               ¬Q                 Q


       {{¬R}, {R}}                             {⊥}                       {{R}, {¬R}}                       {{¬R}, {R}}
      ¬R          R                                                     ¬R             R                  ¬R         R

     {⊥}           {⊥}                                                {⊥}               {⊥}             {⊥}           {⊥}



                  FiguRe 8. Un arbre de recherche par simplification pour l’exemple 7.1.

   Cette recherche réussit s’il existe une branche qui termine sur l’ensemble vide ∅ de clauses, et
échoue si toutes les branches aboutissent à un ensemble qui contient la clause vide (celle-ci est
notée ⊥). La recherche illustrée dans la figure 8 échoue : l’ensemble F de l’exemple 7.1 était bien
insatisfiable.
     Exemple 7.2. Voici un autre exemple de recherche par simplification. Soit l’ensemble de clauses
     F def
       = {{P, ¬R, ¬P }, {Q, ¬R}, {¬Q}}. Un exemple de recherche par simplification est donné
     dans la figure 9.

                                                      {{P , ¬R, ¬P }, {Q, ¬R}, {¬Q}}
                                                 ¬P                                    P

                             {{Q, ¬R}, {¬Q}}                                                    {{Q, ¬R}, {¬Q}}
                         ¬Q                 Q                                               ¬Q                  Q

                {{¬R}}                               {⊥}                          {{¬R}}                            {⊥}
           ¬R            R                                                   ¬R             R

           ∅             {⊥}                                                 ∅                {⊥}



                   FiguRe 9. Un arbre de recherche par simplification pour l’exemple 7.2.

     Cette recherche réussit, puisqu’il existe au moins une feuille étiquetée par l’ensemble vide de
     clauses, par exemple la feuille atteinte par le chemin P, ¬Q, ¬R ; et en effet, toute interprétation
     qui étend [1/P, 0/Q, 0/R] est un modèle de F .

     Voici un pseudo-code pour un algorithme récursif de recherche par simplification.

     Fonction satisfiable(F )
      1 si F = ∅ alors retourner 1
      2 si ⊥ ∈ F alors retourner 0
      3 choisir P ∈ fp(F )
      4 retourner
         satisfiable(simplifie(F, P )) or satisfiable(simplifie(F, ¬P ))

Remarque 7.3. À noter dans ce pseudo-code que le choix de la proposition à utiliser pour simplifier
à la ligne 3 n’a pas besoin d’être le même le long de toutes les branches. Par exemple, la figure 10
                                                INTRODUCTION À LA LOGIQUE                                               49


montre une recherche par simplification pour l’exemple 7.1 qui échoue plus rapidement que celle
de la figure 8.

                                    {{P , Q, ¬R}, {Q, R}, {¬P , ¬Q, R}, {¬P , ¬R}, {P , ¬Q}}
                                              ¬P                                  P

                   {{Q, ¬R}, {Q, R}, {¬Q}}                                            {{Q, R}, {¬Q, R}, {¬R}}
                      ¬Q                  Q                                            ¬R                 R

          {{¬R}, {R}}                           {⊥}                       {{Q}, {¬Q}}                           {⊥}
         ¬R           R                                                  ¬Q            Q


     {⊥}               {⊥}                                           {⊥}                {⊥}



           FiguRe 10. Un autre arbre de recherche par simplification pour l’exemple 7.1.


  Exemple 7.4. Considérons la formule sous forme clausale
                 {{P, Q, R}, {¬P, Q, R}, {R}, {P, ¬Q, ¬R}, {¬P, ¬Q, ¬R}, {¬R}} .
  Si on effectue les simplifications sur P puis Q puis R, l’arbre de recherche obtenu est celui de
  la figure 11, qui est aussi grand que celui d’une recherche par énumération exhaustive.

                             {{P , Q, R}, {¬P , Q, R}, {R}, {P , ¬Q, ¬R}, {¬P , ¬Q, ¬R}, {¬R}}
                                           ¬P                                 P

              {{Q, R}, {R}{¬Q, ¬R}, {¬R}}}                                    {{Q, R}, {R}{¬Q, ¬R}, {¬R}}}
                  ¬Q                  Q                                           ¬Q                  Q


      {{¬R}, {R}}                      {{¬R}, {R}}                    {{¬R}, {R}}                      {{¬R}, {R}}
     ¬R           R                   ¬R           R                 ¬R           R                   ¬R          R

   {⊥}             {⊥}              {⊥}               {⊥}          {⊥}                {⊥}           {⊥}               {⊥}



                FiguRe 11. Un arbre de recherche par simplification pour l’exemple 7.4.

  Il est pourtant possible de faire une recherche par simplification beaucoup plus efficace, en
  commençant par la proposition R, comme illustré dans la figure 12. En général, il peut être
  avantageux de simplifier en priorité sur des propositions qui apparaissent dans beaucoup de
  clauses.
                             {{P, Q, R}, {¬P, Q, R}, {R}, {P, ¬Q, ¬R}, {¬P, ¬Q, ¬R}, {¬R}}
                                                   ¬R                 R

                                 {{P, Q}, {¬P, Q}, ⊥}             {{P, ¬Q}, {¬P, ¬Q}, ⊥}



              FiguRe 12. Un autre arbre de recherche par simplification pour l’exemple 7.4.


7.2.3. Correction et complétude. La recherche de modèle par simplification peut se comprendre
par le biais de règles de réécriture qui agissent sur des ensembles de clauses. Les règles (splitP ) et
(split¬P ) de la figure 13 cherchent à montrer qu’un ensemble fini F est satisfiable en le réduisant
à l’ensemble vide de clauses. Les arbres des figures 8 à 12 recensent des réécritures possibles par
ce système de règles.
                                                                   →∗spl ∅ à l’aide des règles (splitP )
    Il est aisé de voir que F est satisfiable si et seulement si F −
et (split¬P ) pour P ∈ fp(F ). En effet, notons I[1/ℓ] pour l’interprétation qui associe 1 à P si
                                         50                                    INTRODUCTION À LA LOGIQUE



                                                               F −
                                                                 →spl F [>/P ]                             où P ∈ fp(F )               (splitP )
                                                               F −
                                                                 →spl F [>/¬P ]                            où P ∈ fp(F )              (split¬P )



                                                        FiguRe 13. Règles de réécriture de la recherche par simplification.

                                         ℓ = P , 0 à P si ℓ = ¬P , et QI à toute proposition Q 6∈ fp(ℓ). On a alors la conséquence suivante
                                         du lemme 4.7 de substitution propositionnelle
                                         Propriété 7.5. Pour toute ensemble S de clauses, toute interprétation I et tout littéral ℓ, I Z= S[>/ℓ]
                                         si et seulement si I[1/ℓ] Z= S.
                                            Une autre remarque importante est que la simplification par un littéral P ou ¬P conduit à un
                                         ensemble de clauses où ni P ni ¬P n’apparaît.
                                         Propriété 7.6. Soit S un ensemble de clauses et P une proposition. Alors P 6∈ fp(S[>/P ]) et
                                         P 6∈ fp(S[>/¬P ]).
                                             Comme les règles de réécriture de la figure 13 n’appliquent la simplification qu’à une propo-
                                         sition P ∈ fp(F ), on a que F −   →spl F ′ implique fp(F ) ⊋ fp(F ′ ), donc on ne peut appliquer
                                         les règles qu’au plus |fp(F )| fois à un ensemble F donné : on dit que ce système de règles de
                                         réécriture termine.
                                             On en déduit le théorème suivant des propriétés 7.5 et 7.6.
                                         Théorème 7.7. Soit F un ensemble fini de clauses. Alors les règles de la figure 13 sont correctes et
                                                                                            →∗spl ∅.
                                         complètes : F est satisfiable si et seulement si F −
                                         Démonstration. Pour la correction, c’est-à-dire pour montrer que F −    →∗spl ∅ implique F satisfiable,
                                         il suffit d’observer d’une part que l’ensemble vide de clauses ∅ est satisfiable (il est même valide),
                                         et d’autre part que si F ′ est satisfiable – disons par une interprétation I telle que I Z= F ′ – et
                                         F − →spl F ′ par une des règles de la figure 13, alors F est satisfiable :
                                             — pour (splitP ) : alors F ′ = F [>/P ] pour la proposition P : on a I[1/P ] Z= F par la pro-
                                                 priété 7.5 ;
                                             — pour (split¬P ) : alors F ′ = F [>/¬P ] pour la proposition P : on a I[0/P ] Z= F par la
                                                 propriété 7.5.
                                         Une simple récurrence sur le nombre de réécritures dans F −     →∗spl ∅ démontre alors la correction.
                                            Pour la complétude, c’est-à-dire pour montrer que F satisfiable implique F −   →∗spl ∅, supposons
                                         que I Z= F . On ordonne fp(F ) de manière arbitraire comme P1 < · · · < Pn . Soit F0 def     = F ; on
                                         applique pour chaque 1 ≤ i ≤ n à la proposition Pi sur l’ensemble Fi−1
                                            — soit (splitPi ) si I Z= Pi et alors Fi def
                                                                                     = Fi−1 [>/Pi ] et comme I = I[1/Pi ], I Z= Fi par la
                                               propriété 7.5 ;
                                            — soit (split¬Pi ) si I Z= ¬Pi et alors Fi def
                                                                                       = Fi−1 [>/¬Pi ] et comme I = I[1/¬Pi ], I Z= Fi par
                                               la propriété 7.5.
                                         Comme fp(Fi ) = {Pi+1 , . . . , Pn } pour tout 0 ≤ i ≤ n par la propriété 7.6, Fn est un ensemble
                                         de clauses sans propositions. De plus, il ne peut pas contenir la clause vide puisque I Z= Fn . Donc
                                         Fn = ∅.                                                                                             □
 L’implémentation de la recherche par   7.2.4. Implémentation de la recherche par simplification en Java. Comme dans la section 7.1.1,
simplification en Ocaml sera faite en    nous utilisons des représentations proches de celles utilisées en pratique par les solveurs SAT, à
mini-projet.                             savoir qu’un littéral est un entier non nul et une interprétation est un tableau d’entiers. Voici une
                                         implémentation possible de la simplification d’un ensemble de clauses, d’abord dans notre classe
                                         Clause et ensuite au niveau de notre solveur par simplification.
                                    INTRODUCTION À LA LOGIQUE                                   51


 Clause
 public boolean simplifie(int l) {
     if (this.contains(Integer.valueOf(l)))
         return true;
     this.remove(Integer.valueOf(-l));
     return false;
 }
 SolveurSplit
 private SolveurSplit simplifie(int l) {
     interpretation[index(l)] = l;
     clauses.removeIf(c -> c.simplifie(l));
     return this;
 }

   Voici maintenant une implémentation de la recherche de modèle par simplification en Java.
 SolveurSplit
 private boolean satisfiable(int i) {
     // l'ensemble vide de clauses est satisfiable
     if (clauses.size() == 0) {
         // interprétation arbitraire des propositions restantes
         for (int j = i; j < nprops; j++)
             interpretation[j] = j+1;
         return true;
     }
     // un clause vide est insatisfiable
     if (clauses.stream().anyMatch(c -> c.size() == 0))
         return false;
     // branchement :
     SolveurSplit clone = this.clone();
     // - tente de simplifier par le littéral P�
     if (this.simplifie(i+1).satisfiable(i+1))
         return true;
     // - restaure l'état du solveur
     this.interpretation = clone.interpretation;
     this.clauses = clone.clauses;
     // - tente de simplifier par le littéral ¬P�
     return this.simplifie(-i-1).satisfiable(i+1);
 }
 public boolean satisfiable() {
     return satisfiable(0);
 }

    Bien qu’elle ne cherche pas à optimiser l’ordre des littéraux sur lesquels simplifier (voir la
remarque 7.3 et l’exemple 7.4), cette implémentation résout les problèmes de la section 6 en moins
d’une seconde sur ma machine. Elle n’est cependant pas capable de résoudre des problème de
taille plus importante, de l’ordre de plusieurs dizaines de propositions et de clauses.
7.3. Algorithme de Davis, Putnam, Logemann et Loveland. Couramment appelé DPLL                        (Conchon et Simon, 2018, sec. 2.2.3),
                                                                                                     (Goubault-LaRRecq et MacKie, 1997,
d’après ses inventeurs, cet algorithme sert d’inspiration aux solveurs SAT actuels. L’algorithme     sec. 2.4.3), (HaRRisson, 2009, sec. 2.9)
DPLL est un raffinement de la recherche de modèle par simplification de la section 7.2.
   L’idée de départ de l’algorithme DPLL provient de la remarque 7.3 : comment choisir les lit-
téraux par lesquels simplifier l’ensemble de clauses ? Comme vu dans l’exemple 7.4, un mauvais
choix va résulter en un arbre de recherche très grand, potentiellement aussi grand que l’arbre de
recherche par énumération naïve de la section 7.1 ; à l’inverse, un bon choix peut mener beaucoup
plus rapidement à la réponse. L’algorithme DPLL fournit des heuristiques pratiques pour choisir
52                                     INTRODUCTION À LA LOGIQUE


ces littéraux. Voici deux telles heuristiques, qui identifient les littéraux unitaires et les littéraux
purs de l’ensemble de clauses.
Littéraux unitaires. Dans un ensemble S de clauses, une clause C est unitaire si elle ne contient
qu’un seul littéral, et on dit alors que ce littéral est unitaire. Formellement, ℓ est unitaire dans S
si S = S ′ ∪ {{ℓ}} pour un ensemble S ′ . Dans tout modèle I de S, c’est-à-dire si I Z= S, un
littéral unitaire ℓ sera nécessairement satisfait par I : I Z= ℓ. C’est donc un bon choix pour une
simplification.
    Par exemple, dans l’ensemble de clauses de l’exemple 7.4, les littéraux R et ¬R sont unitaires.
Littéraux purs. On définit l’ensemble des littéraux purs d’un ensemble S de clauses comme l’en-
semble des littéraux ℓ tels que ℓ n’apparaît dans aucune clause de S :

                                  Pur(S) def
                                         = {ℓ | ∀C ∈ S . ℓ 6∈ C} .
Dans tout modèle I de S, c’est-à-dire si I Z= S, si ℓ est un littéral pur de S, alors I[1/ℓ] est encore
un modèle de S. C’est encore une fois un bon choix pour une simplification.

     Exemple 7.8. Soit l’ensemble de clauses
                             F def
                               = {{P, ¬Q, R}, {P, ¬R}, {Q, R}, {P, ¬Q}} .
     Alors Pur(F ) = {P }.

7.3.1. Correction et complétude. L’algorithme DPLL peut être vu comme une extension du sys-
tème de règles de la figure 13, qui introduit deux nouvelles règles (unit) et (pure). Tout comme
lors de la recherche de modèle par simplification, les règles de la figure 14 cherchent à montrer
qu’un ensemble fini F de clauses est satisfiable en le réduisant à l’ensemble vide.


                    F ∪ {{ℓ}} −
                              →dpll F [>/ℓ]                                                     (unit)
                               F −
                                 →dpll F [>/ℓ]                     où ℓ ∈ Pur(F )               (pure)
                               F −
                                 →dpll F [>/P ]                    où P ∈ fp(F )              (splitP )
                               F −
                                 →dpll F [>/¬P ]                   où P ∈ fp(F )             (split¬P )



                               FiguRe 14. Règles de réécriture de DPLL.

   On montre que ce système de règles reste correct ; la complétude découle directement de celle
du système de recherche de modèle par simplification.

Théorème 7.9. Soit F un ensemble fini de clauses. Alors les règles de la figure 14 sont correctes et
                                                   →∗dpll ∅.
complètes : F est satisfiable si et seulement si F −

Démonstration. Pour la correction, puisque la recherche de modèle par simplification était cor-
recte (voir le théorème 7.7), il suffit de montrer que, si F ′ est satisfiable – disons par une inter-
prétation I telle que I Z= F ′ – et F −→dpll F ′ par (unit) et (pure), alors F est satisfiable :
   — pour (unit) : alors F = F [>/ℓ] et F = F ′′ ∪ {{ℓ}} pour un littéral unitaire ℓ de F ′′ : on
                              ′    ′′

       a I[1/ℓ] Z= F ′′ par la propriété 7.5 et donc I[1/ℓ] Z= F ;
   — pour (pure) : alors F ′ = F [>/ℓ] pour un littéral pur ℓ : on a I[1/ℓ] Z= F par la propriété 7.5.

   Pour la complétude, c’est-à-dire pour montrer que F satisfiable implique F −       →∗dpll ∅, cela
                                                                   ∗
découle du théorème 7.7. En effet, si F est satisfiable, alors F −                      →∗dpll ∅ en
                                                                 →spl ∅, c’est-à-dire F −
n’utilisant que les règles (splitP ) et (split¬P ).                                               □
                                           INTRODUCTION À LA LOGIQUE                                                         53


7.3.2. Algorithme DPLL. L’intérêt des règles (unit) et (pure) est qu’elles sont inversibles, au sens
suivant.
                                                                                    (unit)                          (pure)
Proposition 7.10 (inversibilité). Soit F un ensemble de clauses. Si F −−→dpll F ′ ou F −−−→dpll F ′
pour un ensemble de clauses F satisfiable, alors F ′ est aussi satisfiable.
Démonstration. Supposons que I soit une interprétation telle que I Z= F .
  — Pour (unit) : alors F = F ∪ {{ℓ}} et en particulier I Z= ℓ. Donc I[1/ℓ] = I Z= F et par la
    propriété 7.5, I Z= F [>/ℓ] = F ′ .
  — Pour (pure) : alors F ′ = F [>/ℓ] où ℓ est un littéral dans Pur(F ). Si I Z= ℓ, alors I[1/ℓ] =
    I Z= F et par la propriété 7.5 I Z= F [>/ℓ] = F ′ . Inversement, si I 6Z= ℓ, alors comme I Z= F ,
    dans toutes les clauses C ∈ F , il existe un littéral ℓC ∈ C tel que I Z= ℓC et forcément
    ℓC 6= ℓ pour toutes les clauses C ∈ F . Mais alors I[1/ℓ] Z= ℓC pour toutes les clauses
    C ∈ F , et donc I[1/ℓ] Z= F . Par la propriété 7.5, I Z= F [>/ℓ] = F ′ .                      □
                                                                                                           (unit)
   L’inversibilité et la correction des règles (unit) et (pure) signifie que, si F −−→dpll F ′ ou
   (pure)
F −−−→dpll F ′ , alors F est satisfiable si et seulement si F ′ l’est. Autrement dit, il n’est pas utile                           L’algorithme DPLL est implémenté
                                                                                                                                  sous forme itérative en utilisant du
d’introduire des points de choix comme lors de l’utilisation des règles (splitP ) et (split¬P ), pour                             backtracking. Les performances des
revenir en arrière s’il s’avérait que F ′ était insatisfiable. Les règles (unit) et (pure) peuvent donc                           solveurs SAT actuels tiennent à une
être appliquées arbitrairement. La stratégie usuelle de l’algorithme DPLL est de les appliquer                                    gestion fine des retours aux points de
                                                                                                                                  choix, et lors de ces retours à l’ajout de
en priorité (et dans cet ordre) avant d’essayer (splitP ) ou (split¬P ), de manière à accélérer la                                nouvelles clauses inférées à partir de la
recherche de preuve en éliminant des points de choix. Voici le pseudo-code de l’algorithme écrit                                  branche d’échec, ceci afin de guider la
en style récursif.                                                                                                                recherche vers une branche de succès ;
                                                                                                                                  cette technique est appelée
                                                                                                                                  « conflict-driven clause learning ».
  Fonction satisfiable(F )                                                                                                         Voir (Conchon et Simon, 2018,
   1 si F = ∅ alors retourner 1                                                                                                   sec. 2.2) et (Zhang et al., 2001).
   2 si ⊥ ∈ F alors retourner 0
   3 si ∃ℓ . F = F ∪ {{ℓ}} alors retourner satisfiable(simplifie(F, ℓ))
   4 si ∃ℓ ∈ Pur(F ) alors retourner satisfiable(simplifie(F, ℓ))
   5 choisir P ∈ fp(F )
   6 retourner
      satisfiable(simplifie(F, P )) or satisfiable(simplifie(F, ¬P ))

   Comme dans le cas de la recherche par simplification, les réécritures du système de la figure 14
sont de longueur au plus |fp(F )|.
   Reprenons les différents exemples de cette section. Pour l’exemple de la figure 10, l’algorithme
DPLL construit (entre autres) l’arbre de recherche de la figure 15. Pour l’exemple 7.2, l’arbre de
recherche DPLL est celui de la figure 16. Pour l’exemple des figures 11 et 12, l’algorithme DPLL
construit (entre autres) l’arbre de recherche de la figure 17. Pour l’exemple 7.8, l’algorithme DPLL
construit l’arbre de recherche de la figure 18.
                              {{P , Q, ¬R}, {Q, R}, {¬P , ¬Q, R}, {¬P , ¬R}, {P , ¬Q}}
                                      ¬P                                  P

             {{Q, ¬R}, {Q, R}, {¬Q}}                                          {{Q, R}, {¬Q, R}, {¬R}}

               ¬Q unitaire                                                                   ¬R unitaire

                   {{¬R}, {R}}                                                     {{Q}, {¬Q}}

                 R unitaire                                                                  Q unitaire

                        {⊥}                                                              {⊥}



                    FiguRe 15. Un arbre de recherche DPLL pour l’exemple 7.1.
                                       54                                   INTRODUCTION À LA LOGIQUE

                                                                           {{P, ¬R, ¬P }, {Q, ¬R}, {¬Q}}

                                                                                 ¬Q unitaire

                                                                                {{P, ¬R, ¬P }, {¬R}}

                                                                                     ¬R pur

                                                                                            ∅



                                                         FiguRe 16. L’arbre de recherche DPLL pour l’exemple 7.2.

                                                            {{P, Q, R}, {¬P, Q, R}, {R}, {P, ¬Q, ¬R}, {¬P, ¬Q, ¬R}, {¬R}}

                                                                                   R unitaire

                                                                               {{P, ¬Q}, {¬P, ¬Q}, ⊥}



                                                         FiguRe 17. Un arbre de recherche DPLL pour l’exemple 7.4.

                                                                       {{P , ¬Q, R}, {P , ¬R}, {Q, R}, {P , ¬Q}}

                                                                                       P pur

                                                                                       {{Q, R}}

                                                                                      Q pur

                                                                                            ∅



                                                         FiguRe 18. L’arbre de recherche DPLL pour l’exemple 7.8.

 L’implémentation d’un algorithme     7.3.3. Implémentation d’un DPLL récursif en Java. Voici enfin une implémentation assez naïve
DPLL récursif en Ocaml sera faite en
mini-projet.
                                       de l’algorithme DPLL en Java sous la forme d’une méthode récursive.
                                            DPLLRec
                                            private DPLLRec simplifie(int l) {
                                                interpretation[index(l)] = l;
                                                clauses.removeIf(c -> c.simplifie(l));
                                                return this;
                                            }
                                            public boolean satisfiable() {
                                                // l'ensemble vide de clauses est satisfiable
                                                if (clauses.size() == 0)
                                                    return true;
                                                // un clause vide est insatisfiable
                                                if (clauses.stream().anyMatch(c -> c.size() == 0))
                                                    return false;
                                                // clause unitaire
                                                Optional<Clause> unitaire
                                                    = clauses.stream().filter(c -> c.size() == 1).findAny();
                                                if (unitaire.isPresent()) {
                                                    int l = unitaire.get().stream().findAny().get().intValue();
                                                    return simplifie(l).satisfiable();
                                                }
                                                // littéral pur
                                                for (int i = 0; i < nprops; i++)
                                                    if (interpretation[i] == 0) {
                                                        final Integer l = Integer.valueOf(i+1);
                                                        final Integer notl = Integer.valueOf(-i-1);
                                                        if (clauses.stream().noneMatch(c ->
                                  INTRODUCTION À LA LOGIQUE                                 55


                        c.stream().anyMatch(j -> j.equals(notl))))
                    return simplifie(l.intValue()).satisfiable();
                if (clauses.stream().noneMatch(c ->
                        c.stream().anyMatch(j -> j.equals(l))))
                return simplifie(notl.intValue()).satisfiable();
          }
      // branchement
      for (int i = 0; i <nprops; i++)
          if (interpretation[i] == 0) {
              DPLLRec clone = this.clone();
              // - tente de simplifier par le littéral Pi
              if (this.simplifie(i+1).satisfiable())
                  return true;
              // - restaure l'état du solveur
              this.interpretation = clone.interpretation;
              this.clauses = clone.clauses;
              // - tente de simplifier par le littéral ¬Pi
              return this.simplifie(-i-1).satisfiable();
          }
      assert false;
      return false;
 }

   Comme précédemment, cette implémentation ne cherche pas à optimiser le choix des littéraux
lors des branchements. Cette implémentation arrive à résoudre des problèmes de taille modeste,
autour de quelques centaines de propositions et de clauses, qui sont hors de portée des implé-
mentations à base de recherche par énumération ou par simplification.
                                              56                                      INTRODUCTION À LA LOGIQUE


                                                                               8. ValiditÉ et RecheRche de pReuve

                                                    Résumé. Le calcul des séquents propositionnel est un système de déduction qui manipule
                                                    des séquents 7− Γ, où Γ est un multi-ensemble fini de formules propositionnelles sous
                                                    forme normale négative. Un séquent 7− Γ pour lequel il existe une dérivation dans le
                                                    système de preuve est dit prouvable, ce qui est noté « 7−LK0 Γ ».
                                                        On peut implémenter la recherche de preuve dans le calcul des séquents propositionnel :
                                                    cela tient à la propriété 8.7 de branches linéaires, et de plus on peut faire une implémen-
                                                    tation sans retours sur erreurs grâce au lemme 8.8 d’inversibilité syntaxique.
                                                           Un séquent 7− Γ est valide, si pour toute interprétation I, il existe une formule propo-
                                                      sitionnelle ϑ ∈ dom(Γ) du séquent telle que I Z= ϑ. Par le théorème 8.10 de correction, si
                                                    7− Γ est prouvable, alors il est valide. Inversement, par le théorème 8.13 de complétude, si
                                                     7− Γ est valide, alors il est prouvable.

                                                    Le problème de validité est le problème de décision suivant.
                                              Problème (VALIDITÉ).
                                                instance : une formule propositionnelle φ
                                                question : φ est-elle valide ?
                                                 Une façon de résoudre ce problème nous est offerte par la dualité entre satisfiabilité et validité
                                              (voir la propriété 3.11) : φ est valide si et seulement si ¬φ n’est pas satisfiable. On peut donc
                                              résoudre VALIDITÉ à l’aide d’un solveur SAT.
 Dans le cas de SAT, un certificat de           Cependant, on souhaiterait aussi, dans le cas où φ est valide, avoir un certificat de validité,
satisfiabilité était simplement un
modèle I de la formule, qui est de taille
                                              qui « explique » pourquoi la formule propositionnelle est valide ; on voudrait de plus pouvoir
|fp(φ)| et I Z= φ peut être vérifié en        aisément vérifier, quand on dispose d’un tel certificat, que la formule propositionnelle était bien
temps polynomial.                             valide.
                                              Certificats d’insatisfiabilité. Or, dans les algorithmes que nous avons vus dans la section 7.3,
                                              dans le cas d’une formule propositionnelle insatisfiable, aucune information n’est retournée ; par
                                              exemple, MiniSat retourne seulement « UNSAT ». Retourner l’arbre de recherche entier du sol-
                                              veur SAT fournirait un certificat facile à vérifier, mais potentiellement beaucoup trop gros et de
                                              plus dépendant des heuristiques utilisées par chaque solveur.
 Voir par exemple GoldbeRg et                   Les solveurs SAT plus récents comme Glucose 10 peuvent fournir des certificats sous des for-
NoviKov (2003) et WetzleR, Heule et
Hunt (2014) pour les certificats de
                                              mats standard. Le principe de base est le suivant : soit F un ensemble de clauses insatisfiable. Un
solveurs SAT.                                 certificat est alors un ensemble F ′ de clauses tel que
                                                   (1) toutes les clauses C ′ ∈ F ′ sont des conséquences logiques de F , c’est-à-dire F ∪{{ℓ}} Z= ⊥
                                                       pour tout littéral ℓ ∈ C ′ , et
                                                   (2) F ∪ F ′ Z= ⊥.
                                              L’espoir ici est que d’une part cet ensemble F ′ soit de petite taille et d’autre part que les tests
                                              d’insatisfiabilité F ∪ {{ℓ}} Z= ⊥ et F ∪ F ′ Z= ⊥ soient aisés, par exemple en n’utilisant que des
                                              règles unitaires (unit).
 On soupçonne en fait que des                Systèmes de preuve. L’approche alternative que nous allons explorer dans cette section est plutôt
certificats de taille polynomiale et          de résoudre le problème de validité directement, à l’aide d’un système de preuve, c’est-à-dire de
vérifiables en temps polynomial               règles de déduction qui garantissent la validité. L’intérêt ici est que la preuve elle-même, c’est-à-
n’existent pas pour VALIDITÉ, car cela
impliquerait NP = coNP, comme vous            dire l’arbre de dérivation dans le système de preuve, fait office de certificat. Un tel certificat est
le verrez en cours de « calculabilité et      très facile à vérifier ; en revanche, il peut être de taille exponentielle en la taille de φ.
complexité » en M1. Cette question de la
« complexité des preuves » a été initiée      8.1. Calcul des séquents propositionnel. Le système de preuve que nous allons étudier dans
par CooK et RecKhow.                          ce cours est un système de calcul des séquents. Il y a quantité de variantes du calcul des séquents
 Voir (DupaRc, 2015, sec. 3.5) ou
(Goubault-LaRRecq et MacKie, 1997,                 10. https://www.labri.fr/perso/lsimon/glucose/
sec. 2.3.3) pour un calcul des séquents
bilatère avec coupure ; d’autres familles
de systèmes de preuve pour la logique
classique propositionnelle sont les
systèmes à la HilbeRt (ibid., sec. 2.3.1),
la déduction naturelle (ibid., sec. 2.3.2),
la résolution propositionnelle (ibid.,
sec. 2.4.2) et les systèmes de tableaux
(ibid., sec. 2.4.1).
                                                  INTRODUCTION À LA LOGIQUE                                                             57


pour la logique classique propositionnelle. Le système que nous étudions ici est un calcul mono-
latère inversible sans coupure, qui a l’avantage de ne comporter que peu de règles et de se prêter
particulièrement bien à la recherche de preuve.
   Un multi-ensemble fini sur un ensemble S est formellement une fonction m: S → N de do-
maine dom(m) def = {e ∈ S | m(e) > 0} fini ; on peut aussi voir m comme une séquence finie de
S ∗ modulo permutation.
   Dans le calcul de la figure 19, un séquent est un multi-ensemble fini Γ de formules en forme
normale négative, et est noté 7− Γ. La virgule dénote l’union de multi-ensembles : par exemple,
Γ, ∆, φ dénote le multi-ensemble avec Γ(φ) + ∆(φ) + 1 occurrences de la formule proposition-
nelle φ, et Γ(ψ) + ∆(ψ) occurrences de ψ 6= φ. On note le séquent vide 7− ⊥, où ⊥(φ) def
                                                                                       = 0 pour
toute formule φ.

                                                                                                                                              Ce calcul ne contient pas ni la règle
                                                                                                                                             structurelle d’échange, qui est implicite
                                                     7− Γ, φ 7− Γ, ψ                         7− Γ, φ, ψ                                      parce que nous travaillons avec des
                                       (ax)                                     (∧)                                    (∨)                   multi-ensembles, ni la règle structurelle
               7− Γ, P , ¬P                             7− Γ, φ ∧ ψ                         7− Γ, φ ∨ ψ                                      d’affaiblissement, qui est implicite dans
                                                                                                                                             la règle d’axiome (ax), ni la règle
                                                                                                                                             structurelle de contraction ni la règle de
                      FiguRe 19. Calcul des séquents propositionnel monolatère.                                                              coupure, mais toutes celles-ci sont
                                                                                                                                             admissibles.

   Une règle du calcul des séquents permet de déduire un séquent conclusion d’un nombre fini de
séquents prémisses. Chaque règle comprend une formule principale dans sa conclusion, indiquée
en orange dans les règles de la figure 19. Un séquent 7− Γ est prouvable, noté 7−LK0 Γ, s’il en existe
une dérivation dans le système de la figure 19.

  Exemple 8.1. La loi de PeiRce de l’exemple 5.2 est prouvable. La dérivation correspondante
  (avec la formule principale indiquée en orange à chaque étape) est :
                                                                (ax)
                                               7 ¬P , Q, P
                                                −
                                                              (∨)                        (ax)
                                              7− ¬P ∨ Q, P         7− ¬P , P
                                                                                         (∧)
                                                    7− (¬P ∨ Q) ∧ ¬P , P
                                                                           (∨)
                                                  7− ((¬P ∨ Q) ∧ ¬P ) ∨ P

  Exemple 8.2. Considérons la formule propositionnelle (P ∧ P ) ⇔ P . Sa forme normale né-
  gative est (¬P ∨ ¬P ∨ P ) ∧ (¬P ∨ (P ∧ P )). Cette formule est prouvable ; une dérivation
  est :
                                                      (ax)                      (ax)                         (ax)
                             7 ¬P , ¬P, P
                              −                    7− ¬P , P        7− ¬P , P
                                           (∨)                                                               (∧)
                            7− ¬P, ¬P ∨ P                 7− ¬P, P ∧ P
                                            (∨)                           (∨)
                          7− ¬P ∨ ¬P ∨ P               7− ¬P ∨ (P ∧ P )
                                                                          (∧)
                                7− (¬P ∨ ¬P ∨ P ) ∧ (¬P ∨ (P ∧ P ))

  Exemple 8.3. Considérons la formule propositionnelle (P ∧ (Q ∨ R) ⇒ ((P ∧ Q) ∨ (P ∧ R)).
  Sa forme normale négative est ¬P ∨ (¬Q ∧ ¬R) ∨ (P ∧ Q) ∨ (P ∧ R). Cette formule est
  prouvable ; une dérivation est :
                                                                                                      (ax)                            (ax)
                                                                                7− ¬P, ¬Q, Q, R                     7− ¬P, ¬R, Q, R
                                                                       (ax)                                                           (∧)
                                              7− ¬P , ¬Q ∧ ¬R, Q, P                       7− ¬P, ¬Q ∧ ¬R, Q, R
                                (ax)                                                                                       (∧)
   7− ¬P , ¬Q ∧ ¬R, P , P ∧ R                                   7− ¬P, ¬Q ∧ ¬R, Q, P ∧ R
                                                                                                (∧)
                            7− ¬P, ¬Q ∧ ¬R, P ∧ Q, P ∧ R
                                                                       (∨)
                          7− ¬P, ¬Q ∧ ¬R, (P ∧ Q) ∨ (P ∧ R)
                                                                         (∨)
                        7− ¬P, (¬Q ∧ ¬R) ∨ (P ∧ Q) ∨ (P ∧ R)
                                                                          (∨)
                       7− ¬P ∨ (¬Q ∧ ¬R) ∨ (P ∧ Q) ∨ (P ∧ R)
58                                                    INTRODUCTION À LA LOGIQUE

     Exemple 8.4. Considérons les trois formules propositionnelles suivantes :
              φA def
                 =B⇒D,                             φB def
                                                      = ¬B ⇒ (¬D ∧ ¬U ) ,                                   φC def
                                                                                                               = B∨D∨U .
     On souhaite montrer que B ∧D est une conséquence logique de φA ∧φB ∧φC . Par le lemme 4.2
     de déduction, φA ∧ φB ∧ φC Z= B ∧ D si et seulement si (φA ∧ φB ∧ φC ) ⇒ B ∧ D est valide,
     autrement dit si et seulement si sa forme normale négative φA ∨ φB ∨ φC ∨ (B ∧ D) est valide,
     où
              φA = B ∧ ¬D ,                        φB = ¬B ∧ (D ∨ U ) ,                            φC = ¬B ∧ ¬D ∧ ¬U .
     La dérivation ci-dessous montre que 7−LK0 φA ∨ φB ∨ φC ∨ (B ∧ D), ce qui implique par le
     théorème 8.10 de correction que la formule est bien valide et donc que B ∧ D est bien une
     conséquence logique de φA ∧ φB ∧ φC .
                                                                                                                               π
                                                              (ax)                                  (ax)                       .
                                           7− B, ¬B, φC , D                 7− ¬D, ¬B, φC , D                                  .
                                                                                                                               .
                             (ax)                                                                   (∧)
        7− φA , ¬B, φC , B                               7− φA , ¬B, φC , D                                        7− φA , D, U, φC , B ∧ D
                                                                                     (∧)                                                        (∨)
                             7− φA , ¬B, φC , B ∧ D                                                                7− φA , D ∨ U , φC , B ∧ D
                                                                                                                                                (∧)
                                                                        7− φA , φB , φC , B ∧ D
                                                                                                           (∨)
                                                                      7− φA , φB , φC ∨ (B ∧ D)
                                                                                                           (∨)
                                                                     7− φA , φB ∨ φC ∨ (B ∧ D)
                                                                                                            (∨)
                                                                     7− φA ∨ φB ∨ φC ∨ (B ∧ D)


     où la dérivation π de 7− φA , D, U, φC , B ∧ D est
                                                                                                                                       π′
                                                                                                                                        .
                                                                                                                                        .
                                                                                                                                        .
                                                                                                                      (ax)
                                                                                           7− φA , D, U, ¬B, B                 7− φA , D, U, ¬B, D
                                                                              (ax)                                                                    (∧)
                                               7− φA , D, U , ¬U , B ∧ D                        7 φA , D, U, ¬B, B ∧ D
                                                                                                 −
                                    (ax)                                                                                               (∧)
      7− φA , D, U, ¬D, B ∧ D                                         7− φA , D, U, ¬U ∧ ¬B, B ∧ D
                                                                                                    (∧)
                                           7− φA , D, U, φC , B ∧ D


     et la dérivation π ′ de 7− φA , D, U, ¬B, D est
                                                                     (ax)                                   (ax)
                                             7− B, D, U, ¬B, D                 7− ¬D, D, U, ¬B, D
                                                                                                            (∧)
                                                           7− φA , D, U, ¬B, D


8.2. Recherche de preuve. La recherche de preuve en calcul des séquents propositionnel vise
à répondre au problème de décision suivant.
Problème (PROUVABILITÉ).
  instance : un séquent propositionnel 7− Γ
  question : 7− Γ est-il prouvable dans le calcul des séquents propositionnel ?
    Comme pour le problème de satisfiabilité, on peut aussi retourner une preuve de 7−LK0 φ
quand la réponse est positive. Comme nous le verrons dans la section 8.3, le calcul des séquents
 est correct et complet : en particulier, pour une formule propositionnelle φ en forme normale né-
 gative, 7−LK0 φ si et seulement si φ est valide. Résoudre PROUVABILITÉ revient donc à résoudre
VALIDITÉ.
Recherche de preuve. La recherche de preuve tente de développer un arbre de dérivation avec
7− Γ pour conclusion, de la racine vers les feuilles. Une branche de recherche de preuve est une
 séquence potentiellement infinie de séquents 7− Γ = 7− Γ0 , 7− Γ1 , . . . calculée par la recherche
de preuve : pour tout i > 0, 7− Γi est une prémisse d’une règle dont 7− Γi−1 est la conclusion. Une
branche d’échec est une branche de recherche de preuve finie 7− Γ0 , 7− Γ1 , . . . , 7− Γn où aucune
règle ne s’applique à 7− Γn , c’est-à-dire qu’il n’est le séquent conclusion d’aucune règle.
 Points de choix. La recherche de preuve n’est pas déterministe : il peut y avoir plusieurs règles
 applicables pour un même séquent 7− Γ. Par exemple, pour 7− ¬P ∨Q, R∨P , on peut commencer
 par sélectionner ¬P ∨ Q comme formule principale et appliquer (∨) :
                                     INTRODUCTION À LA LOGIQUE                                     59

                                          7− ¬P, Q, R ∨ P
                                                           (∨)
                                       7 ¬P ∨ Q, R ∨ P
                                        −
Mais on aurait aussi pu sélectionner R ∨ P comme formule principale et appliquer (∨) :
                                         7− ¬P ∨ Q, R, P
                                                           (∨)
                                        7− ¬P ∨ Q, R ∨ P
En général – mais comme nous allons le voir, pas dans le calcul des séquents de la figure 19 –
il est nécessaire pour dans un algorithme déterministe de recherche de preuve de mémoriser de
tels points de choix pour pouvoir y revenir par backtracking en cas d’échec.

  Exemple 8.5. La formule propositionnelle φex = (P ∨ ¬Q) ∧ P de la figure 1 n’est pas prou-
  vable : il n’y a aucun point de choix dans la recherche de preuve qui échoue ci-dessous :
                                         échec
                                       7 P, ¬Q
                                        −                échec
                                                  (∨)
                                     7− P ∨ ¬Q            7− P
                                                               (∧)
                                          7− (P ∨ ¬Q) ∧ P
  Les deux séquents 7− P, ¬Q et 7− P sont des séquents d’échec, c’est-à-dire des séquents sur
  lequel aucune règle ne s’applique. Les deux branches de recherche de preuve sont des branches
  d’échec, car elles terminent sur des séquents d’échec.

  Exemple 8.6. La formule propositionnelle (P ∨ ¬Q) ∨ (¬P ∧ R) n’est pas prouvable. En effet,
  une recherche de preuve pour cette formule commence nécessairement par appliquer (∨) :
                                          7 P ∨ Q, ¬P ∧ ¬R
                                           −
                                                                        (∨)
                                       7− (P ∨ ¬Q) ∨ (¬P ∧ R)
  Il y a là un point de choix, selon qu’on utilise P ∨ Q ou ¬P ∧ R comme formule principale
  dans le séquent 7− P ∨ Q, ¬P ∧ ¬R. Si on fait le premier choix, la recherche de preuve échoue
  puisqu’une des branches (celle de droite) termine sur le séquent d’échec 7− P, ¬Q, R et est
  donc une branche d’échec :
                                                       (ax)
                                                                échec
                                  7− P , ¬Q, ¬P              7− P, ¬Q, R
                                                                            (∧)
                                              7− P, ¬Q, ¬P ∧ R
                                                                    (∨)
                                            7− P ∨ ¬Q, ¬P ∧ R
  Si on fait l’autre choix, celui de considérer ¬P ∧ R comme principale, la recherche de preuve
  échoue aussi :
                                                     (ax)
                                                                 échec
                                 7− P , ¬Q, ¬P                7− P, ¬Q, R
                                                       (∨)                    (∨)
                                7− P ∨ ¬Q, ¬P               7− P ∨ ¬Q, R
                                                                              (∧)
                                           7− P ∨ ¬Q, ¬P ∧ R
  Comme quel que soit le choix de formule principale, la recherche de preuve échoue, la formule
  n’est pas prouvable.

Propriété de branches finies. On peut montrer que les branches de recherche de preuve dans le
calcul des séquents propositionnel de la figure 19 sont toutes finies, et même linéaires en la taille
du séquent 7− Γ que l’on cherche à prouver.
   On définit pour cela la taille d’un multi-ensemble Γ comme la somme des tailles de ses occur-
                            P
rences de formules |Γ| def
                         = φ∈dom(Γ) |φ| · Γ(φ), où la taille |φ| d’une formule propositionnelle
φ en forme normale négative est définie comme le nombre de nœuds étiquetés par ∧ ou ∨ dans
son arbre de syntaxe ; formellement :
                  |ℓ| def
                      =0,                   |φ ∨ ψ| = |φ ∧ ψ| def
                                                              = 1 + |φ| + |ψ| .
60                                    INTRODUCTION À LA LOGIQUE


Intuitivement, la taille d’une formule propositionnelle est le nombre de nœuds étiquetés par « ∨ »
ou « ∧ » de son arbre de syntaxe abstraite, et la taille d’un séquent est la somme des tailles de
ses formules.
Propriété 8.7 (branches linéaires). Soit 7− Γ un séquent propositionnel. Alors toutes les branches
d’une recherche de preuve pour 7− Γ sont de longueur au plus |Γ|.
Démonstration. On peut vérifier que pour chacune des règles (ax), (∨) et (∧), la taille de chaque
séquent prémisse est strictement inférieure à celle du séquent conclusion.                     □

   Voici comment la recherche de preuve pourrait s’écrire en pseudo-code, qui pour un séquent
courant 7− Γ essaye tour à tour d’utiliser chaque formule φ ∈ dom(Γ) en guise de formule
principale.

     Fonction prouvable(7− Γ)
      1 v := 0
      2 pour tous les φ ∈ dom(Γ) faire
      3     si φ = ℓ et ℓ ∈ dom(Γ) alors
      4         retourner 1
      5       si φ = φ′ ∨ ψ alors
      6           ∆ := Γ \ φ
      7           v := v or prouvable(7− ∆, φ′ , ψ)
      8       si φ = φ′ ∧ ψ alors
      9           ∆ := Γ \ φ
      10          v := v or (prouvable(7− ∆, φ′ ) and prouvable(7− ∆, ψ))
     11    retourner v

  Par la propriété 8.7 de branches linéaires, cet algorithme termine bien : la profondeur des
appels récursifs est bornée par |Γ|.
8.2.1. Inversibilité et algorithme de recherche de preuve. Nous allons maintenant voir que le choix
d’une formule principale n’est pas important dans notre calcul des séquents, et que l’on peut donc
considérablement simplifier le pseudo-code de prouvable. On peut commencer par observer
que, dans nos deux exemples précédents, la recherche de preuve réussit pour nos deux choix de
formule principale :
                                      (ax)                                            (ax)
                      7 ¬P , Q, R, P
                       −                                                7− ¬P , Q, R, P
                                       (∨)                                                (∨)
                     7− ¬P, Q, R ∨ P                                   7− ¬P ∨ Q, R, P
                                        (∨)                                                (∨)
                   7− ¬P ∨ Q, R ∨ P                                   7− ¬P ∨ Q, R ∨ P
   Une règle de déduction est syntaxiquement inversible si, quand il existe une dérivation de
son séquent conclusion, alors il existe une dérivation de chacun de ses séquents prémisses. La
règle (ax) est bien sûr syntaxiquement inversible puisqu’elle n’a aucune prémisse. Mais ce qui est
plus intéressant, c’est que toutes les autres règles de la figure 19 sont elles aussi syntaxiquement
inversibles. Cela signifie que dans une recherche de preuve, on peut appliquer ces règles de ma-
nière gloutonne sans faire de backtracking – donc sans avoir à mémoriser de points de choix – et
que si l’on arrive à un séquent pour lequel aucune règle ne s’applique, alors c’est qu’il n’y avait
pas de preuve.
Lemme 8.8 (inversibilité syntaxique). Les règles du calcul des séquents propositionnel sont syn-
taxiquement inversibles.
Démonstration. Comme déjà mentionné, la règle (ax) est syntaxiquement inversible par défini-
tion puisqu’elle n’a pas de prémisses.
                                   INTRODUCTION À LA LOGIQUE                                       61


Pour la règle (∨) : supposons qu’il existe une dérivation π du séquent 7− Γ, φ∨ψ. On montre
  par récurrence sur la profondeur de π que 7−LK0 Γ, φ, ψ.
  — Si π se termine par (∨) où φ ∨ ψ est principale, alors évidemment il existe une sous-
      dérivation de π pour sa prémisse 7− Γ, φ, ψ.
  — Sinon π se termine par une règle (R) où φ ∨ ψ n’est pas principale. Par inspection des
      règles, on est nécessairement dans une situation
                                      π1                               πk
                                       ..                                  ..
                                        .                                   .
                               7− Γ1 , φ ∨ ψ            ···    7− Γk , φ ∨ ψ
                                                                                  (R)
                                                  7− Γ, φ ∨ ψ
      où 0 ≤ k ≤ 2 (k = 0 correspondant au cas de la règle (ax)). Pour tout 1 ≤ i ≤ k, par
      hypothèse de récurrence sur πi , il existe des dérivations πi′ de 7− Γi , φ, ψ. On a donc la
      dérivation
                                       π1′                            πk′
                                           ..                           ..
                                            .                            .
                                  7− Γ1 , φ, ψ          ···      7− Γk , φ, ψ
                                                                               (R)
                                                    7− Γ, φ, ψ
Pour la règle (∧) : supposons qu’il existe une dérivation π du séquent 7− Γ, φ∧ψ. On montre
  par récurrence sur la profondeur de π que 7−LK0 Γ, φ et 7−LK0 Γ, ψ.
  — Si π se termine par (∧) où φ ∧ ψ est principale, alors évidemment il existe des sous-
      dérivations de π pour chacune de ses prémisses 7− Γ, φ et 7− Γ, ψ.
  — Sinon π se termine par une règle (R) où φ ∧ ψ n’est pas principale. Par inspection des
      règles, on est nécessairement dans une situation
                                      π1                               πk
                                        ..                                  ..
                                         .                                   .
                                7− Γ1 , φ ∧ ψ           ···     7− Γk , φ ∧ ψ
                                                                                  (R)
                                                   7− Γ, φ ∧ ψ
      où 0 ≤ k ≤ 2 (k = 0 correspondant au cas de la règle (ax)). Pour tout 1 ≤ i ≤ k,
      par hypothèse de récurrence sur πi , il existe des dérivations πi′ et πi′′ de 7− Γi , φ et de
     7− Γi , ψ. On a donc les dérivations
                 π1′                          πk′                     π1′′                 πk′′
                  ..                           ..                      ..                   ..
                   .                            .        et             .                    .
              7− Γ1 , φ    ···       7− Γk , φ                     7− Γ1 , ψ       ···  7− Γk , ψ
                                                    (R)                                           (R)
                         7− Γ, φ                                                7− Γ, ψ
                                                                                                   □
Exemple 8.9. Reprenons la recherche de preuve de l’exemple 8.6. Considérons l’application
de la règle (∨) sur la formule principale P ∨ ¬Q dans

                                                (ax)
                                                         échec
                               7− P , ¬Q, ¬P          7− P, ¬Q, R
                                                                  (∧)
                                         7− P, ¬Q, ¬P ∧ R
                                                             (∨)
                                       7− P ∨ ¬Q, ¬P ∧ R
Au moins une prémisse de cette règle n’est pas prouvable, à savoir 7− P, ¬Q, ¬P ∧ R. Par le
lemme 8.8 d’inversibilité syntaxique, la conclusion 7− P ∨ ¬Q, ¬P ∧ R n’est pas prouvable. Il
est donc inutile d’essayer de choisir la formule ¬P ∧ R comme principale, puisque la recherche
de preuve échouera aussi dans ce cas (comme on a pu le vérifier dans l’exemple 8.6).
De plus, quand on a comme ici le choix entre formule ∨ et une formule ∧ comme principale, il
vaut mieux choisir la formule ∨ qui mène à un arbre de recherche de preuve plus petit (comme
on a aussi pu le voir dans l’exemple 8.6).
                                        62                                    INTRODUCTION À LA LOGIQUE


                                           Grâce au lemme 8.8 d’inversibilité syntaxique, la recherche de preuve peut s’implémenter très
                                        aisément par un programme récursif dont voici le pseudo-code.

                                             Fonction prouvable(7− Γ)
                                              1 si 7− Γ = 7− ∆, P, ¬P alors
                                              2      retourner 1
                                              3    si 7− Γ = 7− ∆, φ ∨ ψ alors
                                               4        retourner prouvable(7− ∆, φ, ψ)
                                              5    si 7− Γ = 7− ∆, φ ∧ ψ alors
                                               6        retourner prouvable(7− ∆, φ) and prouvable(7− ∆, ψ)
                                              7    retourner 0

 L’implémentation de la recherche de   8.2.2. Implémentation de la recherche de preuve en Java. Pour notre implémentation en Java
preuve en OCaml sera faite en
mini-projet.
                                        du calcul des séquents, nous allons représenter un séquent par une structure de données plus
                                        riche qu’une simple Collection<Formule>, en distinguant les littéraux, les formules ∧ et les
                                        formules ∨. Notre classe Sequent est définie comme suit.
                                             Sequent
                                             import java.util.*;
                                             public class Sequent {
                                                 protected HashMap<String,Boolean> litteraux;
                                                 protected LinkedList<Formule.Et> ets;
                                                 protected LinkedList<Formule.Ou> ous;
                                                       ..
                                                   // .

                                        L’idée est qu’un littéral positif P du séquent soit associé par litteraux à Boolean.TRUE,
                                        tandis qu’un littéral négatif ¬P le soit à Boolean.FALSE.
                                           Cette structure permet de détecter immédiatement au moment où on ajoute un littéral au
                                        séquent s’il devient une instance de la règle d’axiome (ax) : cela se produit si on ajoute P et
                                        que ¬P était déjà présent, ou si on ajoute ¬P et que P était déjà présent. Voici le code Java
                                        correspondant.
                                             Sequent
                                             // retourne faux si le séquent devient une instance de la règle d'axiome
                                             public boolean add(Formule phi) {
                                                 return phi.addToSequent(this);
                                             }
                                             Formule
                                             protected abstract boolean addToSequent(Sequent seq);
                                             Formule.Et
                                             protected boolean addToSequent(Sequent seq) {
                                                 seq.ets.add(this);
                                                 return true;
                                             }
                                             Formule.Ou
                                             protected boolean addToSequent(Sequent seq) {
                                                 seq.ous.add(this);
                                                 return true;
                                             }
                                             Formule.Non
                                             protected boolean addToSequent(Sequent seq) {
                                                 // vérifie que nous sommes bien en forme normale négative
                                    INTRODUCTION À LA LOGIQUE                                   63


      assert (phi1.getClass() == Formule.Proposition.class);
      Formule.Proposition p = (Formule.Proposition) phi1;
      Boolean existe = seq.litteraux.put(p.nom,Boolean.FALSE);
      return existe == null || !existe.booleanValue();
 }
 Formule.Proposition
 protected boolean addToSequent(Sequent seq) {
     Boolean existe = seq.litteraux.put(nom,Boolean.TRUE);
     return existe == null || existe.booleanValue();
 }

   Plutôt que l’algorithme récursif de la section 8.2.1, nous implémentons un algorithme itératif
avec une file d’attente.
 Sequent
 public boolean prouvable() {
     Queue<Sequent> file = new LinkedList<Sequent>(); // file                  d'attente
     file.add(this);
     // recherche de preuve
     while (!file.isEmpty()) {
         // le séquent à prouver
         Sequent seq = file.poll();
         // cas d'une branche d'échec
         if (seq.ous.isEmpty() && seq.ets.isEmpty())
             return false;
         // choix d'une formule principale
         Formule.Ou phi = seq.ous.poll();
         if (phi != null) {
             // si la règle d'axiome ne s'applique pas, ajout                  à la file
             if (seq.add(phi.phi1) && seq.add(phi.phi2))
                 file.add(seq);
         }
         else {
             Formule.Et psi = seq.ets.poll();
             Sequent clone = (Sequent) seq.clone();
             // si la règle d'axiome ne s'applique pas, ajout                  à la file
             if (seq.add(psi.phi1))
                 file.add(seq);
             // si la règle d'axiome ne s'applique pas, ajout                  à la file
             if (clone.add(psi.phi2))
                 file.add(clone);
         }
     }
     return true;
 }

   Par le théorème 8.10 de correction et le théorème 8.13 de complétude qui seront démontrés
ci-après, pour vérifier qu’une formule propositionnelle φ est valide, il suffit de vérifier que le
séquent 7− φ est prouvable.
 Formule
 public boolean valide() {
     Sequent seq = new Sequent();
     seq.add(this.getNNF());
     return seq.prouvable();
 }
64                                    INTRODUCTION À LA LOGIQUE


8.3. Correction et complétude. Un séquent 7− Γ est satisfait par une interprétation I, ce qu’on
écrit I Z= Γ, s’il existe une formule témoin ϑ ∈ dom(Γ) telle que I Z= ϑ. On dit qu’un séquent
7− Γ est valide et on écrit Z= Γ si pour toute interprétation I, I Z= Γ.
   Notons que ces définitions généralisent bien les notions de satisfiabilité et de validité des for-
 mules propositionnelles. En effet, si Γ = φ une formule propositionnelle en forme normale
négative, par la définition ci-dessus, 7− φ est satisfait par une interprétation I si et seulement s’il
existe une formule témoin ϑ ∈ dom(Γ) telle que I Z= ϑ ; comme dom(Γ) = {φ}, le seul choix
possible pour ϑ est ϑ = φ, et donc I satisfait 7− φ si et seulement si I Z= φ.
   La correction et la complétude du calcul des séquents montrent qu’un séquent est prouvable si
et seulement s’il est valide. La correction se montre par une simple induction sur les dérivations
en calcul des séquents.
Théorème 8.10 (correction). Si 7−LK0 Γ, alors Z= Γ.
Démonstration. On procède par induction structurelle sur une dérivation de 7− Γ, en montrant
pour chaque règle du calcul des séquents que si les prémisses sont valides, alors la conclusion
l’est aussi.
    Pour (ax) : alors Γ = Γ′ , P, ¬P pour une formule φ. Pour toute interprétation I, soit I Z= P ,
       soit I Z= ¬P ; dans tous les cas I Z= Γ.
    Pour (∨) : alors Γ = Γ′ , φ ∨ ψ où 7−LK0 Γ′ , φ, ψ. Soit I une interprétation quelconque ; alors
       par hypothèse d’induction I Z= Γ′ , φ, ψ. Il existe donc une formule témoin ϑ ∈ dom(Γ′ ) ∪
       {φ, ψ} telle que I Z= ϑ. Si ϑ ∈ {φ, ψ}, alors I Z= φ ∨ ψ, sinon ϑ ∈ dom(Γ′ ) et alors I Z= Γ′ ;
       dans tous les cas I Z= Γ.
    Pour (∧) : alors Γ = Γ′ , φ ∧ ψ où 7−LK0 Γ′ , φ et 7−LK0 Γ′ , ψ. Soit I une interprétation quel-
       conque ; alors par hypothèse d’induction I Z= Γ′ , φ et I Z= Γ′ , ψ. Il existe donc une formule
       témoin ϑ ∈ dom(Γ′ ) ∪ {φ} telle que I Z= ϑ et une formule témoin ϑ′ ∈ dom(Γ′ ) ∪ {ψ}
       telle que I Z= ϑ′ . Si ϑ ∈ dom(Γ′ ) ou ϑ′ ∈ dom(Γ′ ), alors I Z= Γ′ . Sinon, ϑ = φ et ϑ′ = ψ
       et donc I Z= φ ∧ ψ. Dans tous les cas I Z= Γ.                                                □
   Pour la complétude du calcul des séquents, c’est-à-dire montrer que si un séquent est valide,
alors il est prouvable, rappelons qu’une branche d’échec est une branche de recherche de preuve
finie 7− Γ0 , 7− Γ1 , . . . , 7− Γn où aucune règle ne s’applique au séquent 7− Γn ; on appelle un tel
séquent un séquent d’échec.
Propriété 8.11 (contre-modèle des séquents d’échec). Soit 7− Γ un séquent d’échec. Alors il en
existe un contre-modèle, c’est-à-dire une interprétation I telle que I 6Z= Γ.
Démonstration. Par définition d’un séquent d’échec, aucune règle ne s’applique à 7− Γ. Par suite,
     — comme ni (∨) ni (∧) ne s’applique, dom(Γ) ne contient que des littéraux : dom(Γ) =
       {ℓ1 , . . . , ℓk } ;
     — comme (ax) ne s’applique pas non plus, dom(Γ) ne contient pas à la fois un littéral et sa
       négation.
Il existe donc une interprétation I telle que I 6Z= ℓj pour tout 1 ≤ j ≤ k, c’est-à-dire telle que
I 6Z= ℓ1 , . . . , ℓk et donc I 6Z= Γ.                                                          □
Par exemple, les branches d’échec de l’exemple 8.6 se terminent sur le séquent d’échec 7− P, ¬Q, R,
et toute interprétation qui étend [0/P, 1/Q, 0/R] en est un contre-modèle.
    L’idée de la preuve de complétude qui va suivre est que l’existence d’un contre-modèle pour
le séquent d’échec 7− Γn d’une branche d’échec 7− Γ0 , 7− Γ1 , . . . , 7− Γn implique l’existence d’un
contre-modèle pour le séquent 7− Γ0 . Nous nous appuyons pour cela sur une version « séman-
tique » de l’inversibilité de notre calcul des séquents. On dit pour cela qu’une règle est séman-
tiquement inversible si, quand sa conclusion est valide, alors chacune de ses prémisses est aussi
valide.
                                      INTRODUCTION À LA LOGIQUE                                      65


Lemme 8.12 (inversibilité sémantique). Les règles du calcul des séquents sont sémantiquement
inversibles. Plus précisément, si une interprétation I est un contre-modèle d’une prémisse, alors c’est
aussi un contre-modèle de la conclusion.
Démonstration.
   Pour la règle (ax) : comme elle n’a pas de prémisse, elle est bien sémantiquement inversible.
   Pour la règle (∨) : supposons I 6Z= Γ, φ, ψ, donc I 6Z= Γ, I 6Z= φ et I 6Z= ψ. On en déduit que
     I 6Z= φ ∨ ψ, et comme I 6Z= Γ, que I 6Z= Γ, φ ∨ ψ.
   Pour la règle (∧) : supposons que I 6Z= Γ, φ (le cas où I 6Z= Γ, ψ est similaire). Donc I 6Z= Γ et
     I 6Z= φ. On en déduit que I 6Z= φ ∧ ψ et donc, puisque I 6Z= Γ, que I 6Z= Γ, φ ∧ ψ.           □
   Dans l’exemple 8.6, toute interprétation I qui étend [0/P, 1/Q, 0/R] est un contre-modèle du
séquent 7− P, ¬Q, R, et par applications successives du lemme 8.12 d’inversibilité sémantique,
on en déduit que I est un contre-modèle du séquent initial 7− (P ∨ ¬Q) ∨ (¬P ∧ R), qui n’est
donc pas valide. C’est ce raisonnement que nous généralisons pour démontrer le théorème de
complétude.
Théorème 8.13 (complétude). Si Z= Γ, alors 7−LK0 Γ.
 Démonstration. On procède par contraposition : on suppose 7− Γ non prouvable, et on montre
que 7− Γ n’est pas valide, en exhibant un contre-modèle du séquent 7− Γ, c’est-à-dire une inter-
prétation I telle que I 6Z= Γ.
    On commence par observer que si 7− Γ n’est pas prouvable, alors il existe une branche d’échec.
En effet, par la propriété 8.7, les branches de recherche de preuve sont finies, donc elles ter-
 minent toutes soit par un séquent d’échec, soit par une instance de la règle d’axiome. Mais si
7− Γ avait une recherche de preuve où toutes les branches se terminaient par une instance de la
 règle d’axiome, alors cette recherche aurait construit une dérivation et donc 7− Γ serait prouvable.
    Soit donc 7− Γ0 , . . . , 7− Γn une branche d’échec où 7− Γ0 = 7− Γ et où 7− Γn est un séquent
d’échec. Par la propriété 8.11 de contre-modèle des séquents d’échec, il existe un contre-modèle
 I de 7− Γn , tel que I 6Z= Γn .
    On montre par récurrence décroissante sur n ≥ i ≥ 0 que I 6Z= Γi . Pour le cas de base au rang
 i = n, on avait bien choisi I tel que I 6Z= Γn . Pour l’étape de récurrence au rang i − 1, on sait par
 hypothèse de récurrence que I 6Z= Γi , et par le lemme 8.12 d’inversibilité sémantique, I 6Z= Γi−1 .      On peut remarquer que, puisque le
                                                                                                          calcul des séquents est correct et
Pour conclure, on a montré qu’il existait un contre-modèle I de 7− Γ0 , c’est-à-dire de 7− Γ, qui         complet, l’inversibilité syntaxique et
 n’est donc pas valide.                                                                              □    l’inversibilité sémantique sont deux
                                                                                                          propriétés équivalentes : la première
                                                                                                          parle de prouvabilité, tandis que la
                                                                                                          seconde parle de validité.
                                           66                                       INTRODUCTION À LA LOGIQUE


                                                                                     9. * Clauses de HoRn

                                                 Résumé. Une clause de HoRn est une clause où au plus un littéral est positif. On repré-
                                                 sente habituellement une telle clause sous la forme d’une implication P ⇐ Q1 ∧ · · · ∧ Qk ,
                                                 ou sous la forme ⊥ ⇐ Q1 ∧ · · · ∧ Qk s’il n’y a aucun littéral positif (une telle clause est
                                                 alors appelée négative).
                                                     Pour tout ensemble S de clauses de HoRn, il existe une interprétation IS telle que S
                                                 soit satisfiable si et seulement si IS Z= S, et qui est minimale au sens où elle met le moins
                                                 de propositions possible à 1 (voir le théorème 9.9). En fait, quand S est satisfiable, cette in-
                                                 terprétation met une proposition à 1 si et seulement si la proposition est une conséquence
                                                 logique de S (voir la proposition 9.10).
                                                      L’ensemble des propositions vraies dans IS peut-être calculé en temps linéaire en la
                                                 taille de l’ensemble de clauses S (voir la section 9.2.3). Cela permet de résoudre HoRnSAT
                                                 – la variante de SAT où les clauses fournies en entrée sont toutes des clauses de HoRn –
                                                 en temps linéaire dans le pire des cas.

                                                Une clause de HoRn est une clause où au plus un littéral est positif.

                                                Exemple 9.1. Considérons la formule propositionnelle
                                                    Q ∧ ((Q ∧ (P ∨ R)) ⇒ S) ∧ ¬(P ′ ∧ Q) ∧ S ∧ ((P ⇒ ¬R) ∨ P ) ∧ ((Q ∧ S) ⇒ R) .
                                                Cette formule est logiquement équivalente à la formule sous forme normale conjonctive
                                                Q ∧ (¬Q ∨ ¬P ∨ S) ∧ (¬Q ∨ ¬R ∨ S) ∧ (¬P ′ ∨ ¬Q) ∧ S ∧ (¬P ∨ ¬R ∨ P ) ∧ (¬Q ∨ ¬S ∨ R) ,
                                                et sous forme clausale comme
                                                    {{Q}, {¬Q, ¬P, S}, {¬Q, ¬R, S}, {¬P ′ , ¬Q}, {S}, {¬P, ¬R, P }, {¬Q, ¬S, R}} .
                                                Chaque clause dans cette forme clausale contient au plus un littéral positif : c’est donc un
                                                ensemble de clauses de HoRn.
                                              On appelle une clause de HoRn sans littéral positif ¬Q1 ∨ · · · ∨ ¬Qk une clause négative et on
                                           l’écrit plutôt sous la forme ⊥ ⇐ Q1 ∧ · · · ∧ Qk ; une telle clause non négative peut aussi être vue
                                           comme une règle de déduction Q1 ···Q
                                                                              ⊥
                                                                                 k
                                                                                    . On appelle une clause de HoRn avec un littéral positif
                                           P ∨¬Q1 ∨· · ·∨¬Qk une clause non négative et on l’écrit plutôt sous la forme P ⇐ Q1 ∧· · ·∧Qk ;
 En intelligence artificielle, on parle   une telle clause non négative peut aussi être vue comme une règle de déduction Q1 ···Q P
                                                                                                                                     k
                                                                                                                                       .
souvent de base de connaissance (ou KB
de l’anglais « knowledge base ») pour
un ensemble de clauses de HoRn.                 Exemple 9.2. Les clauses de l’exemple 9.1 peuvent être écrites de manière équivalente comme
                                                l’ensemble de clauses de HoRn
                                                       {Q, S ⇐ Q ∧ P, S ⇐ Q ∧ P ′ , ⊥ ⇐ P ′ ∧ Q, S, P ⇐ P ∧ R, R ⇐ Q ∧ S} .
                                                On peut aussi voir cet ensemble comme le système de déduction fini ci-dessous.
                                                                     Q P         Q P′          P′       Q           P       R    Q S
                                                             Q        S           S                 ⊥       S           P         R

                                                Les clauses de HoRn ont plusieurs intérêts :
                                                — leur problème de satisfiabilité peut être résolu de manière très efficace, à savoir en temps
                                                   linéaire,
                                                — un système de déduction sur un ensemble fini n’est jamais qu’un ensemble de clauses de
                                                   HoRn,
                                                — c’est le format employé en programmation logique, par exemple par le langage Prolog, et
                                                   en bases de données par le langage Datalog.
                                        INTRODUCTION À LA LOGIQUE                                          67


9.1. Modèle minimal. Dans cette section, on va utiliser un ordre partiel sur les interprétations
(similaire à celui utilisé sur les fonctions booléennes) : I ≤ I ′ si et seulement si, pour toute                L’ensemble BP0 des interprétations
                                                                                                                ordonnées par ≤ forme un treillis
proposition P ∈ P0 , I Z= P implique I ′ Z= P . On note I0 pour l’interprétation constante égale                complet où, pour toute
à 0, c’est-à-dire telle que I0 6Z= P pour toute proposition P ∈ P0 ; alors I0 ≤ I pour toute                    proposition P ∈ P0 , (I ∨ I 0 ) Z= P si
interprétation I ∈ BP0 .                                                                                        I Z= P ou I 0 Z= P , et (I ∧ I 0 ) Z= P si
   La propriété centrale des clauses de HoRn est qu’elles ont un modèle minimal pour cet ordre ≤                I Z= P et I 0 Z= P .
sur les interprétations.
Propriété 9.3 (modèle minimal). Soit S un ensemble de clauses de HoRn. Si S est satisfiable, alors
il a un modèle minimal.
9.1.1. Les fonctions fS . Une des manières de démontrer la propriété 9.3 est de construire explici-              On peut aussi démontrer la
                                                                                                                propriété 9.3 en montrant que l’ensemble
tement ce modèle minimal. Soit S un ensemble de clauses de HoRn. Cet ensemble détermine une                     des modèles Sat(S) d’un ensemble S de
fonction fS : BP0 → BP0 définie pour toute interprétation I ∈ BP0 et toute proposition P ∈ P0                   clauses de HoRn est fermé par ∧
par                                                                                                             (Knuth, 2008, sec. 7.1.1, thm. H).
              fS (I) Z= P si ∃(P ⇐ Q1 ∧ · · · ∧ Qk ) ∈ S . ∀1 ≤ i ≤ k . I Z= Qi .               (5)
                  ′
À noter que si S ⊆ S est le sous-ensemble des clauses non-négatives de S, alors fS = fS : les
                                                                                      ′

clauses négatives n’interviennent pas dans l’équation (5).

  Exemple 9.4. Reprenons les clauses de l’exemple 9.2 et considérons l’interprétation I telle
  que I Z= P et I Z= R et ce sont les seules propositions satisfaites par I ; autrement dit,
  I def
    = I0 [1/P, 1/R]. Alors fS (I) Z= Q, fS (I) Z= S et fS (I) Z= P en utilisant les clauses Q, S et
  P ⇐ P ∧R de l’ensemble de clauses, et ce sont les seules propositions satisfaites par fS (I) ; au-
  trement dit fS (I) = I0 [1/Q, 1/S, 1/P ]. Intuitivement, cela correspond aux trois propositions
  que l’on peut déduire en une étape de déduction depuis les propositions satisfaites par I.

Propriété 9.5 (monotonie de fS ). La fonction fS est monotone : I ≤ I ′ implique fS (I) ≤ fS (I ′ ).
Démonstration. Supposons I ≤ I ′ et soit P une proposition telle que fS (I) Z= P : on cherche à
montrer que fS (I ′ ) Z= P – ce qui montrera fS (I) ≤ fS (I ′ ). Par définition de fS dans l’équa-
tion (5), puisque fS (I) Z= P , il existe une clause P ⇐ Q1 ∧ · · · ∧ Qk dans S telle que I Z= Qi
pour tout 1 ≤ i ≤ k. Comme I ≤ I ′ , on a aussi I ′ Z= Qi pour tout 1 ≤ i ≤ k. Par définition
de fS , on a bien fS (I ′ ) Z= P .                                                              □

  Exemple 9.6. Pour compléter l’exemple 9.4, considérons I ′ telle que I ′ Z= Q, I ′ Z= P , I ′ Z= R
  et I ′ Z= S et ce sont les seules propositions satisfaites par I ′ ; autrement dit, I ′ def = I[1/Q, 1/S].
  Alors fS (I ′ ) Z= Q, fS (I ′ ) Z= S, fS (I ′ ) Z= P , et fS (I ′ ) Z= R et ce sont les seules propositions
  satisfaites par fS (I ′ ). On a fS (I ′ ) = fS (I)[1/R] qui vérifie bien fS (I) ≤ fS (I ′ ).

Lemme 9.7. Soit S ′ un ensemble de clauses non négatives de HoRn. Alors I Z= S ′ si et seulement
si fS ′ (I) ≤ I.
Démonstration. Si I Z= S ′ , alors pour toute clause C = (P ⇐ Q1 ∧ · · · ∧ Qk ) ∈ S ′ , I Z= C.
                    Z P , c’est-à-dire si I Z= Qi pour tout 1 ≤ i ≤ k, alors I Z= P . Cela montre
Dès lors, si fS (I) =
fS ′ (I) ≤ I.
    Inversement, supposons que fS ′ (I) ≤ I, et considérons une clause non négative C = (P ⇐
Q1 ∧ · · · ∧ Qk ) ∈ S ′ : on veut montrer que I Z= C.
    — S’il existe 1 ≤ i ≤ k tel que I 6Z= Qi , alors I Z= C ;
    — sinon, nécessairement I =   Z Qi pour tout 1 ≤ i ≤ k, et alors fS (I) Z= P et comme fS (I) ≤
        I on en déduit I Z= P et donc encore une fois I Z= C.                                    □
   À titre d’exemple, l’interprétation I def = I0 [1/P, 1/R] de l’exemple 9.4 est telle que fS (I) 6⊆ I
et effectivement I 6Z= Q. L’interprétation I ′ def = I0 [1/P, 1/Q, 1/R, 1/S] de l’exemple 9.6 est telle
que fS (I ′ ) ≤ I ′ et effectivement I ′ satisfait toutes les clauses de l’exemple 9.2.
                                                68                                     INTRODUCTION À LA LOGIQUE


                                                9.1.2. Itérations de la fonction fS . En itérant la fonction fS à partir de l’interprétation I0 , par
                                                monotonie de fS on définit une chaîne d’interprétations I0 ≤ fS (I0 ) ≤ fS2 (I0 ) ≤ · · · dont la
                                                                                   W
                                                limite est l’interprétation IS def
                                                                               = n∈N fSn (I0 ), qui est telle que, pour toute proposition P ∈ P0 ,
                                                                         IS Z= P si et seulement si ∃n ∈ N . fSn (I0 ) Z= P .                          (6)
                                                Dans le cas de l’ensemble de clauses de l’exemple 9.2, on obtient la chaîne I0 ≤ I0 [1/Q, 1/S] ≤
                                                I0 [1/Q, 1/R, 1/S] ≤ I0 [1/Q, 1/R, 1/S] ≤ · · · qui se stabilise sur IS = I0 [1/Q, 1/R, 1/S].
 Le lemme 9.8 montre que                       Lemme 9.8. Soit S un ensemble de clauses de HoRn. Alors IS est la plus petite interprétation telle
l’interprétation IS est le plus petit point
fixe de la fonction fS dans le treillis
                                                que fS (IS ) ≤ IS .
complet (BP0 , ≤).
                                                Démonstration. Montrons tout d’abord que fS (IS ) ≤ IS . Considérons pour cela une proposi-
                                                tion P telle que fS (IS ) Z= P et montrons que IS Z= P . Par définition de fS dans l’équation (5),
                                                puisque fS (IS ) Z= P , il existe une clause non négative C = (P ⇐ Q1 ∧ · · · ∧ Qk ) ∈ S où
                                                IS Z= Qi pour tout 1 ≤ i ≤ k. Par l’équation (6), pour chaque 1 ≤ i ≤ k il existe donc un
                                                indice ni tel que fSni (I0 ) Z= Qi . Dès lors, si l’on définit n def
                                                                                                                 = max1≤i≤k ni , fSn (I0 ) Z= Qi pour tout
                                                1 ≤ i ≤ k par monotonie de fS , donc fS (I0 ) Z= P , ce qui implique IS Z= P par l’équation (6).
                                                                                             n+1

                                                    Soit maintenant I une interprétation telle que fS (I) ≤ I. On montre par récurrence sur n que
                                                fSn (I0 ) ≤ I pour tout n, ce qui impliquera IS ≤ I d’après l’équation (6). Pour le cas de base au
                                                rang n = 0, I0 ≤ I. Pour l’étape de récurrence n + 1, fSn (I0 ) ≤ I par hypothèse de récurrence
                                                au rang n + 1, donc fSn+1 (I0 ) = fS (fSn (I0 )) ≤ fS (I) par monotonie de fS , et donc finalement
                                                fSn+1 (I0 ) ≤ I puisque fS (I) ≤ I.                                                                     □

                                                    À noter que l’interprétation I ′ def
                                                                                      = I0 [1/P, 1/Q, 1/R, 1/S] de l’exemple 9.6 était bien telle
 On a même fS      (I 0 )=  I0, autrement      que fS (I ′ ) ≤ I ′ , mais ce n’est pas la plus petite interprétation avec cette propriété : IS def
                                                                                                                                                =
dit I 0 est un point fixe de la fonction fS ,
mais ce n’est pas le plus petit.
                                                I0 [1/Q, 1/R, 1/S] est plus petite.
                                                   Nous déduisons maintenant une preuve de la propriété 9.3 : le modèle minimal de S est l’in-
                                                terprétation IS que nous avons construite.
                                                Théorème 9.9. Soit S un ensemble de clauses de HoRn. Alors S est satisfiable si et seulement si
                                                IS Z= S, et dans ce cas IS est le modèle minimal de S.
                                                Démonstration. Soit S ′ ⊆ S le sous-ensemble des clauses non négatives de S. Cet ensemble
                                                est toujours satisfiable, par exemple par l’interprétation I1 telle que I Z= P pour toute propo-
                                                sition P ∈ P0 . Par les lemmes 9.7 et 9.8 et en notant que fS = fS ′ , IS est donc la plus petite
                                                interprétation telle que IS Z= S ′ .
                                                    Supposons IS Z= S. Alors S est satisfiable, et il reste à montrer que IS est le modèle minimal
                                                de S. En effet, si I ≤ IS est une interprétation telle que I Z= S, alors I Z= S ′ et par les lemmes 9.7
                                                et 9.8, IS ≤ I.
                                                    Supposons maintenant S satisfiable et montrons que IS Z= S. Tout modèle I de S est en
                                                particulier un modèle de S ′ , donc IS ≤ I puisque IS est minimal. De plus, pour toute clause
                                                négative C = (⊥ ⇐ Q1 ∧ · · · ∧ Qk ) ∈ S, comme I Z= C, il existe 1 ≤ i ≤ k tel que I 6Z= Qk .
                                                Donc IS 6Z= Qk et IS Z= C.                                                                           □
                                                9.2. HoRnSAT. Le problème de satisfiabilité associé aux clauses de HoRn est la restriction sui-
                                                vante de SAT :
                                                Problème (HoRnSAT).
                                                   instance : un ensemble fini F de clauses de HoRn
                                                   question : F est-il satisfiable ?
                                                   Une manière naturelle de résoudre HoRnSAT est de calculer l’interprétation IF définie par
                                                l’équation (6) : alors par le théorème 9.9, F est satisfiable si et seulement si IF Z= F , et cette
                                                dernière étape se vérifie en temps linéaire une fois qu’on a calculé IF .
                                      INTRODUCTION À LA LOGIQUE                                     69


9.2.1. Conséquences logiques d’un ensemble de clauses de HoRn. Un autre problème souvent consi-
déré sur des ensembles S de clauses de HoRn est de déterminer quelles en sont les conséquences
logiques au sens de la section 4.1.
   On a vu dans le théorème 9.9 que tout ensemble satisfiable S de clauses de HoRn a un modèle
minimal, qui peut être calculé d’après l’équation (6) en itérant la fonction fS de l’équation (5)
sur l’interprétation I0 . Un autre point de vue sur ce modèle minimal est qu’il met à vrai une
proposition P si et seulement si cette proposition est une conséquence logique de l’ensemble S.
Proposition 9.10. Soit S un ensemble de clauses de HoRn. Si S est satisfiable, alors pour toute           Si S est insatisfiable, alors S Z= P
                                                                                                         pour tout P ∈ P0 .
proposition P ∈ P0 , IS Z= P si et seulement si S Z= P .
Démonstration. Supposons S satisfiable.
   Montrons tout d’abord que S Z= P implique IS Z= P pour toute proposition P . D’après
le théorème 9.9, puisque S est satisfiable, IS Z= S. Par définition d’une conséquence logique,
IS Z= P .
     Montrons maintenant que IS Z= P implique S Z= P pour toute proposition P . Si on note I
l’interprétation telle que I Z= P si et seulement si S Z= P , cela revient à montrer que IS ≤ I. Par
le lemme 9.8, il suffit donc de montrer que fS (I) ≤ I.
     Soit P une proposition telle que fS (I) Z= P : on veut montrer que S Z= P (ce qui montrera
bien I Z= P ). Pour montrer S Z= P , par définition d’une conséquence logique, on suppose que
I ′ Z= S pour une interprétation I ′ et on montre que I ′ Z= P .
     Puisque fS (I) Z= P , par définition de fS dans l’équation (5), il existe une clause non-négative
P ⇐ Q1 ∧ · · · ∧ Qk dans S telle que I Z= Qi pour tout 1 ≤ i ≤ k, c’est-à-dire par définition
de I telle que S Z= Qi pour tout 1 ≤ i ≤ k. Chaque Qi est donc une conséquence logique de S ;
puisque I ′ Z= S on a donc I ′ Z= Qi pour tout 1 ≤ i ≤ k. De plus, I ′ Z= S donc I ′ Z= (P ⇐
Q1 ∧ · · · ∧ Qk ) : cela montre bien I ′ Z= P .                                                     □

   Voici un problème de décision typiquement considéré en intelligence artificielle.
Problème (Conséquence de HoRn).
  instance : un ensemble fini F de clauses de HoRn non-négatives et une proposition P
  question : est-ce que P est une conséquence logique de F ?
   Comme F ne contient que des clauses non-négatives, il est satisfiable. Le proposition 9.10
s’applique donc et montre qu’il suffit de calculer IF le modèle minimal de F et de vérifier si
IF Z= P . Cela peut aussi être résolu à l’aide d’un solveur pour HoRnSAT : en effet, par le lemme 4.2
de déduction, l’ensemble de clauses F ∪ {⊥ ⇐ P } est insatisfiable si et seulement si F Z= P .

9.2.2. Algorithme naïf. Pour les deux problèmes et , on a vu que si on est capable de calculer le
modèle minimal IF d’un ensemble F de clauses de HoRn non-négatives, alors il est ensuite aisé
de répondre.
   Fixons un tel ensemble F de clauses non-négatives. Les interprétations I ∈ Bfp(F ) vont être
représentées comme des ensembles E dans 2fp(F ) : on aura alors P ∈ E si et seulement I Z= P .
Le calcul de IF par itération de la fonction fF comme défini dans les équations (5) et (6) va être
remplacé par un calcul équivalent sur des ensembles. Définissons
              E≤n def                       j
                  = {P ∈ fp(F ) | ∃j ≤ n . fF (I0 ) Z= P }                                         (7)
ainsi que la fonction gF : 2fp(F ) → 2fp(F ) par
            gF (E) def
                   = {P ∈ fp(F ) | ∃P ⇐ Q1 ∧ · · · ∧ Qk . ∀1 ≤ i ≤ k . Qi ∈ E} .                   (8)


Propriété 9.11. E≤0 = ∅ et pour tout n ∈ N, E≤n+1 = E≤n ∪ gF (E≤n ).
70                                      INTRODUCTION À LA LOGIQUE


Démonstration. Par récurrence sur n. Pour le cas de base n = 0,
      E≤0 = {P ∈ fp(F ) | ∃j ≤ 0 . fFj (I0 ) Z= P }                       par (7)
            = {P ∈ fp(F ) | I0 Z= P }
            =∅.
Pour l’étape de récurrence n + 1,
 E≤n+1 = {P ∈ fp(F ) | ∃j ≤ n + 1 . fFj (I0 ) Z= P }                      par (7)
            =   {P ∈ fp(F ) | ∃j ≤ n . fFj (I0 ) Z= P } ∪ {P     ∈ fp(F ) | fFn+1 (I0 ) Z= P }
            =   E≤n ∪ {P ∈ fp(F ) | fFn+1 (I0 ) Z= P }                    par h.r.
            =   E≤n ∪ {P ∈ fp(F ) | fF (fFn (I0 )) Z= P }
            =   E≤n ∪ gF ({P ∈ fp(F ) | fFn (I0 ) Z= P })                 par (5) et (8)
            = E≤n ∪ gF ({P ∈ fp(F ) | ∃j ≤ n .      fFj (I0 )   Z= P })   car ∀j ≤ n . fFj (I0 ) ≤ fFn (I0 )
            = E≤n ∪ gF (E≤n ) .                                           par h.r.                             □

     Exemple 9.12. Reprenons l’exemple 9.2 sans sa clause négative : F def
                                                                       = {Q, S ⇐ Q ∧ P, S ⇐
     Q ∧ P ′ , S, P ⇐ P ∧ R, R ⇐ Q ∧ S}. On a les ensembles suivants : E≤0 = ∅, E≤1 = {Q, S},
     E≤2 = {Q, R, S} = E≤n pour tout n ≥ 2.

   La propriété 9.11 fournit un premier algorithme naïf pour calculer le modèle minimal d’un
ensemble F de clauses non-négatives.

     Fonction horn(F )
                     ′
      1 E := ∅; E := ∅
      2 répéter
      3     E := E ∪ E ′
      4     E ′ := ∅
      5     pour chaque C = (P ⇐ Q1 ∧ · · · ∧ Qk ) ∈ F faire
      6          si (P 6∈ E) and (∀1 ≤ i ≤ k . Qi ∈ E) alors E ′ := E ′ ∪ {P }
      7   jusqu’à E ′ = ∅
      8   retourner E

  Au (n+1)e passage dans le corps de la boucle principale des lignes 3 à 6, la variable E contient
E≤n , tandis que la variable E ′ contient à la fin de la boucle
                                        ′   def
                                       En+1 = gF (E≤n ) \ E≤n .                                           (9)
Dans l’exemple 9.12, onSa ainsi E1′ = {Q, S}, E2′ = {R} et E3′ = ∅.
   On a donc E≤n = 0<j≤n Ej′ : les ensembles Ej′ forment une partition de E≤n , et l’algo-
rithme s’arrête dès que Ej′ = ∅. Autrement dit, on ajoute à chaque nouveau passage dans la
boucle principale au moins une proposition parmi fp(F ) à l’ensemble E, donc on peut faire au
plus |fp(F )| + 1 passages dans la boucle principale.
   Chacun de ces passages passe par la boucle des lignes 5 et 6, qui, du fait des tests Qi ∈ E pour
tout 1 ≤ i ≤ k et pour toute clause P ⇐ Q1 ∧ · · · ∧ Qk de F , a un coût en O(kF k · e(|fp(F )|) si
                                                            P
   — on définit la taille de F comme la somme kF k def   =     C∈S |C| des tailles de ses clauses
       (c’est-à-dire la somme des nombres de littéraux présents dans chaque clause) et
   — e(|fp(F )|) borne le coût d’accès dans un sous-ensemble E de fp(F ). Ce coût peut varier :
       par exemple, avec un arbre binaire de recherche, il est en O(log |fp(F )|), tandis qu’avec
       une table de hachage il est en O(1) si on suppose un hachage parfait mais peut atteindre
                                      INTRODUCTION À LA LOGIQUE                                     71


      O(|fp(F )|) dans le pire des cas sinon ; enfin si |fp(F )| n’est pas trop grand on peut aussi
      représenter E comme une tableau de booléens (bit vector) indexé par fp(F ) avec des accès
      en O(1).
La ligne 3 a quant à elle un coût en |fp(F )| · e(|fp(F )|) si on ajoute un à un les éléments de E ′
dans E. La complexité en temps de cet algorithme naïf est donc en O(|fp(F )| · kF k · e(|fp(F )|),
qui est au moins quadratique.




9.2.3. Algorithme en temps linéaire. Le principal problème dans l’algorithme précédent est qu’il          Cet algorithme est dû à Dowling et
                                                                                                         GallieR (1984) dans sa présentation
faut passer en revue toutes les clauses P ⇐ Q1 ∧ · · · ∧ Qk de F à la ligne 5 puis pour chaque Qi        pour HoRnSAT ; c.f. (Knuth, 2008,
de tester si Qi ∈ E à la ligne 6.                                                                        sec. 7.1.1, algo. C).
    Une idée pourrait être d’utiliser la simplification de clauses comme vue dans l’algorithme           Le même algorithme était cependant
                                                                                                         déjà connu pour un problème équivalent
DPLL : à la ligne 3, à chaque fois qu’on ajoute une proposition Q à l’ensemble E, on pourrait            sur les grammaires algébriques, c.f.
simplifier l’ensemble de clauses F par le littéral P . Pour une clause non-négative de HoRn P ⇐          (HaRRison, 1978, p. 97), (Sippu et
Q1 ∧ · · · ∧ Qi−1 ∧ Qi ∧ Qi+1 ∧ · · · ∧ Qk , sa simplification par Qi est la clause P ⇐ Q1 ∧ · · · ∧     Soisalon-Soininen, 1988, thm. 4.14).
Qi−1 ∧ Qi+1 ∧ · · · ∧ Qk . Cela permet d’éviter de tester si Qi ∈ E lors des tests de la ligne 6. Pour
l’exemple 9.12, les ensembles de clauses sur lesquels on travaille deviennent alors F0 = F =
{Q, S ⇐ Q ∧ P, S ⇐ Q ∧ P ′ , S, P ⇐ P ∧ R, R ⇐ Q ∧ S}, puis F1 = {P ⇐ P ∧ R, R} après
simplification par Q et S, et enfin F2 = {P ⇐ P } après simplification par R. Cette étape de
simplification nécessite cependant toujours une passe sur toutes les clauses restantes à chaque
passage par la boucle principale.




   Le principe de l’algorithme en temps linéaire est de construire un tableau contient qui donne
pour chaque proposition Q ∈ fp(F ) la liste des clauses P ⇐ Q1 ∧ · · · ∧ Qk de F telles que
Q = Qi pour un certain i. De plus, au lieu de simplifier les clauses, on va utiliser un compteur
qui dit pour chaque clause P ⇐ Q1 ∧ · · · ∧ Qk combien de propositions parmi Q1 , . . . , Qk n’ont
pas encore été ajoutées à l’ensemble E. La figure 20 illustre ces structures pour l’exemple 9.12.



                contient                                     compteur      F
                                                                  0,   Q
                   P                       null                   2,   S ⇐Q∧P
                   P′              null                           2,   S ⇐ Q ∧ P′
                   Q                              null            0,   S
                   R               null                           2,   P ⇐P ∧R
                   S               null                           2,   R⇐Q∧S


        FiguRe 20. Les structures de données initiales de l’algorithme en temps linéaire.



   Ces structures initiales sont construites aux lignes 2 à 9 de l’algorithme suivant, dans lesquelles
on initialise aussi E et E ′ pour contenir toutes les propositions dont le compte est initialement
zéro (Q et S dans l’exemple de la figure 20).
72                                          INTRODUCTION À LA LOGIQUE


     Fonction horn(F )
                   ′
      1 E := ∅; E := ∅
      2 pour chaque Q ∈ fp(F ) faire
      3     contient[Q] := null (liste des clauses contenant ¬Q, initialement vide)
       4   pour chaque C = (P ⇐ Q1 ∧ · · · ∧ Qk ) ∈ F faire
       5      compteur[C] := k (nombre de littéraux à traiter de la clause C)
       6      pour chaque 1 ≤ i ≤ k faire
       7         contient[Qi ].add(C) (ajout à la liste)
       8       si k = 0 alors
       9           E := E ∪ {P }; E ′ := E ′ ∪ {P }


   À l’issue de cette initialisation, on a les invariants suivants pour n = 1, qui vont rester vrais
à chaque ne entrée ligne 12 dans la boucle principale donnée ci-dessous :
            S
  (1) E = j≤n Ej′ ,
     (2) E ′ = En′
                                                                                       S
     (3) ∀C = (P ⇐ Q1 ∧ · · · ∧ Qk ) ∈ F , compteur[C] = {1 ≤ i ≤ k | Qi 6∈                0<j<n   Ej′ } .

      12   tant que E ′ 6= ∅ faire
      13      E ′′ := ∅
      14      pour chaque Q ∈ E ′ faire
      15           pour chaque C = (P ⇐ Q1 ∧ · · · ∧ Qk ) ∈ contient[Q] faire
      16              si P 6∈ E alors
      17                  compteur[C] := compteur[C] − 1
      18                  si compteur[C] = 0 alors (c’est-à-dire si Qi ∈ E pour tout 1 ≤ i ≤ k)
      19                      E := E ∪ {P }; E ′′ := E ′′ ∪ {P }

      20       E ′ := E ′′
      21   retourner E

    La mise à jour de E ′′ à la ligne 19 se fait en effet quand compteur[C] = 0, c’est-à-dire quand
toutes les propositions Qi de la clause C sont dans E. L’algorithme termine quand E ′ = ∅.
    En ce qui concerne la complexité de l’algorithme, la phase d’initialisation est en temps O(kF k·
e(|fp(F )|)). Pour la boucle principale, il faut remarquer que, comme les ensembles E ′ successifs,
on ne passe par la ligne 14 qu’au plus une fois par proposition Q ∈ fp(F ) pendant l’exécution.
Cela signifie que pour chaque clause C = (P ⇐ Q1 ∧ · · · ∧ Qk ) ∈ F , on ne passe par la ligne 15
qu’au plus k fois sur la totalité de l’exécution de l’algorithme ; la boucle principale s’exécute donc
elle aussi en O(kF k · e(|fp(F )|)).
    Si on utilise un tableau de booléens pour représenter l’ensemble E, alors e(|fp(F )|) est en
temps constant O(1) et cet algorithme travaille en temps linéaire dans le pire des cas.
Proposition 9.13. Soit F un ensemble fini de clauses de HoRn. Alors on peut calculer IF en temps
déterministe O(kF k · e(|fp(F )|)) où e(|fp(F )|) borne le coût des opérations d’accès dans des sous-
ensembles de fp(F ).
9.2.4. Implémentation de l’algorithme en temps linéaire en Java. Voici comment on pourrait im-
plémenter l’algorithme de la section 9.2.3 en Java. Pour commencer, on peut étendre la classe
Clause de la section 5.2.4 pour traiter les clauses de HoRn. On code ici encore les clauses en
« style DIMACS », c’est-à-dire avec des entiers strictement positifs pour coder les propositions.
                                    INTRODUCTION À LA LOGIQUE                                    73


Une clause de la forme P ⇐ Q1 ∧ · · · ∧ Qk ou de la forme ⊥ ⇐ Q1 ∧ · · · ∧ Qk est représentée
par un objet de la classe HornClause suivante.
 HornClause.java
 public class HornClause {
     // La proposition P (ou 0 pour ⊥ dans une clause négative).
     private int head;
     // L'ensemble de propositions {Q1 , . . . , Qk }.
     private Set<Integer> tail;

      public int head() {
          return head;
      }
      public Set<Integer> tail() {
          return tail;
      }

   Afin d’implémenter le compteur associé à chaque clause, on ajoute aussi un attribut count
ainsi qu’une méthode pour le décrémenter à la ligne 17 de l’algorithme.
 HornClause.java
 // Le nombre de propositions Q1 , . . . , Qk qui restent à traiter ; initialement k .
 private int count;
 // Décrémente le compte associé à la clause et retourne true si ce
 // compte tombe à 0.
 protected boolean decrement() {
     count--;
     return count == 0;
 }

   Voici enfin une implémentation possible de l’algorithme de la section 9.2.3. Une différence avec
cet algorithme est qu’on ne suppose pas que l’ensemble de clauses F (représenté par clauses)
ne contienne uniquement des clauses non-négatives. La variable E, qui représente le modèle
minimal si F est satisfiable, est vue comme un int[], tandis que les variables E ′ et E ′′ sont des
LinkedList<Integer>.
 Horn.java
 private Collection<HornClause> clauses; // l'ensemble F
 private int[] interpretation;           // l'ensemble E
 public boolean satisfiable() {
     @SuppressWarnings("unchecked")
     final Collection<HornClause>[] contient =
         (Collection<HornClause>[]) Array.newInstance((Class<LinkedList<HornClause>>)
         new LinkedList<HornClause>().getClass(), nprops);
     Collection<Integer> nouveaux = new LinkedList<Integer>(); // E 0 := ∅

      // initialisation
      for (int i = 0; i < nprops; i++) {
          // pour tout Q ∈ fp(F )
          interpretation[i] = -i-1; // Q ∉ E
          contient[i] = new LinkedList<HornClause>(); // contient[Q] := null
      }
      for (HornClause c : clauses) {
          // pour tout C ∈ F
          if (c.tail().size() == 0) {
              if (c.head() == 0)
74                                  INTRODUCTION À LA LOGIQUE


                       return false;
                   interpretation[c.head()-1] = c.head();   // E := E ∪ {P }
                   nouveaux.add(Integer.valueOf(c.head())); // E 0 := E 0 ∪ {P }
               }
               else
                   for (Integer q : c.tail())
                       // pour tout 1 ≤ i ≤ k
                       contient[q.intValue()-1].add(c); // contient[Qi ].add(C)
         }

         // boucle principale
         while (!nouveaux.isEmpty()) {
             // tant que E 0 6= ∅
             Collection<Integer> tmp = new LinkedList<Integer>(); // E 00 := ∅
             for (Integer q : nouveaux)
                 // pour tout Q ∈ E 0
                 for (HornClause c : contient[q.intValue()-1]) {
                     // pour tout C ∈ contient[Q]
                     int p = c.head();
                     if ((p == 0 || interpretation[p-1] < 0) &&
                         c.decrement()) {
                         if (p == 0)
                               return false;
                         interpretation[p-1] = p;     // E := E ∪ {P }
                         tmp.add(Integer.valueOf(p)); // E 00 := E 00 ∪ {P }
                     }
                 }
             nouveaux = tmp; // E 0 := E 00
         }
         return true;
     }

9.2.5. Implémentation de l’algorithme en temps linéaire en OCaml. Voici pour finir comment on
pourrait implémenter l’algorithme de la section 9.2.3 en OCaml. Une clause de HoRn de la forme
P ⇐ Q1 ∧ · · · ∧ Qk ou ⊥ ⇐ Q1 ∧ · · · ∧ Qk va être représentée par une paire (p,[q₁;…;qₖ])
de type int * int list.
   On définit aussi un type
     horn.ml
     type hc = { p : int; mutable compteur : int }

pour représenter la proposition P (possiblement ⊥, qui est codé par 0) et la valeur du compteur de
la clause. Le tableau contient est alors un hc list array qui fournit pour chaque proposition Q
une liste de structures de type hc. L’ensemble E est représenté par un bool array, tandis que
les ensembles E ′ et E ′′ le sont par des int list.
     horn.ml
     let hornsat: int list list -> bool array = function clauses ->
       let horns    = List.map horn_of_clause clauses in
       let nprops   = 1 + (List.fold_left max 0
                              (List.map (fun i -> if (i<0) then -i else i)
                                 (List.flatten clauses))) in
       let e        = Array .make nprops false (* E := ∅ *) in
       let cur      = ref [] (* E 0 := ∅ *) in
       let contient = Array .make nprops [] (* contient[Q] := null pour tout Q ∈ fp(F ) *)in
       (* initialisation pour chaque clause (P , [Q1 ;…;Qk ]) *)
                                       INTRODUCTION À LA LOGIQUE                                            75


    let initialise (p, qs) =
      let hc = { p = p; compteur = List.length qs } in
      (* la même paire { p; compteur } va être partagée *)
      List.iter (fun q -> contient.(q) <- (ref hc)::contient.(q)) qs;
      (* si le compteur est initialement nul, ajout de P à E et à E 0 *)
      if (hc.compteur = 0) then (e.(p) <- true; cur := p::(!cur))
    in
    List.iter initialise horns;
    (* boucle principale *)
    while ((List.length !cur) > 0) do (* tant que E 0 6= ∅ *)
      let tmp = ref [] (* E 00 := ∅ *) in
      List.iter (fun q -> (* pour tout Q ∈ E 0 *)
          List.iter (fun hc -> (* pour tout C ∈ contient[Q] *)
              if (not e.(!hc.p)) then (* si P 6∈ E *)
                (!hc.compteur <- !hc.compteur - 1; (* compteur[Q] := compteur[Q] − 1 *)
                  if (!hc.compteur = 0) then
                    (* si le compteur tombe à zéro, ajout de P à E et à E 00 *)
                    (e.(!hc.p) <- true; tmp := (!hc.p)::(!tmp))))
            contient.(q)) !cur;
      cur := !tmp
    done;
    e (* retourner E *)


                                                                                            1

                                                                               7

                                                                   8                                2
                                                        9                                               3
                                                                         10                 5
                                                                                        6       4
                                                            11                12

                                                                   13              15

                                                                        14



               FiguRe 21. Plan du campus11 et graphe de circulation automobile.

9.3. Exemple de modélisation : accessibilité dans un graphe orienté. Commençons par un
exemple très simple de modélisation d’un problème sous la forme d’une question de satisfiabilité
d’un ensemble de clauses de HoRn propositionnelles : celui de l’accessibilité dans un graphe fini                 Comme vu dans le cours d’« éléments
orienté. De manière plus concrète, considérons le graphe de la figure 21, qui représente le graphe               d’algorithmique », le problème
                                                                                                                 d’accessibilité peut être résolu
de circulation automobile autour du campus des Grands Moulins 11. Le problème informatique
                                                                                                                 efficacement par des algorithmes de
que l’on souhaite résoudre est l’existence d’un chemin d’un sommet du graphe à un autre. Par                     parcours de graphe.
exemple, on peut aller du sommet 14 au sommet 1, mais l’inverse n’est pas possible.                               La complexité du problème
   L’idée générale de la modélisation à l’aide de formules propositionnelles est d’utiliser une pro-             d’accessibilité dans un graphe orienté est
position par sommet du graphe et d’encoder la relation d’accessibilité à l’aide de clauses de HoRn.              un problème classique en complexité
Dans le cas de la figure 21 avec le sommet 1 en guise de source, cela signifie construire l’ensemble             algorithmique, que vous verrez dans le
                                                                                                                 cours « calculabilité et complexité » ; c.f.
de propositions {P1 , P2 , . . . , P15 } et l’ensemble F suivant de clauses de HoRn, qui contient une
                                                                                                                 (PeRifel, 2014, prop. 4AL) et (ARoRa et
implication Pv ⇐ Pu si et seulement s’il existe un arc (u, v) dans le graphe.                                    BaRaK, 2009, thm. 4.18).
                                                                                                                  Cet ensemble F pourrait aussi
 11. Données géographiques © 2019 Google.                                                                        s’écrire comme un ensemble de clauses
                                                                                                                 utilisent au plus deux littéraux : chaque
                                                                                                                 formule propositionnelle Pv ⇐ Pu est
                                                                                                                 équivalente à ¬Pu ∨ Pv . On parle alors
                                                                                                                 du problème « 2SAT ». Les liens entre
                                                                                                                 accessibilité et 2SAT sont bien connus,
                                                                                                                 voir (CaRton, 2008, thm. 4.47),
                                                                                                                 (PapadimitRiou, 1993, pp. 184–187) ou
                                                                                                                 (Knuth, 2008, sec. 7.1.1, thm. K).
76                                  INTRODUCTION À LA LOGIQUE


 F def
   ={        P2 ⇐ P1 ,    P 7 ⇐ P1 ,     P 1 ⇐ P2 ,     P 3 ⇐ P2 ,    P 2 ⇐ P3 ,     P 4 ⇐ P3 ,
             P5 ⇐ P4 ,    P15 ⇐ P4 ,     P 2 ⇐ P5 ,     P 4 ⇐ P5 ,    P 5 ⇐ P6 ,     P 1 ⇐ P7 ,
             P6 ⇐ P7 ,    P 8 ⇐ P7 ,     P 7 ⇐ P8 ,     P 9 ⇐ P8 ,   P10 ⇐ P8 ,      P 8 ⇐ P9 ,
             P8 ⇐ P10 ,   P11 ⇐ P10 ,   P12 ⇐ P10 ,     P9 ⇐ P11 ,   P10 ⇐ P11 ,     P6 ⇐ P12 ,
            P10 ⇐ P12 ,   P13 ⇐ P12 ,   P15 ⇐ P12 ,    P11 ⇐ P13 ,   P13 ⇐ P14 , P15 ⇐ P14 ,
            P12 ⇐ P15 }
   Cet ensemble de clauses va nous permettre de répondre au problème d’accessibilité grâce à la
propriété suivante.
Propriété 9.14. Soit G = (V, E) un graphe fini dirigé et s ∈ V un sommet source. Soit {Pv | v ∈
V } l’ensemble des propositions associé à son ensemble de sommets et F def= {Pv ⇐ Pu | (u, v) ∈
E} l’ensemble de clauses de HoRn associé à son ensemble d’arcs. Alors, pour tout sommet v ∈ V ,
F ∪ {Ps } Z= Pv si et seulement s’il existe un chemin dirigé de s à v dans G.
   Dès lors, il existe un chemin dirigé d’un sommet source s ∈ V à un sommet cible t ∈ V si et
seulement si F ∪ {Ps } Z= Pt .
   Voici par exemple un fichier au format DIMACS qui vérifie que le sommet 14 n’est pas acces-
sible depuis le sommet 1 dans le graphe de la figure 21. En effet, un chemin de s à t existe si et
seulement si F ∪ {Ps } Z= Pt d’après la propriété 9.14, si et seulement si F ∪ {Ps } ∪ {¬Pt } est
insatisfiable par le lemme 4.2 de déduction.
     accessibilite.cnf
     p cnf 15 33
     c arcs du graphe
      -1 2 0
      -1 7 0
      -2 1 0
      -2 3 0
      -3 2 0
      -3 4 0
      -4 5 0
      -4 15 0
      -5 2 0
      -5 4 0
      -6 5 0
      -7 1 0
      -7 8 0
      -7 6 0
      -8 7 0
      -8 9 0
      -8 10 0
      -9 8 0
     -10 8 0
     -10 11 0
     -10 12 0
     -11 9 0
     -11 10 0
     -12 6 0
     -12 10 0
     -12 13 0
     -12 15 0
     -13 11 0
     -14 13 0
                                   INTRODUCTION À LA LOGIQUE                                  77


 -14 15 0
 -15 12 0
 c sommet source
 1 0
 c sommet destination
 -14 0

   En général, pour un graphe fini dirigé G = (V, E), un sommet source s ∈ V et un sommet
cible t ∈ V , il existe un chemin dirigé de s à t si et seulement si la formule propositionnelle
suivante n’est pas satisfiable :
                                              ^
                                 Ps ∧ ¬Pt ∧         (¬Pu ∨ Pv ) .                           (10)
                                           (u,v)∈E
                                             78                                      INTRODUCTION À LA LOGIQUE


                                             Partie 3. Logique classique du premier ordre
                                                 La logique propositionnelle de la partie 2 est limitée à l’expression de propriétés de propo-
                                             sitions booléennes (interprétées comme vraies ou fausses). Nous allons l’étendre et étudier la
                                             logique du premier ordre (aussi appelée « calcul des prédicats »). Outre les connecteurs booléens
                                             déjà rencontrés (∧, ∨, ¬, ⇒, …), la logique du premier ordre permet de quantifier (∀, ∃) sur des
                                             éléments et dispose d’un vocabulaire enrichi par des symboles auxiliaires de fonction et de rela-
                                             tion. Par exemple, les formules (1), (2) et (3) de l’introduction étaient des formules de la logique
                                             du premier ordre, où les symboles H, M , V , A et R étaient des symboles de relation.


                                                                                         10. StRuctuRes

                                                   Résumé. Une signature du premier ordre L = (F, P) est constituée de symboles de
                                                   fonction f ∈ F et de symboles de relation R ∈ P. On associe une arité dans N à chaque
                                                   symbole et on note « Fn » l’ensemble des symboles de fonction d’arité n et « Pm » l’en-
                                                   semble des symboles de relation d’arité m ; une fonction d’arité zéro est une constante et
                                                   une relation d’arité zéro est une proposition.
                                                      Une interprétation I d’une signature (F, P) est définie par un domaine DI non vide,
                                                   d’une fonction f I : DIn → DI pour tout f ∈ Fn et tout n et d’une relation RI : DIm → B
                                                   pour tout R ∈ Pm et tout m.

                                                 Les formules du premier ordre sont interprétées sur des structures très générales, utilisables
                                             pour modéliser des structures mathématiques (ordres, groupes, corps, etc.) ou des structures re-
                                             lationnelles comme utilisées en bases de données.

                                             10.1. Signatures. On définit tout d’abord une signature du premier ordre (aussi appelée un «
                                             langage du premier ordre ») comme une paire L = (F, P) formée de deux ensembles dénom-
                                             brables F de symboles de fonction et P 6= ∅ de symboles de relation (aussi appelés « symboles
 On peut aussi travailler avec des          de prédicat »), avec F ∩ P = ∅, et tous deux munis d’une fonction d’arité r: F ∪ P → N. On
signatures non dénombrables, mais les
preuves nécessitent alors d’utiliser des     note Fn def                                   def
                                                       = {f ∈ F | r(f ) = n} et Pn = {R ∈ P | r(R) = n} leurs restrictions aux
notions de théorie des ensembles comme       symboles d’arité n. Une fonction d’arité zéro est appelée une constante ; une relation d’arité zéro
le lemme de ZoRn.
                                             est appelée une proposition.

 (DupaRc, 2015, sec. 11.1)                  10.2. Interprétations. Une interprétation I d’une signature L = (F, P) (aussi appelée une
 L’ensemble des formules valides            « L-structure ») est constituée d’un ensemble DI 6= ∅, appelé son domaine ou son support,
change si l’on permet un domaine vide.                                r(f )                                                        r(R)
                                             d’une fonction f I : DI     → DI pour chaque f ∈ F , et d’une relation RI : DI          → B pour
 En théorie des modèles et en théorie       chaque R ∈ P. Une telle interprétation est notée I = (DI , (f I )f ∈F , (RI )R∈P ) ; dans le cas où
des modèles finis (Chang et KeisleR,
1990 ; Ebbinghaus, Flum et Thomas,           =I est l’égalité sur DI , on l’omet dans cette notation.
1994 ; LibKin, 2004), le symbole d’égalité
est toujours présent et interprété comme          Exemple 10.1 (interprétations propositionnelles). Posons F def              def
                                                                                                                    = ∅ et P = {P (0) , Q(0) }. Dans
l’égalité sur DI ; voir la section 15.1.3.
                                                  cette signature, il n’y a pas de symbole de fonction, et il y a deux symboles de relation P et Q,
                                                  tous deux d’arité 0. Une interprétation possible pour cette signature est I de domaine DI def
                                                                                                                                              = {•}
                                                  avec P I def          def
                                                            = 1 et QI = 0.

                                                  Exemple 10.2 (ordres). Posons F def          def
                                                                                     = ∅ et P = {<(2) , =(2) } où l’exposant « (2) » indique un
                                                  symbole d’arité 2. Dans cette signature, il n’y a pas de symboles de fonction, et il y a deux
                                                  symboles de relation d’arité 2. Une interprétation I = (Q, <) pour cette signature est définie
                                                  par DI def       def
                                                         = Q, <I = < l’ordre habituel sur les rationnels et =I l’égalité sur les rationnels.
                                           INTRODUCTION À LA LOGIQUE                                      79


Exemple 10.3 (arithmétique). Posons F def                       def
                                         = {+(2) , ×(2) } et P = {=(2) }. Cette signa-
ture comprend deux fonctions binaires + et ×, et une relation binaire =. Une interpréta-
tion I = (N, +, ×) pour cette signature est définie par DI def
                                                           = N, +I : (n, m) 7→ n + m,
× : (n, m) 7→ nm et = l’égalité sur N.
  I                  I




                                                                 1



                                           0



                                                                 2



                                     FiguRe 22. Un graphe fini orienté.




Exemple 10.4 (graphe fini orienté). Considérons le graphe fini orienté avec des sommets co-
loriés de la figure 22 et voyons comment le décrire comme une structure sur une signature
appropriée. On pose pour cela F def                    def
                                         = ∅ et P = {E (2) , =(2) , B (1) } où E va représenter la
relation d’adjacence du graphe et B indiquer pour chaque sommet s’il est bleu ou non. Le
graphe de la figure 22 correspond alors à l’interprétation I de domaine DI def       = {0, 1, 2} avec
E I def                                             def
    = {(0, 1), (0, 2), (1, 0), (2, 1), (2, 2)}, B I = {1, 2}, et =I l’égalité entre sommets.

Exemple 10.5 (base de donnée relationnelle). Posons L def
                                                      = {F, P) où
           F def
             = {shining(0) , player(0) , easyrider(0) , apocalypsenow(0) , kubrick(0) , altman(0) , hopper(0) ,
                   nicholson(0) , robbins(0) , coppola(0) , champo(0) , odeon(0) }
et
           P def
             = {Film(3) , Seance(2) , =(2) } .
Une interprétation I possible pour cette signature a pour domaine
       DI def
          = {Shining, The Player, Easy Rider, Apocalypse Now, KubRicK, Altman, HoppeR,
                   Nicholson, Robbins, HoppeR, Le Champo, Odéon}
où les constantes sont interprétées de manière évidente, et
     FilmI def
           = {(Shining, KubRicK, Nicholson), (The Player, Altman, Robbins),
                   (Easy Rider, HoppeR, Nicholson), (Easy Rider, HoppeR, HoppeR),
                   (Apocalypse Now, Coppola, HoppeR)} ,
           I def
Seance = {(Le Champo, Shining), (Le Champo, Easy Rider), (Le Champo, The Player),
                   (Odéon, Easy Rider)}
et = est l’égalité sur DI . Cette interprétation correspond aux tables « Films » et « Séances »
       I

de la base de donnée ci-après.
                                            80                                  INTRODUCTION À LA LOGIQUE


                                                                    Films
 En général, une base de donnée                                                                                     Séances
                                                   titre            réalisation interprète
relationnelle peut-être vue comme une                                                                       cinéma        titre
interprétation de domaine fini sur une             Shining          KubRicK     Nicholson
                                                                                                            Le Champo     Shining
signature dotée des symboles de                    The Player       Altman      Robbins
constantes adéquats, d’un symbole de                                                                        Le Champo     Easy Rider
                                                   Easy Rider       HoppeR      Nicholson
relation par table, et du symbole                                                                           Le Champo     The Player
                                                   Easy Rider       HoppeR      HoppeR
d’égalité ; on appelle cela une signature                                                                   Odéon         Easy Rider
relationnelle.                                     Apocalypse Now   Coppola     HoppeR



                                            10.3. Représentation des interprétations en OCaml. Voyons comment on pourrait repré-
                                            senter les interprétations en OCaml. Une manière peu élégante mais qui a le mérite d’être simple
                                            est de se dire qu’une interprétation I prend un symbole de relation R ou un symbole de fonc-
                                            tion f vu comme une chaîne de caractères, ainsi que n éléments du domaine DI sous la forme
                                            d’une liste, et retourne soit une valeur booléenne (dans le cas de R) soit un élément du domaine
                                            (dans le cas de f ). Si le type générique 'e désigne le type des éléments du domaine DI , une in-
                                            terprétation contient donc une fonction de type string -> 'e list -> bool qui interprète
                                            les symboles de relation et une fonction de type string -> 'e list -> 'e qui interprète
                                            les symboles de fonction.
                                                Pour pouvoir implémenter la sémantique plus tard dans la section 12.3, nous allons aussi avoir
                                            besoin d’une manière d’énumérer les éléments du domaine DI . Quand ce domaine est fini, cela
                                            pourrait prendre la forme d’une liste de type 'e list, mais quand DI est infini cela ne convient
                                            guère. Il y a en fait un type de donnée pour des séquences (potentiellement) infinies dans la
                                            bibliothèque standard d’OCaml : le module Seq. Une séquence d’éléments de type 'e est alors de
                                            type 'e t.
                                                Nos interprétations seront donc des triplets comprenant la séquence des éléments du domaine
                                            (de type 'e t), l’interprétation des symboles de relation (de type string -> 'e list -> bool),
                                            et l’interprétation des symboles de fonction (de type string -> 'e list -> 'e).
                                                 firstorder.ml
                                                 type 'e interpretation =
                                                   'e t * (string -> 'e list -> bool) * (string -> 'e list -> 'e)

                                               Prenons l’exemple 10.1. Pour représenter DI = {•}, on peut utiliser string en guise de type
                                            'e d’éléments et construire la séquence qui ne contient que la chaîne de caractères “•” à l’aide
                                            de la fonction List.to_seq. L’interprétation des symboles de relation ne doit s’inquiéter que
                                            de P et Q, tandis qu’il n’y a pas de symbole de fonction.
                                                 firstorder.ml
                                                 let props : string interpretation =
                                                   (to_seq ["•"],
                                                    (fun s l -> match (s,l) with
                                                                | ("P", []) -> true
                                                                | ("Q", []) -> false
                                                                | _         -> failwith "erreur dans l'interprétation"),
                                                    (fun _                  -> failwith "erreur dans l'interprétation"))

                                                L’exemple 10.4 est un autre exemple d’interprétation I de domaine fini, qui est l’ensemble des
                                            sommets d’un graphe dirigé. On peut représenter les éléments de DI comme des entiers, et voici
                                            la représentation de l’interprétation en OCaml.
                                                 firstorder.ml
                                                 let graph_10_4 : int interpretation =
                                                   (to_seq [0;1;2],
                                   INTRODUCTION À LA LOGIQUE                                 81


     (fun s l -> match (s,l) with
                 | ("=", [u;v]) ->        u = v
                 | ("E", [u;v]) ->        List.mem   (u,v) [(0,1);(0,2);(1,0);(2,1);(2,2)]
                 | ("B", [u])   ->        List.mem   u     [1;2]
                 | _            ->        failwith   "erreur dans l'interprétation"),
     (fun _                     ->        failwith   "erreur dans l'interprétation"))

   Un dernier exemple d’interprétation avec un domaine fini est celui de la base de données
relationnelle de l’exemple 10.5. Dans ce cas, on va représenter les éléments du domaine comme
des string.
 firstorder.ml
 let database : string interpretation =
   let domain_list = ["Shining";"The Player";"Easy Rider";"Apocalypse Now";
                      "Kubrick";"Altman";"Hopper";"Nicholson";"Robbins";
                      "Coppola";"Le Champo";"Odéon"] in
   (to_seq domain_list,
    (fun s l -> match (s,l) with
                | ("=", [s;t])      -> s = t
                | ("Film", [t;r;i]) -> List.mem (t,r,i)
                                         [("Shining","Kubrick","Nicholson");
                                          ("The Player","Altman","Robbins");
                                          ("Easy Rider","Hopper","Nicholson");
                                          ("Easy Rider","Hopper","Hopper");
                                          ("Apocalypse Now","Coppola","Hopper")]
                | ("Seance", [c;t]) -> List.mem (c,t)
                                         [("Le Champo","Shining");
                                          ("Le Champo","Easy Rider");
                                          ("Le Champo","The Player");
                                          ("Odéon","Easy Rider")]
                | _                 -> failwith "erreur dans l'interprétation"),
    (fun s l -> match (s, l) with
                | (s, []) when (List.mem s domain_list) -> s
                | _                 -> failwith "erreur dans l'interprétation"))

   Pour un exemple d’interprétation sur un domaine infini, voyons le cas de l’arithmétique sur
les entiers naturels décrit dans l’exemple 10.3. On a DI = N et on peut représenter ces entiers
naturels comme des int. Une énumération des entiers naturels peut être implémentée à l’aide
de la fonction Seq.unfold.
 firstorder.ml
 let naturals = unfold (fun i -> if (i < 0) then None else Some(i, i+1)) 0
 let natarith : int interpretation =
   (naturals,
    (fun s l -> match (s,l) with
                | ("=", [x;y]) -> x = y
                | _            -> failwith "erreur dans l'interprétation"),
    (fun s l -> match (s,l) with
                | ("+", [i;j]) -> (i + j)
                | ("·", [i;j]) -> (i * j)
                | _            -> failwith "erreur dans l'interprétation"))
                                             82                                          INTRODUCTION À LA LOGIQUE


                                                                                               11. Syntaxe

                                                  Résumé. Fixons une signature L = (F, P) et un ensemble infini dénombrable de va-
                                                  riables X. L’ensemble T (F, X) des termes sur F et X est l’ensemble des arbres de la
                                                  forme
                                                                                     x         ou           f


                                                                                                t1     t2        ...       tn

                                                  où x ∈ X, n ∈ N, f ∈ Fn et t1 , t2 , . . . , tn sont des termes.
                                                      Une formule est un arbre de la forme

                                                                          R         ou         ¬            ou             ∨        ou      ∃x


                                                               t1    t2       ...   tm         φ                       φ        ψ            φ

                                                  où m ∈ N, R ∈ Pm , t1 , t2 , . . . , tm ∈ T (F, X), x ∈ X et φ et ψ sont des formules. Une
                                                  formule de la forme « R(t1 , t2 , . . . , tm ) » est dite atomique.
                                                      Un terme sans variable est un terme clos et on note « T (F) » pour l’ensemble des
                                                  termes clos sur F. Une variable x qui apparaît dans une formule mais pas sous un quanti-
                                                  ficateur ∃x est dite libre ; sinon elle est liée. On note « fv(φ) » pour l’ensemble des variables
                                                  libres de φ et « bv(φ) » pour son ensemble de variables liées. Une formule sans variable
                                                  libre est dite close.

 (DupaRc, 2015, sec. 10.3), (David,         11.1. Formules. Soit X un ensemble infini dénombrable de symboles de variables. Les formules
NouR et Raffalli, 2003, sec. 1.2),           de la logique du premier ordre sur une signature L = (F, P) (aussi appelées « L-formules »)
(Goubault-LaRRecq et MacKie, 1997,           sont définies par la syntaxe abstraite
sec. 6.1), (HaRRisson, 2009, sec. 3.1).
 La logique propositionnelle (aussi
appelée « calcul des propositions ») de la                                          t ::= x | f (t1 , . . . , tm )                                    (termes)
partie 2 est obtenue en posant F = ∅ et
P = P0 , et en interdisant la                                                       α ::= R(t1 , . . . , tm )                             (formules atomiques)
quantification dans la syntaxe des                                                  φ ::= α | ¬φ | φ ∨ φ | ∃x.φ                                     (formules)
formules.

                                             où x ∈ X, m ∈ N, f ∈ Fm et R ∈ Pm . L’ensemble des termes sur X et F est aussi dénoté
                                             T (F, X). Un littéral est une formule atomique α ou sa négation ¬α.
                                                Comme dans le cas de la logique propositionnelle, on peut ajouter d’autres opérateurs boo-
                                             léens à cette syntaxe minimale. Alternativement, ces symboles peuvent être définis dans la lo-
                                             gique :


                                                   φ ∧ ψ def
                                                         = ¬(¬φ ∨ ¬ψ)                                       ∀x.φ def
                                                                                                                 = ¬∃x.¬φ                φ ⇒ ψ def
                                                                                                                                               = ¬φ ∨ ψ
                                                        > def
                                                          = ∀x.R(x, . . . , x) ∨ ¬R(x, . . . , x)                 ⊥ def
                                                                                                                    = ¬>

                                             où R est un symbole arbitraire de P (qui est supposé non vide).
                                                Comme pour les formules propositionnelles, les formules de la logique du premier ordre
                                             sont donc des arbres de syntaxe abstraite. Par exemple, la figure 23 décrit la formule du buveur
                                             ∃x.(B(x) ⇒ ∀y.B(y)). On a matérialisé dans cette figure les liens (en pointillés rouges) entre
                                             quantification et occurrences de chaque variable.
                                          INTRODUCTION À LA LOGIQUE                                      83


                                                      ∃x

                                                      ⇒

                                                  B        ∀y

                                                  x        B

                                                           y

    FiguRe 23. L’arbre de syntaxe abstraite de la formule du buveur ∃x.(B(x) ⇒ ∀y.B(y)).


11.2. Variables libres et variables liées. L’ensemble fv(t) des variables libres (« free variables »           (DupaRc, 2015, sec. 10.6),
                                                                                                              (Goubault-LaRRecq et MacKie, 1997,
en anglais) d’un terme t est défini inductivement par                                                         def. 6.3)
                                                                           [
                fv(x) def
                      = {x} ,                 fv(f (t1 , . . . , tm )) def
                                                                       =     fv(ti ) .
                                                                         1≤i≤m

Un terme t sans variable libre (i.e. fv(t) = ∅) est dit clos ; l’ensemble des termes clos est noté T (F).
  Les ensembles fv(φ) des variables libres et bv(φ) des variables liées (« bound variables » en
anglais) d’une formule φ sont définis inductivement par
                                   [
       fv(R(t1 , . . . , tm )) def
                               =       fv(ti ) ,         bv(R(t1 , . . . , tm )) def
                                                                                 =∅,
                                  1≤i≤m
                            def
                    fv(¬φ) = fv(φ) ,                                  bv(¬φ) def
                                                                             = bv(φ)
                fv(φ ∨ ψ) def
                          = fv(φ) ∪ fv(ψ) ,                      bv(φ ∨ ψ) def
                                                                           = bv(φ) ∪ bv(ψ) ,
                  fv(∃x.φ) def
                           = fv(φ) \ {x}                          bv(∃x.φ) def
                                                                           = {x} ∪ bv(φ) .
Une formule φ sans variable libre (c’est-à-dire telle que fv(φ) = ∅) est dite close. Par exemple,
la formule ∃x.(B(x) ⇒ ∀y.B(y)) représentée dans la figure 23 est close. Si φ est le nom d’une
formule qui n’est pas close, on note couramment « φ(x1 , . . . , xn ) » pour expliciter que x1 , . . . , xn
est une énumération des variables de fv(φ) = {x1 , . . . , xn }, voir exemples 12.5 et 13.6 pour des
exemples d’utilisation de cette notation.

11.3. Syntaxe en OCaml. Une représentation possible des termes et des formules en OCaml est
d’employer des chaînes de caractères pour les symboles de fonction et les symboles de relation.

11.3.1. Syntaxe abstraite en OCaml. Voici les types OCaml pour les termes et les formules. Les
symboles de fonction f ∈ F, de relation R ∈ P et de variables x ∈ X sont tous représentés à
l’aide de chaînes de caractères.
  firstorder.ml
 type term = Var of string | Fun of string * term list
 type atom = string * term list
 type fo = Atom of atom | Non of fo | Ou of fo * fo | Ex of string * fo

   Avec ces déclarations de type, la formule du buveur ∃x.(B(x) ⇒ ∀y.B(y)) représentée dans
la figure 23 s’écrit en syntaxe restreinte comme ∃x.(¬B(x) ∨ ¬(∃y.¬B(y))) et se définit en
OCaml comme suit :
  firstorder.ml
 let buveur = Ex ("x",
                  Ou (Non (Atom ("B", [Var "x"])),
                      Non (Ex ("y", Non (Atom ("B", [Var "y"]))))))
84                                   INTRODUCTION À LA LOGIQUE


11.3.2. Syntaxe concrète en OCaml. Le passage d’une formule, définie par son arbre de syntaxe
abstraite, à sa syntaxe concrète sous forme d’une chaîne de caractères se fait par récursion sur
les termes et formules.
     firstorder.ml
     let rec string_of_term = function
         Var x -> x
       | Fun (f, tl)   -> f^(string_of_terml tl)
     and string_of_terml = function
         []   -> ""
       | [t] -> "("^(string_of_term t)^")"
       | t::l -> (List.fold_left
                            (fun s t' -> s^", "^(string_of_term t'))
                            ("("^(string_of_term t)) l)^")"
     and string_of_fo = function
         Atom (r, tl) -> r^(string_of_terml tl)
       | Non (phi)    -> "¬"^(string_of_fo phi)
       | Ou (phi,psi) -> "("^(string_of_fo phi)^" v "^(string_of_fo psi)^")"
       | Ex (x, phi) -> "(∃"^x^"."^(string_of_fo phi)^")"

11.3.3. Variables libres et variables liées en OCaml. Le calcul des ensembles de variables libres et
de variables liées se fait par récurrence sur les termes et formules.
     firstorder.ml
     let   rec aux_tv t vars = match t with
       |   Var x -> x::vars
       |   Fun (_,tl) -> List.fold_left (fun vs t' -> aux_tv t' vs) vars tl
     and   aux_fv phi vars = match phi with
       |   Atom (_, tl) -> List.fold_left (fun vs t' -> aux_tv t' vs) vars tl
       |   Non(phi')    -> aux_fv phi' vars
       |   Ou(phi',psi)-> aux_fv phi' (aux_fv psi vars)
       |   Ex (x, phi') -> List.filter (fun y -> (x <> y)) (aux_fv phi' vars)
     and   aux_bv phi vars = match phi with
       |   Atom (_, _) -> vars
       |   Non(phi')    -> aux_bv phi' vars
       |   Ou(phi',psi)-> aux_bv phi' (aux_bv psi vars)
       |   Ex (x, phi') -> x::(aux_bv phi' vars)

     let fv phi = List.sort_uniq compare (aux_fv phi [])
     and bv phi = List.sort_uniq compare (aux_bv phi [])
                                             INTRODUCTION À LA LOGIQUE                                             85


                                                   12. SÉmantie

   Résumé. Soit L = (F, P) une signature du premier ordre et B def     = {0, 1} l’ensemble des
   valeurs de vérité, où 0 désigne « faux » et 1 désigne « vrai ». Étant donnée une interpréta-
   tion I de L et une valuation ρ : X → DI des variables,
      — la sémantique d’un terme t est un élément JtKIρ ∈ DI et
      — la sémantique d’une formule φ est une valeur de vérité JφKIρ ∈ B.
   Dans les deux cas, ces sémantiques ne dépendent que de la valuation des variables libres
   de t et φ (propriété 12.1). On note « I, ρ Z= φ » si JφKIρ = 1.
       Une formule est satisfiable s’il existe une interprétation I et une valuation ρ telles que
   I, ρ Z= φ. Une interprétation I est un modèle d’une formule φ (noté « I Z= φ ») si pour
   toute valuation ρ, on a I, ρ Z= φ. Une formule φ est une conséquence logique d’un ensemble
   de formules S (noté « S Z= φ ») si, pour toute interprétation I et pour toute valuation ρ
   telles que I, ρ Z= ψ pour toute formule ψ ∈ S, on a I, ρ Z= φ. Enfin, une formule φ est
   valide (noté « Z= φ ») si pour toute interprétation I et toute valuation ρ, on a I, ρ Z= φ.

    Fixons L = (F, P) une signature du premier ordre. On note B def     = {0, 1} pour l’ensemble                         (David, NouR et Raffalli, 2003,
                                                                                                                        sec. 2.2), (Goubault-LaRRecq et
des valeurs de vérité (aussi appelé « algèbre de Boole »), muni des opérations not : B → B et                           MacKie, 1997, sec. 6.2), (HaRRisson,
or : B2 → B, définies par not 1 = 0 or 0 = 0 et not 0 = 1 or 1 = 1 or 0 = 0 or 1 = 1. Pour                              2009, sec. 3.3).
une famille (vj )j∈J de valeurs de vérité vj ∈ B indexée par un ensemble J, on définit aussi la
disjonction distribuée par Orj∈J vj = 1 si et seulement s’il existe j ∈ J tel que vj = 1.

12.1. Sémantique. Une valuation dans I est une fonction ρ : X → DI . On notera ρ[e/x] pour                               voir aussi (DupaRc, 2015, sec. 11.3)
                                                                                                                        pour une définition de la sémantique en
la valuation qui associe e à x et ρ(y) à y 6= x. Pour un terme t, sa sémantique JtKIρ dans une                          termes de jeux
interprétation I pour une valuation ρ est un élément de DI défini inductivement par
                JxKIρ def
                      = ρ(x) ,                        Jf (t1 , . . . , tm )K def
                                                                             = f I (Jt1 KIρ , . . . , Jtm KIρ )
pour tout m et tout f ∈ Fm .
   La sémantique JφKIρ d’une formule du premier ordre φ dans une interprétation I pour une
valuation ρ est une valeur de vérité dans B définie inductivement par
         JR(t1 , . . . , tm )KIρ def
                                 = RI (Jt1 KIρ , . . . , Jtm KIρ ) ,                J¬φKIρ def
                                                                                           = not JφKIρ ,
                   Jφ ∨ ψKIρ def
                             = JφKIρ or JψKIρ ,                                   J∃x.φKρ def
                                                                                          = Or JφKIρ[e/x] .
                                                                                                 e∈DI

  On dit que (I, ρ) satisfait φ, noté I, ρ Z= φ, si               JφKIρ     = 1 ; cette écriture peut être définie de
manière équivalente par
                  I, ρ Z= R(t1 , . . . , tm )                          si (Jt1 KIρ , . . . , Jtm KIρ ) ∈ RI ,
                  I, ρ Z= ¬φ                                           si I, ρ 6Z= φ ,
                  I, ρ Z= φ ∨ ψ                                        si I, ρ Z= φ ou I, ρ Z= ψ ,
                  I, ρ Z= ∃x.φ                                         si ∃e ∈ DI .I, ρ[e/x] Z= φ .

12.2. Modèles, satisfiabilité et validité. Une formule φ est satisfiable s’il existe une interpré-
tation I et une valuation ρ telle que I, ρ Z= φ. On dit que I est un modèle de φ, noté I Z= φ, si pour
toute valuation ρ, I, ρ Z= φ. Une formule φ est valide, ce qui est noté Z= φ, si pour toute interpré-
tation I et toute valuation ρ, I, ρ Z= φ ; autrement dit, φ est valide si pour toute interprétation I,
I est un modèle de φ.
   Pour un ensemble de formules S, une interprétation I et une valuation ρ, on écrit I, ρ Z= S si
I, ρ Z= ψ pour toutes les formules ψ ∈ S. Si de plus φ est une formule, on écrit S Z= φ si pour
86                                     INTRODUCTION À LA LOGIQUE


toute paire (I, ρ) telle que I, ρ Z= S on a I, ρ Z= φ. Un ensemble S de formules est insatisfiable
s’il n’existe pas I et ρ telles que I, ρ Z= S, ou de manière équivalente si S Z= ⊥.
    Notons que la satisfaction d’une formule ne dépend que de la valuation de ses variables libres.
Propriété 12.1. Pour toute formule φ (resp. terme t), toute interprétation I, et toutes valuations ρ et
ρ′ telles que pour tout x ∈ fv(φ) (resp. x ∈ fv(t)) ρ(x) = ρ′ (x), JφKIρ = JφKIρ′ (resp. JtKIρ = JtKIρ′ ).
Démonstration. Par induction structurelle sur φ (resp. t).                                             □

En particulier, par la propriété 12.1, φ avec fv(φ) = {x1 , . . . , xn } est satisfiable si et seulement
la formule close ∃x1 . . . ∃xn .φ est satisfiable, et φ est valide si et seulement si la formule close
∀x1 . . . ∀xn .φ est valide.

12.3. Implémentation de la sémantique en OCaml. On a déjà vu comment définir le type
'e interpretation dans la section 10.3 pour une interprétation I dans laquelle les éléments
du domaine DI ont le type générique 'e.
  Une valuation est une fonction ρ : X → DI . Comme nous avons représenté les variables
x ∈ X comme des chaînes de caractères, une valuation va donc être une fonction de type
string -> 'e.
     firstorder.ml
     type 'e valuation = string -> 'e

   La mise à jour ρ[e/x] d’une valuation ρ va servir pour la sémantique des formules de la
forme ∃x.φ.
     firstorder.ml
     let upd: 'e valuation -> 'e -> string -> 'e valuation =
       fun rho e x -> (fun y -> if (x = y) then e else rho y)

  La sémantique JtKIρ d’un terme t dans une interprétation I et pour une valuation ρ des variables
peut maintenant s’implémenter par
     firstorder.ml
     let rec tevalue: 'e interpretation -> 'e valuation -> term -> 'e =
       fun ((_,_,funs) as i) rho t ->
       match t with
       | Var x     -> rho x
       | Fun(f,tl) -> funs f (List.map (fun t -> tevalue i rho t) tl)

   Pour la sémantique des formules du premier ordre, il va nous falloir une implémentation de
l’opérateur Ore∈DI . C’est cette implémentation qui a motivé l’ajout d’une séquence de type 'e t
(qui est un type défini dans le module Seq) à nos interprétations pour énumérer les éléments du
domaine DI . Voici son code OCaml, qui parcourt les éléments x de la séquence et retourne true
dès que predicate x est vrai, et retourne false si la séquence termine avant cela. À noter
que cette fonction ne termine pas si la séquence est infinie et le prédicat est faux sur tous ses
éléments.
     firstorder.ml
     let rec exists: ('e -> bool) -> 'e t -> bool = fun predicate domain ->
       match domain () with
       | Nil -> false
       | Cons (x, next) -> if (predicate x)
                           then true
                           else exists predicate next

   La sémantique JφKIρ d’une formule du premier ordre φ dans une interprétation I et pour une
valuation ρ des variables peut ensuite s’implémenter par
                                     INTRODUCTION À LA LOGIQUE                                   87


 firstorder.ml
 let rec evalue:'e interpretation -> 'e valuation -> fo -> bool =
   fun ((dom,rels,funs) as i) rho phi ->
   match phi with
   | Atom (r, tl) -> rels r (List.map (fun t -> tevalue i rho t) tl)
   | Non(phi')    -> not(evalue i rho phi')
   | Ou(phi',psi)-> ((evalue i rho phi') || (evalue i rho psi))
   | Ex (x, phi') -> exists (fun e -> evalue i (upd rho e x) phi') dom

12.4. Exemples de formules. Voici quelques exemples de formules du premier ordre.

 Exemple 12.2 (loi de PeiRce). Prenons la signature L = (∅, {P (0) , Q(0) } de l’exemple 10.1. La
 formule de PeiRce ((P ⇒ Q) ⇒ P ) ⇒ P déjà présentée dans l’exemple 3.10 est une formule
 du premier ordre sur cette signature. Elle est encore valide : pour toute interprétation I et pour
 toute valuation ρ, soit P I = 1 et alors I, ρ Z= P et donc I, ρ Z= ((P ⇒ Q) ⇒ P ) ⇒ P ,
 soit P I = 0 et alors I, ρ 6Z= P donc I, ρ Z= P ⇒ Q, donc I, ρ 6Z= (P ⇒ Q) ⇒ P , et enfin
 I, ρ Z= ((P ⇒ Q) ⇒ P ) ⇒ P .

 Exemple 12.3 (formule du buveur). Considérons la signature L = (∅, {B (1) }) avec une re-
 lation unaire B. La formule ∃x.(B(x) ⇒ ∀y.B(y)), qui se lit habituellement « il existe un
 individu tel que s’il boit alors tout le monde boit », est valide.                                    On notera que cette formule n’est pas
                                                                                                      valide si l’on permet un domaine
 Nous allons montrer que dans toute interprétation I et pour toute valuation ρ, I, ρ Z=               d’interprétation vide. Elle n’est pas non
 ∃x.(B(x) ⇒ ∀y.B(y)). Cela revient à montrer que pour toute interprétation I, il existe un            plus valide en logique intuitionniste du
 élément e ∈ DI tel que I, ρ[e/x] Z= B(x) ⇒ ∀y.B(y), c’est-à-dire tel que                             premier ordre.

                I, ρ[e/x] 6Z= B(x)            ou             I, ρ[e/x] Z= ∀y.B(y) .
 Il y a alors deux cas selon l’interprétation B du symbole de relation B :
                                               I




                         e
           BI                                                         BI
                             DI                                                       DI


     soit B I ⊊ DI : il existe un élément               soit B I = DI : comme DI 6= ∅, on
     « sobre » e ∈ DI tel que e 6∈ B I , et             peut choisir n’importe quel e ∈ DI et
     on a bien                                          on a bien
                I, ρ[e/x] 6Z= B(x)                               I, ρ[e/x] Z= ∀y.B(y)

 Exemple 12.4 (requêtes sur un graphe). Considérons à nouveau la signature et l’interpréta-
 tion I de l’exemple 10.4 qui représente le graphe de la figure 22. On peut par exemple déterminer
 s’il existe un sommet de degré sortant un par la formule close
                              ∃x.(∃y.E(x, y) ∧ ∀z.y = z ∨ ¬E(x, z)) .                          (11)
                                             88                                        INTRODUCTION À LA LOGIQUE

                                                  Cette formule va s’évaluer à 1 dans l’interprétation I et pour n’importe quelle valuation ρ
                                                  (puisque la formule est close) : I est un donc modèle de la formule. En effet,
                                                                                     I, ρ Z= ∃x.(∃y.E(x, y) ∧ ∀z.y = z ∨ ¬E(x, z))
                                                                           car I, ρ[1/x] Z= ∃y.E(x, y) ∧ ∀z.y = z ∨ ¬E(x, z)
                                                                      car I, ρ[1/x, 0/y] Z= E(x, y) ∧ ∀z.y = z ∨ ¬E(x, z)
                                                         car d’une part I, ρ[1/x, 0/y] Z= E(x, y) puisque (1, 0) ∈ E I ,
                                                         et d’autre part I, ρ[1/x, 0/y] Z= ∀z.y = z ∨ ¬E(x, z) :
                                                           en effet I, ρ[1/x, 0/y, 0/z] Z= y = z ∨ ¬E(x, z) puisque y et z sont valués à 0
                                                               puis I, ρ[1/x, 0/y, 1/z] Z= y = z ∨ ¬E(x, z) puisque (1, 1) 6∈ E I
                                                           et enfin I, ρ[1/x, 0/y, 2/z] Z= y = z ∨ ¬E(x, z) puisque (1, 2) 6∈ E I .
 Comme vous l’apprendrez en cours
de bases de données, le calcul relationel
– qui est le nom que l’on donne à la
logique du premier ordre sur une                  Exemple 12.5 (requêtes sur une base de données). Considérons la signature et l’interpréta-
signature relationnelle – est équivalent à        tion I de l’exemple 10.5. Une formule du premier ordre permet d’exprimer des requêtes sur
l’algèbre relationnelle – qui sont les            la base de données correspondante : si x1 , . . . , xn sont les variables libres de φ(x1 , . . . , xn ),
opérations implémentées au sein des
systèmes de gestion de base de données –          l’ensemble de n-uplets
ce résultat est connu comme le théorème
de Codd et est ce qui permet de répondre                                φ(I) def
                                                                             = {(e1 , . . . , en ) | I, [e1 /x1 , . . . , en /xn ] Z= φ}
aux requêtes SQL.
                                                  est le résultat de la requête. Le langage SQL de requêtes sur une base de données permet d’ex-
                                                  primer des requêtes de la logique du premier ordre, et nous allons donner des exemples de
                                                  requêtes en SQL pour chaque formule.
                                                     — Les titres des films présents dans la base de données :
                                                                                             ∃r∃i.Film(x, r, i)                                      (12)
                                                        avec pour résultat {Shining, The Player, Easy Rider, Apocalypse Now}. Cette requête peut
                                                        être exprimée en SQL sur la base de données de l’exemple 10.5 par
                                                        SELECT DISTINCT titre
                                                          FROM Films
                                                     — Tous les cinémas qui diffusent un film avec HoppeR :
                                                                                 ∃t∃r.Film(t, r, hopper) ∧ Seance(x, t)                              (13)
                                                        avec pour résultat {Le Champo, Odéon}. La requête SQL correspondante est
                                                        SELECT DISTINCT cinema
                                                          FROM Films NATURAL JOIN Seances
                                                         WHERE Films.interprete = 'Hopper'
                                                     — Tous les cinémas qui diffusent un film de KubRicK avec HoppeR :
                                                                               ∃t.Film(t, kubrick, hopper) ∧ Seance(x, t)                            (14)
                                                        avec pour résultat ∅. La requête SQL correspondante est
                                                        SELECT     DISTINCT cinema
                                                          FROM     Films NATURAL JOIN Seances
                                                         WHERE     Films.interprete = 'Hopper'
                                                           AND     Films.realisation = 'Kubrick'
                                                     — Les interprètes qui ont joué dans un film dirigé par KubRicK ou par Coppola :
                                                                              ∃t.Film(t, kubrick, x) ∨ Film(t, coppola, x)                           (15)
                                                        avec pour résultat {Nicholson, HoppeR}. La requête SQL correspondante est
                               INTRODUCTION À LA LOGIQUE                                89

   SELECT    DISTINCT interprete
     FROM    Films
    WHERE    Films.realisation = 'Kubrick'
       OR    Films.realisation = 'Coppola'
— Les réalisateurs qui ont joué dans un film qu’ils ont dirigé :
                                     ∃t.Film(t, x, x)                                 (16)
   avec pour résultat {HoppeR}. Une requête SQL correspondante est
   SELECT DISTINCT F1.realisation
     FROM Films F1 JOIN Films F2 ON F1.realisation = F2.interprete
                                 AND F1.titre = F2.titre
— Les réalisateurs et les cinémas qui diffusent leurs films :
                             ∃t∃i.Film(t, x, i) ∧ Seance(y, t)                        (17)
   avec pour résultat {(KubRicK, Le Champo), (Altman, Le Champo), (HoppeR, Le Champo),
   (HoppeR, Odéon)}. Une requête SQL correspondante est
   SELECT DISTINCT realisation, cinema
     FROM Films NATURAL JOIN Seances
— Les réalisateurs dont les films passent dans tous les cinémas :
                ∀c.(∃t.Seance(c, t)) ⇒ (∃t∃i. Film(t, x, i) ∧ Seance(c, t))           (18)
   avec pour résultat {HoppeR}. Une requête SQL possible pour cela est
   SELECT DISTINCT F1.realisation
     FROM Films F1
    WHERE NOT EXISTS
          (SELECT S1.cinema
             FROM Seances S1
           EXCEPT
           SELECT S2.cinema
             FROM Seances S2 NATURAL JOIN Films F2
            WHERE F1.realisation = F2.realisation)
   À noter ici que par souci de lisibilité, on aurait pu définir une formule cinema(c) def
                                                                                       =
   ∃t.Seance(c, t) et écrire notre requête (18) comme
                    ∀c.cinema(c) ⇒ ∃t∃i.Film(t, x, i) ∧ Seance(c, t) .                (19)
  Comme la langue française est ambiguë, on aurait aussi pu comprendre cette requête
  comme
                   ∃t∃i.Film(t, x, i) ∧ ∀c.cinema(c) ⇒ Seance(c, t)                 (20)
  qui retourne aussi {HoppeR}.
— Les interprètes qui ont joué dans un film de HoppeR mais pas dans un film de KubRicK :
                   (∃t.Film(t, hopper, x)) ∧ ¬(∃t.Film(t, kubrick, x))                (21)
   avec pour résultat {HoppeR}. Une requête SQL possible pour cela est
   SELECT    interprete
     FROM    Films
    WHERE    realisation = 'Hopper'
   EXCEPT
   SELECT    interprete
     FROM    Films
    WHERE    realisation = 'Kubrick'
90                                       INTRODUCTION À LA LOGIQUE

        — Les interprètes qui n’ont joué que dans un seul film :
                            ∃t∃r.Film(t, r, x) ∧ ∀t′ ∀r′ .Film(t′ , r′ , x) ⇒ t = t′               (22)
           avec pour résultat {Robbins}. Une requête SQL possible pour cela est
           SELECT    interprete
             FROM    Films
           EXCEPT
           SELECT    F1.interprete
             FROM    Films F1, Films F2
            WHERE    F1.interprete = F2.interprete
              AND    F1.titre <> F2.titre

     Exemple 12.6 (propriétés des ordres). Dans la signature de l’exemple 10.2, l’interprétation I
     de domaine Q est un modèle de la formule
                                                 ∀x∃y.y < x                                        (23)
     qui exprime le fait que l’ordre n’est pas borné à gauche ; la formule est donc satisfiable. Il en
     serait de même si on avait pris DI def
                                         = Z et <I l’ordre sur les entiers relatifs. En revanche, si on
                   def
     avait pris DI = N, la formule (23) serait devenue fausse : cette formule n’est donc pas valide.
     La formule close
                                    ∀x∀y.x < y ⇒ ∃z.x < z ∧ z < y                                  (24)
     exprime que l’ordre est dense. Elle est vraie sur Q mais pas sur Z et est donc satisfiable mais
     pas valide. La formule
                                   ∀x∃y∀z.x < y ∧ ¬(x < z ∧ z < y)                                 (25)
     est au contraire vraie sur Z mais fausse sur Q.
                                            INTRODUCTION À LA LOGIQUE                                                91


                                               13. Substitutions

   Résumé. Une substitution est une fonction σ de domaine fini qui associe à toute variable
   x ∈ X un terme σ(x) ∈ T (F, X) ; par extension, tσ est le terme t dans lequel toutes les
   occurrences de chaque variable x ont été remplacées par σ(x).
        Une substitution σ est applicable à une formule φ si elle n’interagit pas avec les va-
   riables liées de φ ; on note alors « φσ » pour la formule φ dans laquelle toutes les oc-
   currences de chaque variable x ont été remplacées par σ(x). Modulo α-renommage, qui
   consiste à renommer les variables liées de φ, on peut toujours appliquer une substitution
   (c.f. propriété 13.3).
       Soit I une interprétation et ρ une valuation. On dénote par « ρσ » la valuation qui
   associe pour toute variable x ∈ X l’élément (ρσ)(x) def
                                                         = Jσ(x)KIρ ; alors le lemme 13.5 de
   substitution dit que JφσKIρ = JφKIρσ .

   Une substitution est une fonction σ: X → T (F, X) de domaine dom(σ) def         = {x ∈ X | σ(x) 6=                      (DupaRc, 2015, sec. 10.7),
                                                                                                                          (Goubault-LaRRecq et MacKie, 1997,
x} fini. On note aussi σ comme [σ(x1 )/x1 , . . . , σ(xn )/xn ] où x1 , . . . , xn sont les variables dis-                def. 6.4), (HaRRisson, 2009, sec. 3.4).
tinctes de dom(σ).
   Une substitution définit une fonction t 7→ tσ de T (F, X) dans T (F, X) par induction sur le
terme t
                    xσ def
                       = σ(x) ,                        f (t1 , . . . , tm )σ def
                                                                             = f (t1 σ, . . . , tm σ)
pour tout m ∈ N et tout f ∈ Fm . Une substitution à image dans T (F) est dite close.

   Ces définitions s’étendent aussi aux formules. Cependant, du fait de la présence de variables
liées dans les formules, une substitution n’est pas applicable à n’importe quelle formule. Pour une
                                                     S
substitution σ et une formule φ, on note rv(σ) def= x∈dom(σ) fv(σ(x)) son ensemble de variables
images (« range variables » en anglais). On dit que σ est applicable à φ si
                                       (dom(σ) ∪ rv(σ)) ∩ bv(φ) = ∅ ,
et dans ce cas on définit φσ comme l’application de σ à φ par induction sur la formule φ
               R(t1 , . . . , tm )σ def
                                    = R(t1 σ, . . . , tm σ) ,                  (¬φ)σ def
                                                                                     = ¬(φσ) ,
                      (φ ∨ ψ)σ def
                               = (φσ) ∨ (ψσ) ,                               (∃x.φ)σ def
                                                                                     = ∃x.(φσ) ,
où m ∈ N et R ∈ Pm .
   La composition σσ ′ de deux substitutions σ et σ ′ est définie par φ(σσ ′ ) def
                                                                               = (φσ)σ ′ . Par exemple
(B(x) ∨ B(y))[y/x, z/y] = B(y) ∨ B(z), (B(x) ∨ B(y))[y/x][z/y] = B(z) ∨ B(z), et (B(x) ∨
B(y))[z/x] = B(z) ∨ B(y).
13.1. Lemme de substitution. Les valuations fournissent le pendant côté modèles des sub-
stitutions côté formules. Pour une substitution σ et une valuation ρ, notons σρ la valuation
x 7→ Jσ(x)KIρ pour tout x ∈ X. Nous préparons ici le terrain pour le lemme 13.5 de substitution,
qui sera énoncé sous une forme plus générale un peu plus loin.                                                             Une substitution propositionnelle τ
                                                                                                                          reliait deux interprétations I et Iτ ; par
Lemme 13.1. Pour tout terme t, toute substitution σ, toute interprétation I, et toute valuation ρ,                        contraste, une substitution σ relie deux
                                                                                                                          valuations ρ et ρσ.
JtσKIρ = JtKIσρ .
Démonstration. Par induction structurelle sur t.
   Pour le cas de base d’une variable x, JxσKIρ = Jσ(x)KIρ = (σρ)(x) = JxKIσρ .
   Pour un terme f (t1 , . . . , tm ), Jf (t1 , . . . , tm )σKIρ = Jf (t1 σ, . . . , tm σ)KIρ = f I (Jt1 σKIρ , . . . ,
           h.i. I
Jtm σKIρ ) =   f (Jt1 KIσρ , . . . , Jtm KIσρ ) = Jf (t1 , . . . , tm )KIσρ .                                       □
                                         92                                    INTRODUCTION À LA LOGIQUE


                                         Lemme 13.2. Pour toute formule φ, toute substitution σ applicable à φ, toute interprétation I, et
                                         toute valuation ρ, JφσKIρ = JφKIσρ .
                                         Démonstration. Par induction structurelle sur φ.
                                            Pour une formule atomique R(t1 , . . . , tm ), une négation ¬φ, ou une disjonction φ ∨ ψ, cela
                                         découle du lemme 13.1 et de l’hypothèse d’induction. Pour une quantification ∃x.φ,
                                                                                              h.i.
                                                   J(∃x.φ)σKIρ = J∃x.(φσ)KIρ = Or JφσKIρ[e/x] =    Or JφKIσ(ρ[e/x]) = J∃x.φKIσρ ,
                                                                                  e∈DI                e∈DI

                                         où il faut montrer pour justifier cette dernière étape que, pour toute variable libre z ∈ fv(φ),
                                         (σ(ρ[e/x]))(z) = ((σρ)[e/x])(z), ce qui permettra de conclure par la propriété 12.1. Si z = x,
                                         alors (σ(ρ[e/x]))(x) = Jσ(x)KIρ[e/x] = JxKIρ[e/x] = e = JxKI(σρ)[e/x] = ((σρ)[e/x])(x) où
                                         σ(x) = x puisque, comme σ est applicable à ∃x.φ et x ∈ bv(∃x.φ), x 6∈ dom(σ). Si z 6= x, alors
                                         (σ(ρ[e/x]))(z) = Jσ(z)KIρ[e/x] = Jσ(z)KIρ = ((σρ)[e/x])(z), où l’égalité centrale repose sur le
                                         fait que x 6∈ fv(σ(z)), qui à son tour découle de bv(∃x.φ) ∩ rv(σ) = ∅ puisque σ est applicable
                                         à ∃x.φ.                                                                                       □
 L’α-renommage est aussi une notion     13.2. α-renommages. Quand une substitution σ n’est pas applicable à une formule φ, il est
de base du λ-calcul, l’archétype de
langage de programmation fonctionnelle
                                         cependant possible d’effectuer un α-renommage à φ pour obtenir une formule φ′ sur laquelle
qui donne son nom (entre autres) aux     appliquer σ. On raisonnera donc implicitement non sur des formules mais sur des classes de
lambda-expressions de Java et OCaml.     formules équivalentes à α-renommage près. Il est important dans ce cas que cette opération
                                         définisse une congruence (l’α-congruence) sur les formules pour pouvoir continuer à raisonner
                                         inductivement, et que l’opération préserve la sémantique des formules.
                                              On définit l’opération d’α-renommage comme une règle de réécriture sur les formules
                                                                                 ∃x.φ →α ∃y.φ[y/x]                             (α-renommage)
                                         où y 6∈ fv(∃x.φ) et [y/x] est applicable à φ. À noter que l’α-renommage n’impacte que les
                                         variables liées de φ, ce qui explique pourquoi il en préserve la sémantique (voir le lemme 13.4
                                         ci-dessous).
                                            On définit l’α-congruence =α comme la plus petite congruence entre formules engendrée
                                         par →α , c’est-à-dire la plus petite relation réflexive, symétrique et transitive telle que φ →α ψ
                                         implique φ =α ψ et telle que si φ =α ψ et φ′ =α ψ ′ , alors ¬φ =α ¬ψ, φ ∨ φ′ =α ψ ∨ ψ ′ et
                                         ∃x.φ =α ∃x.ψ.
                                           En appliquant des α-renommages inductivement sur les sous-formules croissantes de φ, on
                                         peut au besoin renommer toutes les variables liées de φ, et on déduit :
                                         Propriété 13.3 (applicabilité). Pour toute substitution σ et toute formule φ, il existe une formule φ′
                                         telle que φ =α φ′ et que σ soit applicable à φ′ . De plus, si φ =α φ′′ et σ est aussi applicable à φ′′ ,
                                         alors φ′ =α φ′′ et φ′ σ =α φ′′ σ.

                                              Il reste à vérifier que les α-renommages n’impactent pas la sémantique des formules.
                                         Lemme 13.4 (α-congruence). Soient φ et ψ deux formules telles que φ =α ψ. Alors pour toute
                                         interprétation I et toute valuation ρ, JφKIρ = JψKIρ .
                                         Démonstration. Par induction sur la congruence =α .
                                           Le cas de base est celui d’un α-renommage ∃x.φ →α ∃y.φ[y/x] avec y 6∈ fv(∃x.φ) et [y/x]
                                         applicable. Puisque [y/x] est applicable, par le lemme 13.2,
                                               J∃y.φ[y/x]KIρ = Or Jφ[y/x]KIρ[e/y] = Or JφKI[y/x](ρ[e/y]) = Or JφKIρ[e/x] = J∃x.φKIρ
                                                                e∈DI                     e∈Di                   e∈Di

                                         où nous devons justifier pour l’avant-dernière étape que, pour toute variable libre z ∈ fv(φ),
                                         ([y/x](ρ[e/y]))(z) = (ρ[e/x])(z), ce qui permettra de conclure ce cas de base par la propriété 12.1.
                                         Si x = z, alors ([y/x](ρ[e/y]))(x) = JyKIρ[e/y] = e = JxKIρ[e/x] = (ρ[e/x])(x). Si x 6= z, alors
                                       INTRODUCTION À LA LOGIQUE                                         93


d’une part ([y/x](ρ[e/y]))(z) = JzKIρ[e/y] = JzKIρ puisque y 6∈ fv(∃x.φ) et donc y 6= z, et d’autre
part (ρ[e/x])(z) = JzKIρ[e/x] = JzKIρ .

    Le cas de base de la réflexivité ainsi que les étapes d’induction pour la symétrie, la transitivité,
et la congruence pour ¬, ∨ et ∃ sont évidents puisque JφKIρ = JψKIρ vue comme une relation entre
formules est aussi une congruence.                                                                    □

   La propriété 13.3 et le lemme 13.4 justifient un abus de notation : nous écrirons désormais
« φσ » pour une formule φ′ σ où φ =α φ′ et σ est applicable à φ′ . Le lemme 13.1 ainsi que le
lemme 13.4 d’α-congruence combiné au lemme 13.2 nous permettent alors d’énoncer le lemme
de substitution.
Lemme 13.5 (substitution). Pour tout terme t, toute formule φ, toute substitution σ, toute inter-              (Goubault-LaRRecq et MacKie, 1997,
                                                                                                              thm. 6.8).
prétation I, et toute valuation ρ, JtσKIρ = JtKIσρ et JφσKIρ = JφKIσρ .

   On utilisera par la suite deux identités aisément démontrables par induction sur φ : en appli-
quant au besoin une α-congruence à φ pour rendre les substitutions applicables, si x 6∈ fv(φ),
alors
                                             φ[t/x] =α φ ,                                            (26)
et si x 6∈ fv(φ) \ {y}, alors
                                       φ[x/y][t/x] =α φ[t/y] .                                        (27)

  Exemple 13.6 (propriétés arithmétiques). Dans la signature arithmétique avec F def              =
  {+(2) , ×(2) } et P def
                      = {=(2) } de l’exemple 10.3 et l’interprétation I = (N, +, ×), on peut définir
  dans la logique :
    — le nombre 0 par une formule avec une variable libre
                                         zero(x) def
                                                 = x+x=x.                                             (28)
       Pour rappel, si « φ » est le nom d’une formule qui n’est pas close, on peut expliciter que
       fv(φ) = {x1 , . . . , xn } en écrivant « φ(x1 , . . . , xn ) ». C’est ce que l’on a fait ici avec la
       formule « zero ». De manière très naturelle, on écrit alors « zero(y) » pour le résultat
       zero[y/x] du renommage de x en y dans la formule zero.
          Pour revenir à la sémantique de notre formule (28), on a I Z= ∃x.zero(x) ∧
       ∀y.(zero(y) ⇒ x = y), c’est-à-dire qu’il y a exactement un élément e du domaine
       DI def
           = N tel que I, ρ[e/x] Z= zero(x) : c’est e = 0.
     — de même, le nombre 1 par une formule avec une variable libre
                                     un(x) def
                                           = ¬zero(x) ∧ x × x = x                                     (29)
       et alors I Z= ∃x.un(x) ∧ ∀y.(un(y) ⇒ x = y) ;
     — l’ordre strict par une formule avec deux variables libres
                                   x < y def
                                         = ∃z.¬zero(z) ∧ y = x + z ;                                  (30)
     — le prédicat
                                pair(x) def
                                        = ∃y∃z.x = y × (z + z) ∧ un(z) ;                              (31)
     — le prédicat
                 premier(x) def
                            = ¬zero(x) ∧ ¬∃y∃z.x = y × z ∧ ¬un(y) ∧ ¬un(z) ;                          (32)
     — une formule close qui dit que tout nombre premier supérieur à 2 est impair :
                       ∀x.(premier(x) ∧ ∃y.x > y + y ∧ un(y)) ⇒ ¬pair(x) .                            (33)
94                                  INTRODUCTION À LA LOGIQUE


13.3. Implémentation des substitutions en OCaml. Nous allons représenter une substitu-
tion σ = [t1 /x1 , . . . , tn /xn ] comme une liste d’associations sa=[(x₁,t₁);…;(xₙ,tₙ)] :
     firstorder.ml
     type sassoc = (string * term ) list

La fonction de type X → T (F, X) associée est alors la suivante :
     firstorder.ml
     type substitution = string -> term
     let subst_of_sassoc: sassoc -> substitution =
       fun sa -> fun x -> match List.assoc_opt x sa with
       | None   -> Var x
       | Some t -> t

   Nous allons implémenter simultanément les substitutions et les α-renommages. Pour cela, on
dispose d’une séquence variables de type string t de noms de variables de X, ainsi que
d’une fonction find : ('a -> bool) -> 'a t -> 'a qui trouve un élément satisfaisant
un certain prédicat à l’intérieur d’une séquence. On a égalementSimplémenté une fonction rv :
sassoc -> string list qui calcule l’ensemble dom(σ) ∪ x∈dom(σ) fv(σ(x)) des noms de
variables « réservées » qui ne doivent pas être liées dans une formule φ pour la substitution soit
applicable à φ.
   La fonction alpha : string -> fo -> string list -> string * fo prend en
argument le nom x de la variable et la formule φ d’une formule ∃x.φ, ainsi qu’une liste de noms
de variables à éviter, et retourne une paire (y, φ[y/x]) telle que ∃x.φ →α ∃y.φ[y/x].
     firstorder.ml
     (* α-renommage d'une formule ∃x.φ *)
     let rec alpha x phi context =
       (* liste des noms de variables que l'on ne peut pas utiliser *)
       let forbidden =
         List.rev_append (fv (Ex (x,phi))) (List.rev_append context (bv phi)) in
       (* on trouve un nom de variable y utilisable *)
       let y =
         find (fun v -> not(List.mem v forbidden)) (append (to_seq[x]) variables) in
       (* on renvoie la paire (y, φ[y/x]) *)
       (y, fsubst [(x,Var y)] phi)
       and
     (* application d'une substitution à un terme t *)
         tsubst sa t = match t with
         | Var x -> subst_of_sassoc sa x
         | Fun (f,tl) -> Fun (f, List.map (tsubst sa) tl)
       and
     (* application d'une substitution à une formule φ *)
         fsubst sa phi = match phi with
         | Atom (r, tl) -> Atom (r, List.map (tsubst sa) tl)
         | Non(phi)     -> Non(fsubst sa phi)
         | Ou(phi,psi) -> Ou(fsubst sa phi, fsubst sa psi)
         | Ex (x, phi) -> (* α-renommage à la volée *)
            let (y, phi') = alpha x phi (rv sa) in Ex (y, fsubst sa phi')
                                                         INTRODUCTION À LA LOGIQUE                                                        95


                                                         14. FoRmes noRmales

   Résumé. On peut mettre n’importe quelle formule sous forme normale négative en
   « poussant » les négations vers les feuilles grâce aux dualités de de MoRgan ; la formule
   obtenue est alors de la forme
                 R              ou             ¬          ou            ∨         ou             ∧         ou       ∃x      ou     ∀x
                                               R
     t1     t2       ...   tm                                       φ       ψ               φ        ψ              φ              φ
                                t1       t2        ...   tm

   où m ∈ N, R ∈ Pm , t1 , t2 , . . . , tm ∈ T (F, X) et φ et ψ sont des formules sous forme
   normale négative. Les formules de la forme « R(t1 , t2 , . . . , tm ) » ou « ¬R(t1 , t2 , . . . , tm ) »
   sont appelées des littéraux.
       Une formule est sans quantificateur si elle est de la forme
                                     R                   ou          ¬           ou             ∨         ou        ∧
                                                                     R
                           t1   t2       ...       tm                                       φ       ψ           φ       ψ
                                                          t1    t2       ...     tm

   où m ∈ N, R ∈ Pm , t1 , t2 , . . . , tm ∈ T (F, X) et φ et ψ sont des formules sans quantifi-
   cateurs. Une formule est sous forme prénexe si elle est de la forme
                                                               ou           ∃x         ou            ∀x
                                                   ψ
                                                                            φ                        φ

   où φ est sous forme prénexe et ψ est sans quantificateurs. On peut mettre une formule
   sous forme prénexe à partir d’une formule sous forme normale négative en « tirant » les
   quantificateurs vers la racine.
      Une formule sous forme prénexe est universelle si elle est de la forme
   « ∀x1 ∀x2 . . . ∀xn .ψ » où ψ est sans quantificateurs. La skolémisation d’une formule
   produit une formule équi-satisfiable sous forme universelle.

   Comme en logique propositionnelle, les formules du premier ordre peuvent être mises sous                                                     (David, NouR et Raffalli, 2003,
                                                                                                                                               sec. 2.6), (Goubault-LaRRecq et
différentes formes normales préservant la sémantique (formules équivalentes) ou préservant la                                                  MacKie, 1997, sec. 6.5.1)
satisfiabilité (formules équi-satisfiables).



14.1. Forme normale négative. Une formule du premier ordre est en forme normale négative
si elle respecte la syntaxe abstraite


          ℓ ::= α | ¬α                                                                                                           (littéraux)
          φ ::= ℓ | φ ∨ φ | φ ∧ φ | ∃x.φ | ∀x.φ                                                 (formules en forme normale négative)


où α est une formule atomique et x ∈ X. En d’autres termes, les négations ne peuvent apparaître
que devant des formules atomiques. La mise sous forme normale négative procède en « pous-
sant » les négations vers les feuilles ; pour une formule φ, on notera nnf(φ) sa forme normale
96                                     INTRODUCTION À LA LOGIQUE


négative obtenue inductivement par
                nnf(α) def
                       =α,                                     nnf(¬α) def
                                                                       = ¬α ,
            nnf(φ ∨ ψ) def
                       = nnf(φ) ∨ nnf(ψ) ,                  nnf(φ ∧ ψ) def
                                                                       = nnf(φ) ∧ nnf(ψ) ,
        nnf(¬(φ ∨ ψ)) def
                      = nnf(¬φ) ∧ nnf(¬ψ) ,             nnf(¬(φ ∧ ψ)) def
                                                                      = nnf(¬φ) ∨ nnf(¬ψ) ,
            nnf(∃x.φ) def
                      = ∃x.nnf(φ) ,                          nnf(∀x.φ) def
                                                                       = ∀x.nnf(φ) ,
           nnf(¬∃x.φ) def
                      = ∀x.nnf(¬φ) ,                       nnf(¬∀x.φ) def
                                                                      = ∃x.nnf(¬φ) ,
             nnf(¬¬φ) def
                      = nnf(φ) .
En termes algorithmiques, cette mise sous forme normale négative se fait en temps linéaire. Elle
préserve visiblement la sémantique des formules : φ et nnf(φ) sont équivalentes. On notera en
général
                                             φ def
                                               = nnf(¬φ)
pour la forme normale négative de la négation de φ.

     Exemple 14.1. La formule du buveur de l’exemple 12.3 s’écrit sous forme normale négative
     comme ∃x.(¬B(x) ∨ ∀y.B(y)).

     Exemple 14.2. La formule (24) de l’exemple 12.6 s’écrit sous forme normale négative comme
                                 ∀x∀y.¬(x < y) ∨ ∃z.x < z ∧ z < y .                           (34)

     Exemple 14.3. La requête (18) de l’exemple 12.5 s’écrit sous forme normale négative comme
                      ∀c.(∀t.¬Seance(c, t)) ∨ (∃t∃i.Film(t, x, i) ∧ Seance(c, t)) .           (35)
     La requête (21) s’écrit sous forme normale négative comme
                          (∃t.Film(t, hopper, x)) ∧ (∀t.¬Film(t, kubrick, x)) .               (36)
     La requête (22) s’écrit sous forme normale négative comme
                         ∃t∃r.Film(t, r, x) ∧ ∀t′ ∀r′ .¬Film(t′ , r′ , x) ∨ t = t′ .          (37)

      On peut observer par induction structurelle sur φ que
Propriété 14.4. Pour toute formule φ en forme normale négative et toute substitution σ, (φ)σ =
(φσ).
   La profondeur p(φ) d’une formule φ en forme normale négative est définie inductivement par
p(ℓ) def                                     def
     = 0 pour un littéral, p(φ∨ψ) = p(φ∧ψ) = 1+max{p(φ), p(ψ)}, et p(∃x.φ) = p(∀x.φ) =
                                                                                           def

1 + p(φ).

14.1.1. Implémentation de la forme normale négative en OCaml. Afin d’implémenter la mise sous
forme normale négative en OCaml, nous commençons par étendre la syntaxe des formules pour
permettre explicitement les formules φ ∧ ψ et les formules ∀x.φ.
     firstorder.ml
     type fo =
       Atom of atom
     | Non of fo
     | Ou of fo * fo
     | Et of fo * fo     (* formules φ ∧ ψ *)
     | Ex of string * fo
     | Pt of string * fo (* formules ∀x.φ *)
                                       INTRODUCTION À LA LOGIQUE                                       97


   Toutes les fonctions vu dans les sections précédentes sont ensuite modifiées pour traiter cette
syntaxe étendue des formules.
   Le calcul de nnf(φ) pour une formule φ est ensuite une implémentation directe de la définition.
 firstorder.ml
 let rec nnf_of_fo: fo          ->   fo = function
     Atom (r, tl)               ->   Atom (r, tl)
   | Ou(phi, psi)               ->   Ou(nnf_of_fo phi, nnf_of_fo psi)
   | Et(phi, psi)               ->   Et(nnf_of_fo phi, nnf_of_fo psi)
   | Ex (x, phi)                ->   Ex (x, nnf_of_fo phi)
   | Pt(x, phi)                 ->   Pt(x, nnf_of_fo phi)
   | Non(Atom (r, tl))          ->   Non(Atom (r, tl))
   | Non(Non(phi))              ->   nnf_of_fo phi
   | Non(Ou(phi, psi))          ->   Et(nnf_of_fo (Non(phi)), nnf_of_fo (Non(psi)))
   | Non(Et(phi, psi))          ->   Ou(nnf_of_fo (Non(phi)), nnf_of_fo (Non(psi)))
   | Non(Ex (x, phi))           ->   Pt(x, nnf_of_fo (Non(phi)))
   | Non(Pt(x, phi))            ->   Ex (x, nnf_of_fo (Non(phi)))

14.2. Forme prénexe. Une formule est sous forme prénexe si elle est de la forme Q1 x1 . . . Qn xn .ψ         (DupaRc, 2015, sec. 11.6), (David,
                                                                                                            NouR et Raffalli, 2003, sec. 2.6.2),
où Qi ∈ {∀, ∃} pour tout 1 ≤ i ≤ n et ψ est sans quantificateur, c’est-à-dire ψ respecte la syntaxe         (Goubault-LaRRecq et MacKie, 1997,
abstraite                                                                                                   thm. 6.10), (HaRRisson, 2009, sec. 3.5)


                    ψ ::= ℓ | ψ ∨ ψ | ψ ∧ ψ .                           (formules sans quantificateur)

Propriété 14.5 (forme prénexe). Pour toute formule φ, on peut construire une formule prénexe
équivalente.

Démonstration. Sans perte de généralité, on peut supposer que φ est déjà sous forme normale
négative. On procède alors par induction sur φ :

   Cas de ℓ : Alors ℓ est déjà sous forme prénexe.

   Cas de φ ∨ φ′ : Par hypothèse d’induction, φ et φ′ sont équivalentes à Q1 x1 . . . Qn xn .ψ et
     Q′1 y1 . . . Q′m ym .ψ ′ où ψ et ψ ′ sont sans quantificateur. Par le lemme 13.4 d’α-congruence,
     on peut supposer que ces formules utilisent des ensembles disjoints de variables : {x1 , . . . , xn }∩
     fv(ψ ′ ) = ∅ et fv(ψ) ∩ {y1 , . . . , ym } = ∅.
         Montrons que la formule (Q1 x1 . . . Qn xn .ψ) ∨ (Q′1 y1 . . . Q′m ym .ψ ′ ) est équivalente à
      Q1 x1 . . . Qn xn .Q′1 y1 . . . Q′m ym .(ψ ∨ ψ ′ ), qui sera donc équivalente à φ ∨ φ′ . On procède
      pour cela par récurrence sur n + m. Le cas de base pour n + m = 0 est trivial. Pour l’étape
      de récurrence, il suffit de montrer que pour toutes formules θ et θ′ et x 6∈ fv(θ′ ),
      — (∃x.θ) ∨ θ′ avec x 6∈ fv(θ′ ) est équivalente à ∃x.θ ∨ θ′ : en effet, pour toute interpréta-
        tion I et toute valuation ρ,


   J(∃x.θ) ∨ θ′ KIρ = ( Or JθKIρ[e/x] ) or Jθ′ KIρ
                        e∈DI

                    = ( Or JθKIρ[e/x] ) or ( Or Jθ′ KIρ[e/x] )   (car DI 6= ∅, et par la propriété 12.1)
                        e∈DI                 e∈DI

                    = Or Jθ ∨ θ′ KIρ[e/x]
                       e∈DI

                    = J∃x.(θ ∨ θ′ )KIρ .
98                                         INTRODUCTION À LA LOGIQUE


           — (∀x.θ) ∨ θ′ avec x 6∈ fv(θ′ ) est équivalente à ∀x.θ ∨ θ′ : en effet, pour toute interpréta-
             tion I et toute valuation ρ,
       J(∀x.θ) ∨ θ′ KIρ = ( And JθKIρ[e/x] ) or Jθ′ KIρ
                             e∈DI

                         = And (JθKIρ[e/x] or Jθ′ KIρ )                                     (par distributivité)
                            e∈DI

                         = And (JθKIρ[e/x] or Jθ′ KIρ[e/x] )     (par la propriété 12.1 puisque x 6∈ fv(θ′ ))
                            e∈DI

                         = J∀x.(θ ∨ θ′ )KIρ .
      Cas de φ ∧ φ′ : Similaire au cas précédent.
      Cas de ∃x.φ : Par hypothèse d’induction, φ est équivalente à Q1 x1 . . . Qn xn .ψ où ψ est sans
        quantificateur. Alors ∃x.φ est équivalente à ∃x.Q1 x1 . . . Qn xn .ψ.
      Cas de ∀x.φ : Similaire au cas précédent.                                                              □

     Exemple 14.6. La négation de la formule du buveur de l’exemple 12.3 s’écrit sous forme nor-
     male négative comme ∀x.(B(x) ∧ ∃y.¬B(y)). Une forme prénexe de cette négation est alors
     ∀x.∃y.(B(x) ∧ ¬B(y)).

     Exemple 14.7. La formule (34) de l’exemple 14.2 s’écrit sous forme prénexe comme
                                    ∀x∀y∃z.¬(x < y) ∨ (x < z ∧ z < y) .                                    (38)

     Exemple 14.8. Mettons les formules de l’exemple 14.3 sous forme prénexe. Pour la requête (35),
     il faut procéder à un α-renommage sur une des sous-formules qui quantifient sur t ; par
     exemple :
                      ∀c.(∀t.¬Seance(c, t)) ∨ (∃t′ ∃i.Film(t′ , x, i) ∧ Seance(c, t′ ) .       (39)
     On peut maintenant appliquer la propriété 14.5 à (39) :
                          ∀c∀t∃t′ ∃i.¬Seance(c, t) ∨ (Film(t′ , x, i) ∧ Seance(c, t′ )) .                  (40)
     On procède de même pour (36) :
                               ∃t∀t′ .Film(t, hopper, x) ∧ ¬Film(t′ , kubrick, x) .                        (41)
     Et aussi pour (37) :
                            ∃t∃r∀t′ ∀r′ .Film(t, r, x) ∧ (¬Film(t′ , r′ , x) ∨ t = t′ ) .                  (42)

14.2.1. Implémentation de la forme prénexe en OCaml. L’implémentation le calcul de la forme
prénexe d’une formule φ en forme normale négative va suivre les arguments de la preuve de la
propriété 14.5 : une formule (∃x.ψ) ∨ φ où x 6∈ fv(φ) est logiquement équivalente à ∃x.ψ ∨ φ, et
il en est de même modulo commutativité du ∨, ainsi qu’en remplaçant ∨ par ∧ ou ∃ par ∀. Afin
de garantir x 6∈ fv(φ), on procède à un α-renommage à la volée de la formule ∃x.ψ.
     firstorder.ml
     let   rec pnf_of_nnf: fo -> fo = function
       |   Atom (_,_) as phi -> phi
       |   Non(_)     as phi -> phi
       |   Ex (x,phi) -> Ex (x, pnf_of_nnf phi)
       |   Pt(x,phi) -> Pt(x, pnf_of_nnf phi)
       |   Ou(phi,psi) -> (match (pnf_of_nnf phi, pnf_of_nnf psi) with
                             | (phi, Ex (x,psi)) -> (* α-renommage à la volée *)
                                let (y,psi') = alpha x psi (fv phi) in
                                Ex (y, pnf_of_nnf (Ou(phi, psi')))
                             | (Ex (x,psi),phi) -> (* α-renommage à la volée *)
                                let (y,psi') = alpha x psi (fv phi) in
                                       INTRODUCTION À LA LOGIQUE                                   99


                        Ex (y, pnf_of_nnf (Ou(psi', phi)))
                     | (phi, Pt(x,psi)) -> (* α-renommage à la volée *)
                        let (y,psi') = alpha x psi (fv phi) in
                        Pt(y, pnf_of_nnf (Ou(phi, psi')))
                     | (Pt(x,psi),phi) -> (* α-renommage à la volée *)
                        let (y,psi') = alpha x psi (fv phi) in
                        Pt(y, pnf_of_nnf (Ou(psi', phi)))
                     | (phi,psi) -> Ou(phi,psi))
   | Et(phi,psi) -> (match (pnf_of_nnf phi, pnf_of_nnf psi) with
                     | (phi, Ex (x,psi)) -> (* α-renommage à la volée *)
                        let (y,psi') = alpha x psi (fv phi) in
                        Ex (y, pnf_of_nnf (Et(phi, psi')))
                     | (Ex (x,psi),phi) -> (* α-renommage à la volée *)
                        let (y,psi') = alpha x psi (fv phi) in
                        Ex (y, pnf_of_nnf (Et(psi', phi)))
                     | (phi, Pt(x,psi)) -> (* α-renommage à la volée *)
                        let (y,psi') = alpha x psi (fv phi) in
                        Pt(y, pnf_of_nnf (Et(phi, psi')))
                     | (Pt(x,psi),phi) -> (* α-renommage à la volée *)
                        let (y,psi') = alpha x psi (fv phi) in
                        Pt(y, pnf_of_nnf (Et(psi', phi)))
                     | (phi,psi) -> Et(phi,psi))
 let pnf_of_fo: fo -> fo = function phi -> pnf_of_nnf(nnf_of_fo phi)

14.3. Skolémisation. Une formule φ = Q1 x1 . . . Qn xn .ψ sous forme prénexe est existentielle           (David, NouR et Raffalli, 2003,
                                                                                                        sec. 2.7), (Goubault-LaRRecq et
si Qi = ∃ pour tout 1 ≤ i ≤ n, et universelle si Qi = ∀ pour tout 1 ≤ i ≤ n. La skolémisation           MacKie, 1997, thm. 6.12), HaRRisson,
d’une formule φ est une formule universelle équi-satisfiable.                                           2009, [sec. 3.6
   On étend pour cela l’ensemble F des symboles de fonction. Pour toute formule φ et toute
variable x, on fixe une énumération ⃗xφ de fv(∃x.φ) et on ajoute un nouveau symbole de fonction
fφ,x 6∈ F d’arité |fv(∃x.φ)|. Soit F ′ def
                                       = F ] {fφ,x | f formule sur (F, P) et x ∈ X}.
   La skolémisation s(φ) d’une formule φ en forme normale négative est alors définie par
                                        s(ℓ) def
                                             =ℓ,
                                  s(φ ∨ ψ) def
                                           = s(φ) ∨ s(ψ) ,
                                  s(φ ∧ ψ) def
                                           = s(φ) ∧ s(ψ) ,
                                   s(∃x.φ) def
                                           = (s(φ))[fφ,x (⃗xφ )/x]
                                   s(∀x.φ) def
                                           = ∀x.s(φ) .
On peut noter que, si φ était sous forme prénexe, alors s(φ) est universelle.
Théorème 14.9 (SKolem). Soit φ une formule du premier ordre. Alors on peut construire une for-
mule universelle équi-satisfiable.
Démonstration. On peut supposer φ sous forme prénexe. Il suffit alors de montrer que φ et s(φ)
sont équi-satisfiables.
   Commençons par montrer que, si φ est satisfiable, alors s(φ) l’est aussi. Pour toute inter-
prétation I sur la signature (F, P), on construit une interprétation I ′ sur la signature (F ′ , P).
L’interprétation I ′ a le même domaine DI ′ def = DI que I et interprète les symboles de F et P de
                          ′            ′ def
la même manière : f I def   = f I et RI = RI pour tout f ∈ F et R ∈ P. Il faut maintenant fournir
une interprétation des symboles fφ,x . Considérons pour cela une formule φ et une variable x.
Soit x1 , . . . , xn l’énumeration de fv(∃x.φ). Pour tout tuple (e1 , . . . , en ) ∈ DIn , on définit
             DI,φ,x (e1 , . . . , en ) def
                                       = {e ∈ DI | I, ρ[e1 /x1 , . . . , en /xn , e/x] Z= φ} .   (43)
                                               100                                        INTRODUCTION À LA LOGIQUE


                                               Comme DI 6= ∅, on peut choisir un élément e∅ ∈ DI . On étend alors l’interprétation I : si
                                                                                                                   I′
                                               DI,φ,x (e1 , . . . , en ) est non vide, on choisit un représentant fφ,x (e1 , . . . , en ) ∈ DI,φ,x (e1 , . . . , en ),
                                                                        I′
                                               et sinon on pose fφ,x       (e1 , . . . , en ) = e∅ .
                                                  Montrons maintenant par induction sur φ que, pour toute interprétation I et toute valuation ρ,
                                               I, ρ Z= φ implique I ′ , ρ Z= s(φ). On ne traite ici que le cas d’une formule ∃x.φ. Soit x1 , . . . , xn
                                               l’énumération de fv(∃x.φ). On a les implications

                                                                                            I, ρ Z= ∃x.φ
                                                     ⇒                   ∃e ∈ DI , I, ρ[e/x] Z= φ
                                                                   ′
                                                     ⇒           I
                                                           I, ρ[fφ,x (ρ(x1 ), . . . , ρ(xn ))/x] Z= φ
                                                                   ′
                                                     ⇒    I ′ , ρ[fφ,x
                                                                   I
                                                                       (ρ(x1 ), . . . , ρ(xn ))/x] Z= s(φ)                                par hyp. ind.
                                                                                             ′
                                                     ⇒                                     I , ρ Z= (s(φ))[fφ,x (x1 , . . . , xn )/x]     par le lemme 13.5

                                                                              ⇒                                 I ′ , ρ Z= s(∃x.φ) .

                                                   Inversement, montrons que si s(φ) est satisfiable, alors φ l’est aussi. Pour une interprétation I
                                               sur la signature (F ′ , P), on définit l’interprétation I|F comme sa restriction à la signature (F, P) ;
                                               autrement dit, on « oublie » dans I|F les interprétations des symboles de fonction fφ,x . Montrons
                                               par induction sur φ que I, ρ Z= s(φ) implique I|F , ρ Z= φ. Encore une fois, nous ne traitons que
                                               le cas d’une formule ∃x.φ où x1 , . . . , xn est l’énumération de fv(∃x.φ). On a les implications

                                                                                             I, ρ Z= s(∃x.φ)
                                                     ⇒                                       I, ρ Z= (s(φ))[fφ,x (x1 , . . . , xn )/x]
                                                     ⇒            I
                                                           I, ρ[fφ,x  (ρ(x1 ), . . . , ρ(xn ))/x]   Z= s(φ)                                par le lemme 13.5
                                                     ⇒            I
                                                         I|F , ρ[fφ,x (ρ(x1 ), . . . , ρ(xn ))/x]   Z= φ                                   par hyp. ind.
                                                     ⇒                                    I|F , ρ Z= ∃x.φ .                                                       □

                                                 Exemple 14.10. La formule du buveur ∃x.(B(x) ⇒ ∀y.B(y)) se skolémise en introduisant
 La skolémisation préserve la                   un symbole de constante a pour f(B(x)⇒∀y.B(y)),x où fv(∃x.(B(x) ⇒ ∀y.B(y))) = ∅ :
satisfiabilité, mais pas la validité. Ainsi,
la formule du buveur est valide, mais la                                                         B(a) ⇒ ∀y.B(y) .                                               (44)
formule (44) ne l’est pas :
l’interprétation I avec DI = {e1 , e2 },         Exemple 14.11. La formule (38) de l’exemple 14.7 se skolémise en introduisant une fonction f
aI = e1 et B I = {e1 } en est un
contre-modèle.                                   d’arité deux pour fφ,z où φ = ¬(x < y) ∨ (x < z ∧ z < y) et fv(∃z.φ) = {x, y} :
                                                                             ∀x∀y.¬(x < y) ∨ (x < f (x, y) ∧ f (x, y) < y) .                                    (45)

 Les requêtes que nous obtenons ici             Exemple 14.12. La requête (40) de l’exemple 14.8 se skolémise en introduisant une fonction f
ont encore x en variable libre. Pour
obtenir une formule universelle
                                                 d’arité 3 pour fφ,t′ où φ = ∃i.¬Seance(c, t) ∨ (Film(t′ , x, i) ∧ Seance(c, t′ ) et fv(∃t.φ) =
équi-satisfiable close, il faudrait dans         {x, c, t}, ainsi qu’une fonction g d’arité 4 pour fψ,i où ψ = ¬Seance(c, t) ∨ (Film(t′ , x, i) ∧
chaque cas introduire une constante a et         Seance(c, t′ ) et fv(∃i.ψ) = {x, c, t, t′ } :
remplacer x par a.
                                                     ∀c∀t.¬Seance(c, t) ∨ (Film(f (x, c, t), x, g(x, c, t, f (x, c, t))) ∧ Seance(c, f (x, c, t))) .            (46)
                                                 La requête (41) se skolémise en introduisant une fonction h d’arité 1 :
                                                                            ∀t′ .Film(h(x), hopper, x) ∧ ¬Film(t′ , kubrick, x) .                               (47)
                                                 La requête (42) se skolémise en introduisant une fonction f d’arité 1 et une fonction g ′
                                                                                                                               ′

                                                 d’arité 2 :
                                                                  ∀t′ ∀r′ .Film(f ′ (x), g ′ (x, f ′ (x))) ∧ (¬Film(t′ , r′ , x) ∨ f ′ (x) = t′ ) .             (48)
                                     INTRODUCTION À LA LOGIQUE                                     101


14.3.1. Implémentation de la skolémisation en OCaml. Pour implémenter la skolémisation, c’est-
à-dire la fonction s(φ) définie plus haut, nous allons avoir besoin de générer des symboles de
fonction fφ,x . On implémente pour cela une séquence functions de type string t qui liste
des symboles de fonctions. Il faut de plus éviter qu’un nom de fonction fφ,x soit en conflit avec
un symbole de fonction utilisé dans φ ; la fonction ff : fo -> string list retourne pour
cela l’ensemble des symboles de fonction utilisés dans la formule passée en argument.
 firstorder.ml
 let skolem_of_nnf : fo -> fo =
   let rec aux = fun forbidden -> function
       Atom (_,_) as phi -> phi
     | Non(_)     as phi -> phi
     | Ou(phi, psi)       -> Ou(aux forbidden phi, aux forbidden psi)
     | Et(phi, psi)       -> Et(aux forbidden phi, aux forbidden psi)
     | Pt(x, phi)         -> Pt(x, aux forbidden phi)
     | Ex (x, phi)        ->
        (* appel récursif pour construire s(φ) *)
        let sphi = aux forbidden phi in
        (* la séquence de variables ⃗xφ sous forme de liste *)
        let args = List.rev_map (fun x -> Var x) (fv (Ex (x,phi))) in
        (* le symbole de fonction fφ,x *)
        let fphix =
           find (fun f -> not(List.mem f (List.rev_append forbidden (ff sphi))))
             functions in
        (* application de la substitution [fφ,x (⃗xφ )/x] *)
        fsubst [(x, Fun(fphix, args))] sphi
   in fun phi -> aux (ff phi) phi
 let skolem phi = skolem_of_nnf(nnf_of_fo phi)


14.4. * Forme clausale. Une clause est une formule close universelle ∀x1 . . . ∀xn .ψ où ψ est            (David, NouR et Raffalli, 2003,
                                                                                                         sec. 7.4.2)
une disjonction de littéraux. Une formule est sous forme clausale si c’est une conjonction de
clauses, que l’on présente aussi comme un ensemble de clauses.                                            La mise sous forme clausale en
                                                                                                         logique du premier ordre sert en
Théorème 14.13 (forme clausale). Soit φ une formule. Alors on peut construire un ensemble équi-          particulier de préliminaire à l’utilisation
                                                                                                         des preuves par résolution ; voir (David,
satisfiable Cl(φ) de clauses.                                                                            NouR et Raffalli, 2003, sec 7.4),
                                                                                                         (Goubault-LaRRecq et MacKie, 1997,
Démonstration. Soit φ une formule. En quantifiant existentiellement ses variables libres fv(φ) =         sec. 7.3)
{x1 , . . . , xn }, on obtient une formule close équi-satisfiable φ′ def
                                                                     = ∃x1 . . . ∃xn .φ. Par le théo-
rème 14.9 de SKolem, on construit une formule universelle close équi-satisfiable s(φ′ ). Il reste
simplement à mettre s(φ′ ) sous forme normale conjonctive, en utilisant le fait queV ∀x.φ  W ∧ ψ est
équivalente à (∀x.φ) ∧ (∀x.ψ). On obtient ainsi une écriture de s(φ) comme i ∀⃗x. ji ℓji , et             Voir la section 5.2.1 pour la mise sous
                                  W                                                                      forme normale conjonctive.
on définit alors Cl(φ) def = {∀⃗x. ji ℓji }i .                                                     □

  Exemple 14.14. La forme clausale de la négation ¬(∃x.B(x) ⇒ ∀y.B(y)) de la formule du
  buveur est ¬B(a) ∧ ∀x.B(x).

14.4.1. Implémentation de la forme clausale en OCaml. Voyons comment implémenter la construc-
tion donnée dans la démonstration du théorème 14.13. La première étape est de construire φ′ def     =
∃x1 . . . ∃xn .φ où fv(φ) = {x1 , . . . , xn } ; on implémente cela dans la fonction close ci-dessous.
 firstorder.ml
 (* quantification existentielle des variables libres *)
 let close: fo -> fo = fun phi ->
   let rec quantify vars phi = match vars with
102                                    INTRODUCTION À LA LOGIQUE


         | []    -> phi
         | x::xs -> quantify xs (Ex (x,phi))
       in quantify (fv phi) phi

      La deuxième étape est de skolémiser φ′ en une formule universelle close équi-satisfiable.
  firstorder.ml
  (* formule universelle close équi-satisfiable *)
  let universal: fo -> fo = fun phi -> skolem(close(phi))

      Pour la mise sous forme clausale, on va définir une clause comme une liste de littéraux :
  firstorder.ml
  type litteral = Pos of string * term list | Neg of string * term list
  type clause   = litteral list

      On définit des fonctions auxiliaires pour manipuler des formules sous forme clausale.
  firstorder.ml
                                                              ∧∨            ∧∨
  (* calcul de la forme normale conjonctive de (   ℓi,j ) ∧ ( ℓ0k,l ) *)
  let cnf_and_cnf: clause list -> clause list -> clause list =
    List.rev_append
                                                              ∧∨            ∧∨
  (* calcul de la forme normale conjonctive de (     ℓi,j ) ∨ ( ℓ0k,l ) *)
  let cnf_or_cnf: clause list -> clause list -> clause list =
    (* calcul de la forme normale
        ∨         ∧∨ 0       ∧(∨     ∨conjonctive
                                           )      de
       ( ℓj ) ∨ (   ℓk,l ) ⇔     ℓj ∨ ℓ0k,l *)
    let cnf_or_cl: clause list -> clause -> clause list =
      fun clauses cl -> List.rev_map (List.rev_append cl) clauses in
    fun clauses1 clauses2 -> concat_map (cnf_or_cl clauses1) clauses2
                                                              (∧∨       )
  (* calcul de la forme normale conjonctive de ¬       ℓi,j ) *)
  let not_cnf: clause list -> clause list = fun clauses ->
    (* si ⊥ apparaît dans la conjonction, alors on retourne ∅ *)
    if List.mem
           ( ∧ ∨ []) clauses
                       ∨ ∧ then [] else
      (* ¬      ℓi,j ⇔     ℓi,j *)
      let negclauses = List.rev_map
                           (fun cl -> List.rev_map (function
                                            Pos(r,tl) -> [Neg(r,tl)]
                                          | Neg(r,tl) -> [Pos(r,tl)]) cl)
                           clauses in
      let rec distribute = function
          []          -> [[]]
        | cnf::cnfs -> cnf_or_cnf cnf (distribute cnfs) in
      distribute negclauses

    La mise sous forme clausale proprement dite est en fait une mise sous forme conjonctive de
la sous-formule sans quantificateur ψ de s(φ′ ) = ∀y1 · · · ∀ym .ψ.
  firstorder.ml
  let clauses_of_fo: fo -> clause list = fun phi ->
  (* descendre dans une formule universelle close
      jusqu'à la formule ψ sans quantificateur *)
  let rec qf_of_prenex: fo -> fo = function
       Ex (_, psi) -> qf_of_prenex psi
     | Pt(_, psi) -> qf_of_prenex psi
     | psi         -> psi
  in
                                                INTRODUCTION À LA LOGIQUE                                          103


  let psi = qf_of_prenex (universal phi) in
  (* mise sous forme clausale de ψ (qui est en nnf et sans quantificateur) *)
  let rec cnf_of_qf: fo -> clause list = function
      Atom (r,tl)      -> [[Pos(r,tl)]]
    | Non(Atom (r,tl)) -> [[Neg(r,tl)]]
    | Et(psi1,psi2)    -> cnf_and_cnf (cnf_of_qf psi1) (cnf_of_qf psi2)
    | Ou(psi1,psi2)    -> cnf_or_cnf (cnf_of_qf psi1) (cnf_of_qf psi2)
    | _                -> failwith "incorrect argument of cnf_of_qf"
  in cnf_of_qf psi

14.5. * Modèles de HeRbRand. Nous avons vu dans la définition de la sémantique des for-                                   (Goubault-LaRRecq et MacKie, 1997,
mules du premier ordre que les interprétations pouvaient être extrêmement variées : il suffit d’un                       sec. 5.2), (HaRRisson, 2009, sec. 3.7)
domaine non vide et d’interprétations des symboles de fonction et de relation. Si on cherche à
construire un modèle d’une formule, cela laisse un choix considérable. Nous allons voir dans cette
section qu’en fait, on peut se restreindre à des interprétations très particulières, appelées inter-
prétations de HeRbRand, dans lesquelles le domaine est tout simplement l’ensemble des termes
clos.
   Supposons pour cela F0 6= ∅, de telle sorte que l’ensemble T (F) des termes clos soit non
vide. L’interprétation d’un symbole de fonction f d’arité n dans une interprétation de HeRbRand
va simplement être la fonction qui associe le terme f (t1 , . . . , tn ) aux termes t1 , . . . , tn . Afin
d’interpréter les symboles de relation, on va définir la base de HeRbRand
                      B def
                        = {R(t1 , . . . , tm ) | m ∈ N, R ∈ Pm , t1 , . . . , tm ∈ T (F)}
comme l’ensemble des instanciations des symboles de relation de P.
   Une interprétation de HeRbRand est une fonction H : B → B qui associe une valeur de vérité
à chaque élément de la base de HeRbRand. On identifie H avec l’interprétation de domaine
DH def
    = T (F) qui associe
          f H (t1 , . . . , tn ) def
                                 = f (t1 , . . . , tn ) ,     RH (t1 , . . . , tm ) def
                                                                                    = H(R(t1 , . . . , tm ))
à tout f ∈ Fn et R ∈ Pm pour tout n, m.
Théorème 14.15 (HeRbRand). Soit S un ensemble de formules universelles closes. Alors S est
satisfiable si et seulement si S est satisfiable dans une interprétation de HeRbRand.
Démonstration. Seul le sens direct nécessite une preuve. Soit I une interprétation telle que I Z= S.                      Les formules de S doivent être
On définit l’interprétation de HeRbRand H par H(R(t1 , . . . , tm )) def            = JR(t1 , . . . , tm )KI pour tous   closes : S = {P (x), ¬P (a)} avec
                                                                                                                         F = {a} est satisfiable mais ne l’est pas
m ∈ N, R ∈ Pm , et t1 , . . . , tm ∈ T (F) ; comme les formules et termes en question sont clos, il                      dans une interprétation de HeRbRand.
n’est pas utile de préciser sous quelle valuation.
    Montrons que H Z= S. Pour toute formule close ∀x1 . . . ∀xn .φ ∈ S où φ est sans quan-
tificateur et fv(φ) = {x1 , . . . , xn }, et pour tous t1 , . . . , tn ∈ DH = T (F), on définit σ def               =
[t1 /x1 , . . . , tn /xn ] – qui peut être vue à la fois comme une substitution close et comme une valua-
tion dans DH – et ρ def     = [Jt1 KI /x1 , . . . , Jtn KI /xn ] une valuation dans I. On montre JφKH        σ = JφKρ
                                                                                                                     I

par induction sur φ ; par suite, comme I Z= ∀x1 . . . ∀xn .φ, on en déduit H Z= ∀x1 . . . ∀xn .φ
comme voulu.
    — Pour une formule atomique α, par définition de H, JαKH                  σ = JασK par le lemme 13.5, et
                                                                                         H

       cette sémantique est égale à JασK par définition de R , qui n’est autre que JαKIρ par le
                                                      I                       H

       lemme 13.5.
                                                              H h.i.
    — Pour une négation ¬φ, J¬φKH            σ = not JφKσ = not JφKρ = J¬φKρ .
                                                                            I          I

                                                                             H h.i.
    — Pour une disjonction φ ∨ ψ, Jφ ∨ ψKH               σ = JφKσ or JψKσ = JφKρ or JψKρ = Jφ ∨ ψKρ .
                                                                   H                  I         I              I
                                                                                                                    □
   Le théorème de HeRbRand permet de « réduire » la logique du premier ordre à la logique
propositionnelle. Pour une formule universelle close φ = ∀⃗x.φ′ où φ′ est sans quantificateur,
            = {φ′ σ | σ substitution close} l’ensemble de ses instances de HeRbRand. Pour
on note φΣ def
104                                     INTRODUCTION À LA LOGIQUE

                                                               S
un ensemble de formules universelles closes S, on écrit SΣ def
                                                           = φ∈S φΣ. Une formule de SΣ
peut ainsi être vue comme une formule propositionnelle avec la base de HeRbRand B comme
ensemble de propositions.
Propriété 14.16. Soit S un ensemble de formules universelles closes et H une interprétation de
HeRbRand. Alors H Z= S si et seulement si H Z= SΣ.
Démonstration. Pour toute formule close φ = ∀x1 . . . ∀xn .φ′ ∈ S où φ′ est sans quantificateur
et fv(φ′ ) = {x1 , . . . , xn }, H Z= φ si et seulement si pour tous termes clos t1 , . . . , tn ∈ DH ,
H, [t1 /x1 , . . . , tn /xn ] Z= φ′ , si et seulement si pour tous termes clos t1 , . . . , tn ∈ T (F), H Z=
φ′ [t1 /x1 , . . . , tn /xn ], si et seulement si pour toute formule ψ ∈ φΣ, H Z= ψ.                       □
Corollaire 14.17. Soit S un ensemble de formules universelles closes. Alors S est satisfiable si et
seulement si SΣ est propositionnellement satisfiable sur l’ensemble de propositions B.
Démonstration. Par le théorème 14.15, S est satisfiable si et seulement s’il existe une interpréta-
tion de HeRbRand H telle que H Z= S. Il suffit alors d’appliquer la propriété 14.16 à S et H. □
                                     INTRODUCTION À LA LOGIQUE                                      105


                                    15. ThÉoRies et modÈles

   Résumé. Une théorie est un ensemble T de formules closes (c’est-à-dire de formules sans
   variables libres) tel que, si φ est close et T Z= φ, alors φ ∈ T . On définit habituellement
   des théories de deux manières :
     (1) comme l’ensemble des formules closes Th(I) def
                                                    = {φ close | I Z= φ} dont une
         interprétation I est un modèle, ou
     (2) comme l’ensemble des formules closes Th(A) def
                                                      = {φ close | A Z= φ} des consé-
         quences logiques d’une axiomatisation A (c’est-à-dire que A est un ensemble de
         formules closes).
       Dans une signature L qui contient le symbole d’égalité =, une interprétation est nor-
   male si l’interprétation =I du symbole est l’égalité sur le domaine. Si une interprétation I
   satisfait les axiomes de congruence, alors =I est une congruence et on peut construire
   l’interprétation quotient I/=I , qui est une interprétation normale qui satisfait les mêmes
   formules que I (c.f. lemme 15.5).
       Une théorie T est cohérente si elle ne contient pas à la fois une formule φ et sa né-
   gation ¬φ. Elle est complète si, pour toute formule close φ, φ ∈ T ou ¬φ ∈ T . Elle est
   décidable s’il existe un algorithme (qui dépend de T ) qui prend en entrée une formule
   close φ et répond si φ ∈ T ou non.
       Toutes les théories ne sont pas décidables. Une manière de montrer qu’une théo-
   rie T est décidable est de montrer qu’elle permet l’élimination des quantificateurs, c’est-
   à-dire de montrer que pour toute formule φ (pas nécessairement close), il existe une for-
   mule ψ sans quantificateurs telle que T Z= φ ⇔ ψ. C’est le cas par exemple de la théorie
   Th(Aoldns ) des ordres linéaires denses non bornés stricts (c.f. lemme 15.12) et de la théorie
   Th(Q, 1, (q·)q∈Q , +, <) de l’arithmétique linéaire sur les rationnels (c.f. lemme 15.15).

   Prise en isolation, une formule du premier ordre utilise des symboles non interprétés, qui              (DupaRc, 2015, sec. 11.7), (David,
                                                                                                          NouR et Raffalli, 2003, chap. 3),
peuvent être interprétés de manière arbitraire et potentiellement contre-intuitive. Ainsi, quand          (Goubault-LaRRecq et MacKie, 1997,
nous avons défini les signatures des exemples 10.2, 10.3 et 10.5, nous avions une intuition de            sec. 6.4)
quelles interprétations seraient « raisonnables », mais rien n’oblige les interprétations à respec-
ter cette intuition. Dans la signature F def       def
                                         = ∅ et P = {<(2) , =(2) } de l’exemple 10.2, les formules
closes
                         ∃x.¬(x = x)                             ∃x.x < x
sont satisfiables, par exemple par l’interprétation I de domaine DI = {e} telle que <I = {(e, e)}
et =I = ∅. De manière similaire, dans la signature de l’exemple 10.5, la formule close
                                        hopper = easyrider
est satisfiable, par exemple par l’interprétation I de domaine DI = {e} telle que tous les symboles
de constantes soient interprétées comme e (shiningI = playerI = · · · = odeonI = e), et FilmI =
SeanceI = ∅ et =I = {(e, e)}.
   Le problème que nous rencontrons avec ces exemples est que nous voulons restreindre nos in-
terprétations à avoir une forme particulière, pour interdire les interprétations « contre-intuitives ».

15.1. Théories logiques. Rappelons que pour un ensemble S de formules et une formule φ, φ
est une conséquence logique de S, noté S Z= φ, si pour toute interprétation I, si I est un modèle
de toutes les formules de S alors I est un modèle de φ. En symboles, S Z= φ si I Z= S (c’est-à-dire
si pour toute valuation ρ et toute formule ψ ∈ S, I, ρ Z= ψ) implique I Z= φ. Rappelons aussi
qu’une formule close est une formule sans variable libre.
                                           106                                  INTRODUCTION À LA LOGIQUE


 (HaRRisson, 2009, def. 5.4).                Une théorie est un ensemble T de formules closes sur une même signature (F, P) du premier
 À noter que certains ouvrages            ordre, tel que, si φ est une formule close et T Z= φ, alors φ ∈ T . Par exemple, l’ensemble de
définissent une théorie comme un           toutes les formules closes est une théorie – d’un intérêt toutefois assez limité.
ensemble de formules closes, sans
demander qu’il soit fermé par
conséquence logique ; c’est le cas par
                                           15.1.1. Théories de structures. Pour une interprétation I, on définit la théorie de I comme l’en-
exemple de (DupaRc, 2015, sec. 11.7),      semble
(David, NouR et Raffalli, 2003,
def. 2.5.1) et (Chang et KeisleR, 1990,                                  Th(I) def
                                                                               = {φ close | I Z= φ}                                       (49)
sec. 1.4). Dans ces notes nous parlerons
                                           des formules closes dont I est un modèle. Plus généralement, pour une classe K d’interprétations
plutôt d’axiomatisations pour de tels
ensembles de formules ; voir la            sur la même signature, la théorie de K est l’ensemble
section 15.1.2 ci-dessous.
                                                                        Th(K) def
                                                                              = {φ close | ∀I ∈ K . I =
                                                                                                      Z φ}                                (50)
                                           des formules closes qui sont vraies dans toutes les interprétations dans K ; avec ces notations,
                                           Th(I) = Th(K) pour la classe K def = {I} qui ne contient que I. On vérifie aisément que Th(K) est
                                           bien une théorie : si Th(K) Z= φ, c’est-à-dire si pour toute interprétation I, I Z= Th(K) implique
                                           I Z= φ, alors en particulier pour toute interprétation I ∈ K, I Z= Th(K) par définition de Th(K),
                                           donc I Z= φ et donc φ ∈ Th(K).

                                             Exemple 15.1. Prenons comme dans l’exemple 10.1 une signature F = ∅ et P = {P (0) , Q(0) }
                                             avec deux propositions P et Q, et soit l’interprétation de domaine DI = {•} où P I = 1 et
                                             QI = 0. Alors Th(I) contient en particulier les formules P , ¬Q, P ∨ Q ∨ Q, ¬¬P , Q ∨ ∃x.P ,
                                             etc.
                                           15.1.2. Théories axiomatiques. L’approche précédente, qui définit des théories à partir d’une classe
                                           d’interprétations K, se heurte rapidement au problème suivant : comment définir la classe K elle-
                                           même ? Ainsi, pour la signature de l’exemple 10.2, on pourrait souhaiter ne considérer que des
                                           ordres. Pour cela, il est pratique de spécifier directement dans la logique quelles sont les pro-
                                           priétés attendues de nos interprétations. Par exemple, on peut demander pour la signature de
                                           l’exemple 10.2 que ∀x.x = x.
                                               En général, une axiomatisation A est un ensemble de formules closes sur une signature (F, P)
                                           du premier ordre. La théorie de A est alors définie comme l’ensemble

                                                                             Th(A) def
                                                                                   = {φ close | A Z= φ}                                   (51)
                                           des conséquences logiques closes de A ; on parle parfois de « théorie axiomatique » pour une
                                           telle théorie. Lorsque A est un ensemble fini, on dit que Th(A) est définissable. Lorsque A est
                                           récursif – c’est-à-dire lorsqu’il existe un algorithme qui prend en entrée une formule ψ et répond
                                           si ψ ∈ A ou non –, on dit que Th(A) est récursivement axiomatisable. Bien sûr, si Th(A) est
                                           définissable, alors elle est récursivement axiomatisable.

                                             Exemple 15.2 (théorie de l’égalité pure). Considérons la signature P = {=(2) }. Nous dé-
                                             finissons une axiomatisation Aeq telle que I Z= Aeq si et seulement si =I est une relation
                                             d’équivalence sur DI :
                                                                ∀x.                                    x=x                  (réflexivité de =)
                                                              ∀x∀y.                          x=y ⇒y =x                        (symétrie de =)
                                                           ∀x∀y∀z.                (x = y ∧ y = z) ⇒ x = z                  (transitivité de =)
                                             Par exemple, l’interprétation I dépeinte dans la figure 24 et définie par DI def
                                                                                                                          = {a, b, c} et
                                             =I def
                                                = {(a, a), (a, b), (b, a), (b, b), (c, c)} est un modèle de Aeq .
                                          INTRODUCTION À LA LOGIQUE                                               107


                                              =           =           =
                                                  =
                                              a           b           c
                                                  =

                           FiguRe 24. Une interprétation I telle que I Z= Aeq .

  Exemple 15.3 (théorie des congruences). Considérons une signature L = (F, P) telle que
  =(2) ∈ P. Nous définissons une axiomatisation Acgr (L) telle que I Z= Acgr (L) si et seulement
  si =I est une congruence sur DI : on définit pour cela Acgr (L) comme Aeq à laquelle on ajoute,
  pour tout symbole de fonction f d’arité n dans F
    ∀x1 . . . ∀xn .∀y1 . . . ∀yn .   x1 = y1 ∧ · · · ∧ xn = yn ⇒ f (x1 , . . . , xn ) = f (y1 , . . . , yn )
                                                                                            (f -congruence)
  et pour tout symbole de relation R 6= = d’arité m dans P
  ∀x1 . . . ∀xm .∀y1 . . . ∀ym . x1 = y1 ∧ · · · ∧ xm = ym ⇒ (R(x1 , . . . , xm ) ⇒ R(y1 , . . . , ym ))
                                                                                    (R-congruence)
  Par exemple, pour Los def                                                     def
                        = (∅, {<(2) , =(2) }), l’interprétation I de domaine DI = {a, b, c, d} où
     <I def
        = {(a, c), (b, c), (a, d), (b, d), (c, d)}        =I def
                                                             = {(a, a), (a, b), (b, a), (b, b), (c, c), (d, d)}
  est un modèle de Acgr (Los ) (voir la figure 25).


                                     =    a                   <
                                                      <       =
                                         = =                      <
                                                              c           d   =
                                                  <
                                     =    b               <


                       FiguRe 25. Une interprétation I telle que I Z= Acgr (Los ).


15.1.3. Interprétations normales. Soit L = (F, P) une signature du premier ordre qui contient le                         (HaRRisson, 2009, sec. 4.1)
symbole d’égalité, c’est-à-dire tel que =(2) ∈ P. Une interprétation I de L est dite normale si =I
est la relation d’égalité sur DI . Quand on utilise la logique du premier ordre avec le symbole =(2) ,
on souhaite généralement que celui-ci soit interprété comme l’égalité, donc ne travailler qu’avec
des interprétations normales.
   Comme vu dans les exemples 15.2 et 15.3, même en présence des axiomes de l’égalité, les
interprétations ne sont pas forcément normales. Une manière de construire une interprétation
normale à partir d’un modèle de Acgr (L) est de faire son quotient, c’est-à-dire d’identifier les
éléments de DI qui sont équivalents par la relation =I .
   Plus précisément, si une interprétation I est un modèle de Acgr (L), c’est-à-dire si =I est une
congruence, alors on peut définir son quotient I/=I . Le domaine DI/=I def            = DI /=I de ce quo-
tient est l’ensemble des classes d’équivalences de DI ; on écrit [e]=I pour la classe d’équivalence
qui contient l’élément e ∈ DI . Pour chaque symbole de fonction f ∈ F d’arité n, son inter-
                                              I
prétation dans I/=I est telle que f I/= ([e1 ]=I , . . . , [en ]=I ) def = [e]=I si f I (e1 , . . . , en ) = e.
Pour chaque symbole de relation R ∈ P \ {=} d’arité m, son interprétation dans I/=I est telle
            I
que RI/= ([e1 ]=I , . . . , [em ]=I ) = 1 si RI (e1 , . . . , em ) = 1. Enfin, l’interprétation du symbole
108                                                     INTRODUCTION À LA LOGIQUE


d’égalité dans I/=I est l’égalité entre classes d’équivalences : l’interprétation I/=I est bien une
interprétation normale.

  Exemple 15.4 (quotients). Les quotients des interprétations des figures 24 et 25 sont repré-
  sentées dans les figures 26 et 27 respectivement. Dans ces figures, [a]=I = [b]=I = {a, b} et
  [c]=I = {c}.


                                                               =                     =

                                                            {a, b}                  {c}

                       FiguRe 26. Le quotient I/=I de l’interprétation de la figure 24.


                                                                              <

                                         =          {a, b}         <          {c}     <            {d}      =

                                                                              =

                       FiguRe 27. Le quotient I/=I de l’interprétation de la figure 25.

   L’intérêt de cette construction du quotient I/=I d’une interprétation I est que l’on ne peut
pas « distinguer » le quotient de l’interprétation I à l’aide d’une formule du premier ordre ; on
dit dans ce cas que I et I/=I sont élémentairement équivalents.
Lemme 15.5 (équivalence élémentaire d’un quotient). Soit I une L-interprétation telle que I Z=
Acgr (L) et I/=I son quotient. Pour toute valuation ρ : X → DI , on définit [ρ]=I : X → DI /=I
par [ρ]=I (x) def
              = [ρ(x)]=I pour tout x ∈ X. Alors, pour tout terme t et pour toute formule du premier
                                   I/=I                         I/=I
ordre φ, [JtKIρ ]=I = JtK[ρ]                 et JφKIρ = JφK[ρ]            .
                                        =I                           =I

Démonstration. Le lemme se démontre par induction sur les termes t et les formules φ. Pour le
cas de base des termes,
                            I/=I
                       JxK[ρ]           = [ρ]=I (x) = [ρ(x)]=I = [JxKIρ ]=I .
                                   =I

Pour l’étape d’induction des termes, si f ∈ Fn ,
                            I/=I                    I       I/=I                    I/=I
       Jf (t1 , . . . , tn )K[ρ]        = f I/= (Jt1 K[ρ]            , . . . , Jtn K[ρ]        )
                                   =I                          =I                         =I
                                                    I
                                        = f I/= ([Jt1 KIρ ]=I , . . . , [Jtn KIρ ]=I )                   par hyp. ind.
                                                                                                                             I
                                        =    [f (Jt1 KIρ , . . . , Jtn KIρ )]=I
                                                I
                                                                                                         par def. de f I/=
                                        =    [Jf (t1 , . . . , tn )KIρ ]=I .
      Pour le cas de base des formules, si R ∈ P \ {=} est d’arité m,
                            I/=I                    I        I/=I                   I/=I
      JR(t1 , . . . , tm )K[ρ]          = RI/= (Jt1 K[ρ]             , . . . , Jtn K[ρ]        )
                                   =I                           =I                        =I
                                                    I
                                        = RI/= ([Jt1 KIρ ]=I , . . . , [Jtn KIρ ]=I )                    par hyp. ind.
                                                                                                                             I
                                        = RI (Jt1 KIρ , . . . , Jtn KIρ )                                par def. de RI/=
                                        = JR(t1 , . . . , tm )KIρ .
                                                    INTRODUCTION À LA LOGIQUE                                          109


Dans le cas d’une formule atomique qui utilise le symbole d’égalité,
                      I/=I               I/=I                      I/=I
             Jt = t′ K[ρ]        = (JtK[ρ]             = Jt′ K[ρ]         )            car I/=I est normale
                            =I                 =I                    =I

                                 = ([JtKIρ ]=I = [Jt′ KIρ ]=I )                        par hyp. ind.
                                 =   (JtKIρ   =   I
                                                       Jt′ KIρ )                       par déf. de [.]=I
                                 = Jt =       t′ KIρ   .
Les cas de la négation et de la disjonction sont faciles, et il reste l’étape d’induction pour
                      I/=I                                   I/=I
              J∃x.φK[ρ]          =      Or             JφK[ρ]           ′ /x]
                            =I       e′ ∈DI /=I                 =I [e

                                                      I/=I
                                 = Or JφK[ρ]                                           par déf. de DI /=I et de Or
                                     e∈DI                  =I [[e]=I /x]

                                                      I/=I
                                 = Or JφK[ρ[e/x]]                                      par déf. de [ρ]=I
                                     e∈DI                       =I


                                 = Or JφKIρ[e/x]                                       par hyp. ind.
                                     e∈DI

                                 = J∃x.φKIρ .                                                                          □
   Le lemme 15.5 permet de raisonner sur les interprétations normales à la place des interpréta-
tions : pour toute formule φ sur une signature L avec le symbole d’égalité,
   — il existe une interprétation normale I et une valuation ρ telles que I, ρ Z= φVsi et seulement
       s’il existe une interprétation I ′ et une valuation ρ′ telles que I ′ , ρ′ Z= φ ∧ ψ∈Acgr (L) ψ ;
   — il existe une interprétation normale I telle que, pour toute valuation ρ, I, ρ Z= φ si et
       seulement
       V            s’il existe une interprétation I ′ telle que, pour toute valuation ρ′ , I ′ , ρ′ Z= φ ∧
          ψ∈Acgr (L) ψ ;
   — pour toute interprétation normale I et pour toute valuation ρ, I, V        ρ Z= φ si et seulement
                                                                                                        si,
       pour toute interprétation I ′ et pour toute valuation ρ′ , I ′ , ρ′ Z=      ψ∈Acgr (L) ψ ⇒ φ.
Autrement dit, les notions de satisfiabilité, d’existence de modèle et de validité restreintes aux                            Les ouvrages de théorie des modèles
                                                                                                                             comme (Chang et KeisleR, 1990 ;
interprétations normales se réduisent aux notions correspondantes pour des interprétations ar-                               Ebbinghaus, Flum et Thomas, 1994) ou
bitraires.                                                                                                                   de théorie des modèles finis comme
                                                                                                                             (LibKin, 2004) travaillent uniquement
  Exemple 15.6 (théorie des ordres stricts). Reprenons la signature Los = (F, P) où F = ∅ et                                 avec des interprétations normales.
  P = {<(2) , =(2) } de l’exemple 10.2. Nous allons définir une axiomatisation Aos telle que, pour
  toute interprétation normale I, I Z= Aos si et seulement si DI est strictement ordonné par <I .
  Nous ajoutons pour cela à Acgr (Los ) de l’exemple 15.3 les deux formules suivantes :
                      ∀x.                                                       ¬(x < x)             (irréflexivité de <)
                ∀x∀y∀z.                           (x < y ∧ y < z) ⇒ x < z                              (transitivité de <)
  Par exemple, les interprétations des figures 25, 27 et 28 sont des modèles de Aos . Si I Z= Aos ,
  on appelle <I un pré-ordre strict ; si I est de plus une interprétation normale, alors <I est un
  ordre (partiel) strict.


  Exemple 15.7 (théorie des ordres linéaires stricts). Continuons l’exemple 15.6. Nous définis-
  sions une axiomatisation Aols qui contient les formules de Aos plus la formule suivante :
                                                ∀x∀y.x < y ∨ x = y ∨ y < x                                 (totalité de <)
  L’interprétation I de la figure 28 n’est pas un modèle de Aols puisque a 6< b, a 6=I b et b 6<I a.
                                                                                                 I

  Les interprétations des figures 25 et 27 sont en revanche des modèles de Aols . Si I Z= Aols ,
  on appelle <I un pré-ordre total strict ; si de plus I est normale, alors on appelle <I un ordre
  linéaire strict.
110                                           INTRODUCTION À LA LOGIQUE


                  =     a       <    c    =                  =     {a}
                            <                                               <
                                    = =                                         {c, d}        =
                            <                                               <
                  =                       =                  =     {b}
                        b       <    d

            FiguRe 28. Une interprétation I telle que <I soit un pré-ordre strict (à gauche)
            et son quotient I/=I (à droite).




  Exemple 15.8 (axiomatiser une interprétation). Reprenons maintenant la signature L et l’in-
  terprétation I de l’exemple 10.5. On souhaite définir une axiomatisation A qui contient Acgr (L)
  et telle que Th(I) = Th(A). Pour cela, on va définir A de telle sorte que, pour toute interpré-
                                                  ′
  tation I ′ , I ′ Z= A si et seulement si I ′ /=I est isomorphe à I ; dès lors, A Z= φ
      — ssi pour toute interprétation I , si I ′ Z= A alors I ′ Z= φ (par déf. de A Z= φ),
                                            ′
                                                         ′
      — ssi pour toute interprétation I ′ , si I ′ /=I et I sont isomorphes, alors I ′ = Z φ (par hyp.
                 ′
         sur I Z= A),
                                                       ′                                   ′
      — ssi pour toute interprétation I ′ , si I ′ /=I et I sont isomorphes, alors I ′ /=I Z= φ (par le
         lemme 15.5),
      — ssi I Z= φ.
                                                             I′
  Nous W allons commencer par imposer que DI ′ /= soit inclus dans DI par la formule
  ∀x. c∈F0 x = c, c’est-à-dire
            ∀x.x = shining ∨ x = player ∨ x = easyrider ∨ x = apocalypsenow ∨ x = kubrick ∨ x = altman
              ∨x = hopper ∨ x = nicholson ∨ x = robbins ∨ x = coppola ∨ x = champo ∨ x = odeon

  À noter que cette formule garantit en particulier que pour toute constante c ∈ F0 , il existe
                       ′     ′      ′
  d ∈ F0 telle que (cI , dI ) ∈ {=I }.
                                                                                      I′     I′
                                   V constantes c 6= d de F0 , leurs interprétations c et d
  Nous forçons aussi que pour toutes
  soient distinctes, par la formule c̸=d∈F0 ¬(c = d), c’est-à-dire
      ¬(shining = player) ∧ ¬(shining = easyrider) ∧ ¬(shining = apocalypsenow) ∧ ¬(shining = kubrick)
  ∧¬(shining = altman) ∧ ¬(shining = hopper) ∧ ¬(shining = nicholson) ∧ ¬(shining = robbins)
  ∧¬(shining = coppola) ∧ ¬(shining = champo) ∧ ¬(shining = odeon) ∧ ¬(player = easyrider)
  ∧¬(player = apocalypsenow) ∧ ¬(player = kubrick) ∧ ¬(player = altman) ∧ ¬(player = hopper)
  ∧¬(player = nicholson) ∧ ¬(player = robbins) ∧ ¬(player = coppola) ∧ ¬(player = champo)
  ∧¬(player = odeon) ∧ ¬(easyrider = apocalypsenow) ∧ ¬(easyrider = kubrick) ∧ ¬(easyrider = altman)
  ∧¬(easyrider = hopper) ∧ ¬(easyrider = nicholson) ∧ ¬(easyrider = robbins) ∧ ¬(easyrider = coppola)
  ∧¬(easyrider = champo) ∧ ¬(easyrider = odeon) ∧ ¬(apocalypsenow = kubrick) ∧ ¬(apocalypsenow = altman)
  ∧¬(apocalypsenow = hopper) ∧ ¬(apocalypsenow = nicholson) ∧ ¬(apocalypsenow = robbins) ∧ ¬(apocalypsenow = coppola)
  ∧¬(apocalypsenow = champo) ∧ ¬(apocalypsenow = odeon) ∧ ¬(kubrick = altman) ∧ ¬(kubrick = hopper)
  ∧¬(kubrick = nicholson) ∧ ¬(kubrick = robbins) ∧ ¬(kubrick = coppola) ∧ ¬(kubrick = champo)
  ∧¬(kubrick = odeon) ∧ ¬(altman = hopper) ∧ ¬(altman = nicholson) ∧ ¬(altman = robbins)
  ∧¬(altman = coppola) ∧ ¬(altman = champo) ∧ ¬(altman = odeon) ∧ ¬(hopper = nicholson)
  ∧¬(hopper = robbins) ∧ ¬(hopper = coppola) ∧ ¬(hopper = champo) ∧ ¬(hopper = odeon)
  ∧¬(nicholson = robbins) ∧ ¬(nicholson = coppola) ∧ ¬(nicholson = champo) ∧ ¬(nicholson = odeon)
  ∧¬(robbins = coppola) ∧ ¬(robbins = champo) ∧ ¬(robbins = odeon) ∧ ¬(coppola = champo)
  ∧¬(coppola = odeon) ∧ ¬(champo = odeon)
      Cela garantit que DI ′ contienne DI .
                                     INTRODUCTION À LA LOGIQUE                                      111

                                                   ′               ′
  Il reste à imposer que les relations FilmI et SeanceI soient les bonnes. Pour la relation Film,
  on écrit pour cela
                                          (
                 ∀x∀y∀z.Film(x, y, z) ⇔        (x = shining ∧ y = kubrick ∧ z = nicholson)
                                              ∨(x = player ∧ y = altman ∧ z = robbins)
                                              ∨(x = easyrider ∧ y = hopper ∧ z = nicholson)
                                              ∨(x = easyrider ∧ y = hopper ∧ z = hopper)
                                                                                                )
                                              ∨(x = apocalypsenow ∧ y = coppola ∧ z = hopper)
  Pour la relation Seance, on écrit de manière similaire
                                                       (
                          ∀x∀y.Seance(x, y, z) ⇔            (x = champo ∧ y = shining)
                                                           ∨(x = champo ∧ y = easyrider)
                                                           ∨(x = champo ∧ y = player)
                                                                                          )
                                                           ∨(x = odeon ∧ y = easyrider)

15.1.4. Cohérence, complétude et décidabilité. On dit qu’une théorie T est cohérente si elle ne            La définition qui nous intéresse ici le
                                                                                                          plus est celle de décidabilité, qui est un
contient pas à la fois une formule φ et sa négation ¬φ. Une théorie incohérente ne peut pas avoir         problème algorithmique.
de modèle : pour toute interprétation I, I 6Z= T (sans quoi on aurait I =
                                                                        Z φ et I Z= ¬φ, ce qui est        Mais ces trois définitions sont les clefs
absurde). Mais une théorie incohérente T contient alors toutes les formules closes puisqu’elle est        pour comprendre le « programme de
                                                                                                          HilbeRt » visant à assurer les
fermée par conséquence logique : pour toute formule close ψ, on aura en effet T Z= ψ puisque              fondements des mathématiques
pour toute interprétation I, I Z= T (qui est faux) impliquera bien I Z= ψ.                                elles-mêmes, les réponses négatives
                                                                                                          apportées à ce programme par les deux
Propriété 15.9. Une théorie est cohérente si et seulement si elle a au moins un modèle, si et seule-      théorèmes d’incomplétude de GÖdel, et
ment si elle ne contient pas toutes les formules closes.                                                  enfin la naissance de la notion de
                                                                                                          calculabilité avec la réponse négative à
                                                                                                          l’Entscheidungsproblem apportée par
   Par suite, si K 6= ∅ est une classe d’interprétations, alors Th(K) est forcément cohérente ; en        ChuRch via le λ-calcul et par TuRing
revanche, si A est une axiomatisation, alors Th(A) est cohérente si et seulement si A a un modèle.        via la notion de machine de TuRing.
                                                                                                          Voir la section 15.3 pour plus de détails.
    On dit qu’une théorie T est complète si, pour toute formule close φ, on a φ ∈ T ou ¬φ ∈
T . Observons que si K est une classe d’interprétations, alors Th(K) est forcément complète :
pour toute formule close φ, soit K Z= φ, soit K 6Z= φ. En revanche, pour une axiomatisation A
donnée, Th(A) n’est pas forcément complète. Par exemple, considérons l’axiomatisation Aeq de
l’exemple 15.2 et la formule φ = ∀x∀y.x = y qui exprime le fait que DI contient exactement une
classe d’équivalence pour =I : |DI /=I | = 1. Alors Aeq 6Z= φ puisqu’il existe des modèles avec
strictement plus d’une classe d’équivalence, et Aeq 6Z= ¬φ puisqu’il en existe avec exactement
une classe d’équivalence.
   On dit qu’une théorie T est décidable s’il existe un algorithme qui prend en entrée une for-            En théorie des modèles, on dit qu’une
mule φ et répond si φ ∈ T , c’est-à-dire un algorithme qui résout le problème de décision suivant,        théorie T décide une formule φ si
aussi connu comme le « Entscheidungsproblem ».                                                            φ ∈ T ou ¬φ ∈ T , ce qui n’a pas le
                                                                                                          même sens ! Une théorie complète décide
Problème (DÉCISION DE T ).                                                                                donc toutes les formules closes.
  instance : une formule close φ
  question : est-ce que φ ∈ T ?
Si T = Th(A) est une théorie axiomatique définissable, c’est-à-dire si A est fini, alors φ ∈ T
siVet seulement
               si A Z= φ, ce qui d’après le lemme 4.2 de déduction est le cas si et seulement si
     ψ∈A ψ   ⇒  φ est valide. La DÉCISION DE T peut ainsi se « réduire » au problème suivant
dans le cas d’une théorie définissable :
Problème (VALIDITÉ).
    instance : une formule φ
    question : φ est-elle valide ?
En particulier, si T = Th(∅) est la théorie de l’ensemble vide d’axiomes, la DÉCISION DE T
est exactement le problème de validité d’une formule du premier ordre, puisqu’à partir d’une
                                         112                                  INTRODUCTION À LA LOGIQUE


                                         formule φ quelconque il suffit de la clore par des quantifications universelles pour obtenir une
                                         formule équi-valide.
                                             Dans le cas de la théorie Th(I) d’une interprétation I fixée, la décidabilité de Th(I) revient à
                                         l’existence d’un algorithme qui prend une formule close φ en entrée et répond si I Z= φ, c’est-à-
                                         dire qu’une telle théorie est décidable si et seulement s’il existe un algorithme pour le problème
                                         suivant.
                                         Problème (ÉVALUATION DANS I).
                                             instance : une formule close φ
                                             question : est-ce que I Z= φ ?
                                         Si le problème d’ÉVALUATION DANS I était aisé à résoudre dans le cas de la logique proposi-
                                         tionnelle (c.f. section 3), ce n’est malheureusement plus le cas dans le cas de la logique du premier
                                         ordre, et il existe des théories indécidables. Nous allons commencer par voir dans la section 15.2
                                         une technique algorithmique qui permet de décider certaines théories. Mais voici une dernière
                                         remarque, qui fait appel à des notions que nous n’avons pas couvertes dans ces notes, et ne sera
                                         pas démontrée.
 (David, NouR et Raffalli, 2003,        Propriété 15.10. Si une théorie T est récursivement axiomatisable et complète, alors elle est déci-
thm. 3.6.5)                              dable.
 (HaRRisson, 2009, sec. 5.6), (David,   15.2. Élimination des quantificateurs et décidabilité. Rappelons qu’une formule ψ est sans
NouR et Raffalli, 2003, sec. 3.7),
(Chang et Lee, 1973, sec. 1.5)
                                         quantificateurs si elle respecte la syntaxe abstraite
                                                        ψ ::= ℓ | ψ ∨ ψ | ψ ∧ ψ | ⊥ | >                       (formules sans quantificateur)
                                         où ℓ est un littéral.
                                             Une théorie T permet l’élimination des quantificateurs si pour toute formule φ, il existe une
                                         formule ψ sans quantificateur telle que φ et ψ sont équivalentes modulo T , c’est-à-dire telle que
                                         T Z= φ ⇔ ψ. Cette élimination est effective s’il existe un algorithme d’élimination des quanti-
                                         ficateurs pour T , c’est-à-dire un algorithme qui prend une formule φ en entrée et retourne une
                                         telle formule ψ. Si la formule φ est close, alors ψ ne contiendra aucune variable, et il est alors
                                         (généralement) assez aisé de déterminer si T Z= ψ.
                                             Appelons une formule primitive existentielle si elle est de la forme ε = ∃x.ℓ1 ∧ · · · ∧ ℓn où
                                         ℓ1 , . . . , ℓn sont des littéraux tels que x ∈ fv(ℓi ) pour tout 1 ≤ i ≤ n. Supposons que pour
                                         toute formule primitive existentielle ε, on dispose d’un algorithme qui retourne une formule sans
                                         quantificateur qeT (ε) équivalente modulo T . Alors on a un algorithme général d’élimination des
                                         quantificateurs pour la théorie T :
                                         Lemme 15.11. Si une formule sans quantificateur qeT (ε) équivalente modulo T à ε peut être
                                         calculée pour toute formule primitive existentielle ε, alors une formule sans quantificateur qeT (φ)
                                         équivalente modulo T à φ peut être calculée pour toute formule φ.
                                         Démonstration. On définit qeT (φ) par induction structurelle sur φ.
                                           — Pour une formule atomique α, elle est déjà sans quantificateurs et il n’y a rien à faire : on
                                             pose qeT (α) def
                                                           = α.
                                           — Pour le cas d’une formule ¬φ, on pose qeT (¬φ) def   = ¬qeT (φ) qui est bien équivalente
                                             modulo T à ¬φ.
                                           — Pour le cas d’une formule φ ∨ ψ, on pose qeT (φ ∨ ψ) def  = qeT (φ) ∨ qeT (ψ) qui est bien
                                             équivalente modulo T à φ ∨ ψ.
                                           — Pour le cas d’une formule ∃x.φ, on construit une formule sans quantificateur qeT (φ) équi-
                                             valente modulo T par hypothèse d’induction. On a alors
                                                                            T Z= (∃x.φ) ⇔ (∃x.qeT (φ))
                                               et on procède comme suit.
                                     INTRODUCTION À LA LOGIQUE                                     113


     (1) On met qeT (φ)
                     W sous forme
                              V normale disjonctive : qeT (φ) est équivalente (en particulier
         modulo T ) à 1≤j≤m 1≤i≤n ℓi,j pour des littéraux ℓi,j , et donc
                                             _       ^
                          T Z= (∃x.φ) ⇔ (∃x.              ℓi,j ) .
                                                     1≤j≤m 1≤i≤n

     (2) Comme on a l’équivalence logique (∃x.ψ ∨ ψ ′ ) ⇔ (∃x.ψ) ∨ (∃x.ψ ′ ) pour toutes for-
         mules ψ, ψ ′ , on en déduit que
                                                               
                                          _            ^
                            T Z= (∃x.φ) ⇔     ∃x.         ℓi,j  ,
                                             1≤j≤m         1≤i≤n

         et il suffit V
                      donc de construire une formule sans quantificateurs pour chacune des for-
         mules ∃x. 1≤i≤n ℓi,j .
     (3) Enfin, si ψ, ψ ′ sont des formules telles que x 6∈ fv(ψ), on a l’équivalence logique (∃x.ψ∧
                                                                      V
         ψ ′ ) ⇔ (ψ ∧ ∃x.ψ ′ ). Dès lors, pour chaque formule ∃x. 1≤i≤n ℓi,j , soient Ij def  = {1 ≤
                                       def
         i ≤ n | x ∈ fv(ℓi,j )} et I¯j = {1 ≤ i ≤ n | x 6∈ fv(ℓi,j )} les indices des littéraux où x
         est une variable libre ou non. On a donc
                                                                              
                                          _        ^                 ^
                      T Z= (∃x.φ) ⇔            (      ℓi,j ) ∧ (∃x.     ℓi,j ) .
                                      1≤j≤m      i∈I¯j             i∈Ij
                                      V
     (4) Chacune des formules ∃x. i∈Ij ℓi,j est primitive existentielle, et d’après l’énoncé du
                                                                         V
         lemme on peut calculer une formule sans quantificateur qeT (∃x. i∈Ij ℓi,j ) équivalente
         modulo T . On pose donc
                                                                       
                                  _       ^                     ^
                             def
                     qeT (φ) =         (     ℓi,j ) ∧ qeT (∃x.   ℓi,j )
                                  1≤j≤m      i∈I¯j                 i∈Ij

         qui est bien équivalente modulo T à ∃x.φ.                                                 □
15.2.1. Implémentation en OCaml de l’élimination des quantificateurs. La démonstration ci-dessus
du lemme 15.11 explique comment construire une formule sans quantificateurs qeT (φ) logique-
ment équivalente à φ modulo une théorie T , pour peu que l’on sache construire une formule
sans quantificateurs qeT (ε) qui soit logiquement équivalente à une formule primitive existen-
tielle ε = ∃x.ℓ1 ∧ · · · ∧ ℓn où x ∈ fv(ℓi ) pour tout 1 ≤ i ≤ n, aussi modulo la théorie T .
L’emploi d’une forme normale disjonctive à l’étape (1) est crucial dans cette démonstration, mais
travailler avec des formes normales disjonctives n’est pas très adapté pour les applications que
nous verrons dans la section 16.1 sur les solveurs SMT.
    L’implémentation que nous allons voir travaille de manière duale : on suppose que l’on sait
construire une formule sans quantificateurs qeT (υ) qui soit logiquement équivalente à une for-
mule primitive universelle υ = ∀x.ℓ1 ∨ · · · ∨ ℓn où x ∈ fv(ℓi ) pour tout 1 ≤ i ≤ n. Une telle
formule est équivalente à la négation de la formule primitive existentielle ∃x.ℓ1 ∧ · · · ∧ ℓn . Toute
la démonstration du lemme 15.11 peut être refaite dans ce cadre, par dualité. Cela va permettre
d’utiliser des formules sous forme normale conjonctive, comme déjà fait dans la section 14.4.1.
    Pour rappel, on a défini des types litteral et clause comme suit
 firstorder.ml
 type litteral = Pos of string * term list | Neg of string * term list
 type clause   = litteral list

ainsi que des fonctions auxiliaires cnf_and_cnf, cnf_or_cnf et not_cnf pour calculer la
conjonction, la disjonction et la négation d’une formule sous forme normale conjonctive repré-
sentée comme un clause list.
                                         114                                 INTRODUCTION À LA LOGIQUE


                                           La fonction qe ci-dessous va prendre en argument une fonction qeprun de type string ->
                                         clause -> clause list ainsi qu’une formule φ. La fonction qeprun implémente le calcul
                                         de qeT (υ) où υ = ∀x.ℓ1 ∨ · · · ∨ ℓn est une formule primitive universelle, représentée par son
                                         nom de variable x et sa liste de littéraux.
                                           firstorder.ml
                                           let rec qe: (string -> clause -> clause list) -> fo -> clause list =
                                             fun qeprun phi -> match phi with
                                             | Atom (r,tl)     -> [[Pos(r,tl)]]
                                             | Non(phi)        -> not_cnf(qe qeprun phi)
                                             | Et(phi,psi)     -> cnf_and_cnf (qe qeprun phi) (qe qeprun psi)
                                             | Ou(phi,psi)     -> cnf_or_cnf (qe qeprun phi) (qe qeprun psi)
                                             | Ex (x,phi)      -> not_cnf(qe qeprun (Pt(x,Non(phi))))
                                             | Pt(x,phi)       ->
                                                (* cas d'une formule ∀x.φ *)
                                                begin
                                                   (* étape (1) : mise sous forme normale conjonctive de qeT (φ)
                                                                                                     ∧       ∨
                                                      c'est le cas par construction : qeT (φ) = ∀x. 1≤i≤n 1≤j≤m ℓi,j *)
                                                   let qephi: clause list
                                                                        ( =∧qe qeprun     phi in
                                                                                               )   (∧                        )
                                                                                     ∨                          ∨
                                                   (* étape (2) : on a ∀x. 1≤i≤n 1≤j≤m ℓi,j ⇔         1≤i≤n ∀x.   1≤j≤m ℓi,j
                                                                                             ∨
                                                      et on va traiter chaque formule ∀x. 1≤j≤m ℓi,j séparément *)
                                                   concat_map (fun cl ->
                                                       (* étape (3) : on distingue les littéraux ℓi,j pour 1 ≤ j ≤ m
                                                          tels que x ∈ fv(ℓi,j ), qu'on met dans `xfv' ;
                                                          les autres vont dans `xnfv' *)
                                                       let (xfv,xnfv) =
                                                         List.partition (function
                                                               Pos(r, tl) ->
                                                                List.mem x
                                                                  (List.fold_left (fun vs t' -> aux_tv t' vs) [] tl)
                                                             | Neg(r, tl) ->
                                                                List.mem x
                                                                  (List.fold_left (fun vs t' -> aux_tv t' vs) [] tl))
                                                           cl in
                                                       (* étape (4) : on appelle qeprun sur chaque disjonction
                                                          des littéraux qui ont x comme variable libre *)
                                                       let xfv': clause list = qeprun x xfv in
                                                       (* finalement, on distribue les littéraux dans lesquels
                                                          x n'apparaît pas *)
                                                       List.rev_map (fun cl -> List.rev_append cl xnfv) xfv') qephi
                                                end
 (HaRRisson, 2009, sec. 5.6), (David,   15.2.2. Théorie des ordres linéaires denses non bornés. Reprenons la signature avec F = ∅ et
NouR et Raffalli, 2003, sec. 3.7.2),
(Chang et Lee, 1973, sec. 1.5)           P = {<(2) , =(2) } et l’axiomatisation Aols des ordres linéaires stricts des exemples 15.2, 15.3,
                                         15.6 et 15.7. Nous définissons l’axiomatisation Aoldns des ordres linéaires denses non bornés en
                                         ajoutant à Aols les deux formules suivantes :
                                                                      ∀x∀y∃z.(x < y) ⇒ (x < z ∧ z < y)                           (densité)
                                                                      ∀x∃y∃z.z < x ∧ x < y                                    (non borné)
                                         Observons que l’interprétation I de domaine Q où < est l’ordre strict sur les rationnels et =I
                                                                                               I

                                         l’égalité sur Q est un modèle de Aols , qui est donc une théorie cohérente.
                                         Lemme 15.12. La théorie Th(Aoldns ) permet effectivement l’élimination des quantificateurs.
                                         Démonstration. Avant de commencer la démonstration, on peut remarquer que
                                           (0) un littéral négatif sur (F, P) est
                                     INTRODUCTION À LA LOGIQUE                                    115


      — soit de la forme ¬(x = y) et alors il est équivalent à x < y ∨ y < x modulo Aoldns par
        totalité de <,
      — soit de la forme ¬(x < y) et alors il est équivalent à x = y ∨ y < x modulo Aoldns par
        totalité de <.
  Par le lemme 15.11, il suffit de pouvoir calculer une formule qeTh(Aoldns ) (ε) pour une for-
mule ε = ∃x.ψ primitive existentielle. Par la remarque (0) précédente, tous les littéraux dans ψ
peuvent être supposés positifs.
 (A) S’il existe un littéral x < x dans ψ, on a alors ε équivalente à ⊥ modulo Th(Aoldns ) par
     irréflexivité de < et on pose qeTh(Aoldns ) (ε) def
                                                     = ⊥.
 (B) S’il existe un littéral x = y dans ψ avec x un nom de variable différent de y, on a alors ε
     équivalente à ψ[y/x] modulo Th(Aoldns ) par transitivité de = et par R-congruence et on
     pose qeTh(Aoldns ) (ε) def
                            = ψ[y/x].
 (C) Sinon, un littéral de la forme x = x dans ψ peut être simplement supprimé par réflexivité
     de =,
 (D) et il ne reste plus que des littéraux de la forme y < x ou de la forme x < z : on a une
     formule équivalente modulo Th(Aoldns ) à
                                     ^                ^
                             ∃x.(        yi < x) ∧ (      x < zj )
                                   1≤i≤m              1≤j≤n

      où x 6= yi et x 6= zj pour tous 1 ≤ i ≤ m et 1 ≤ j ≤ n.
     (a) Si m = 0 ou n = 0, puisque < est non borné on peut poser qeTh(Aoldns ) (ε) def
                                                                                    = >.
     (b) Sinon, par transitivité de < et densité on définit notre formule comme qeTh(Aoldns ) (ε) def
                                                                                                  =
         V        V
           1≤i≤m    1≤j≤n yi < zj .                                                               □

  Exemple 15.13. Considérons la formule ∃x∃y∃z.x < y ∧ y < z ∧ ¬(x < z). Cette formule
  contredit la transitivité de <, et nous allons montrer que qeTh(Aoldns ) (φ) = ⊥.
  Par les arguments du lemme 15.11 (étapes 2 et 3), cette formule est équivalente à
                                ∃x∃y.x < y ∧ ∃z.y < z ∧ ¬(x < z)
  où la formule ∃z.y < z ∧ ¬(x < z) est primitive existentielle avec z qui apparaît dans chacun
  des deux littéraux.
  L’étape 0 du lemme 15.12 nous fait par traduire ¬(x < z) en z < x∨x = z modulo Th(Aoldns ) :
  on obtient par distributivité deux nouvelles formules primitives existentielles ∃z.y < z ∧z < x
  et ∃z.y < z ∧ x = z. Ces formules correspondent respectivement aux cas (D.b) et (B) et on a
  qeTh(Aoldns ) (∃z.y < z ∧ z < x) = y < x et qeTh(Aoldns ) (∃z.y < z ∧ x = z) = y < x. Notre
  formule équivalente modulo Th(Aoldns ) est maintenant
                                  ∃x∃y.x < y ∧ (y < x ∨ y < x)
  (que l’on peut évidemment simplifier) et où la formule ∃y.x < y ∧ y < x est primitive existen-
  tielle avec y qui apparaît dans chacun de ses deux littéraux.
  Cette formule correspond au cas (D.b) du lemme 15.12 et on obtient qeTh(Aoldns ) (∃y.x < y ∧ y <
  x) = x < x. Notre formule est maintenant
                                              ∃x.x < x
  qui est primitive existentielle avec x qui apparaît dans son unique littéral.
  En appliquant le cas (A) du lemme 15.12, on obtient qeTh(Aoldns ) (∃x.x < x) = ⊥, qui est bien la
  formule sans quantificateur qu’on espérait trouver.

Théorème 15.14. La théorie Th(Aoldns ) est décidable.
                                            116                                   INTRODUCTION À LA LOGIQUE


 Cette preuve montre que, pour toute       Démonstration. Par le lemme 15.12, pour toute formule close φ, on peut calculer une formule sans
formule close φ, soit
qeTh(Aoldns ) (φ) = ⊤ soit
                                            variables qeTh(Aoldns ) (φ) équivalente modulo Th(Aoldns ). Il suffit donc d’être capable de déterminer
qeTh(Aoldns ) (φ) = ⊥, et donc soit         si Th(Aoldns ) Z= ψ pour ψ sans variables. Comme F est vide, T (F) l’ensemble des termes clos
Th(Aoldns ) Z= φ ⇔ ⊤ soit                   est lui aussi vide : ψ est soit > soit ⊥.                                                            □
Th(Aoldns ) Z= φ ⇔ ⊥, donc soit
Th(Aoldns ) Z= φ soit Th(Aoldns ) Z= ¬φ :
la théorie Th(Aoldns ) est donc aussi           La démonstration du lemme 15.12 peut être traduite en une implémentation en OCaml de
complète.                                   l’élimination des quantificateurs pour la théorie Th(Aoldns ). En suivant la démarche de la sec-
                                            tion 15.2.1, il nous faut implémenter une fonction qeprun_oldns de type string     W -> clause
                                            -> clause list qui prend en entrée une formule primitive universelle ∀x. 1≤j≤m ℓj où
                                            x ∈ fv(ℓj ) pour tout 1 ≤ j ≤ m (représentée par le nom de variable x et la liste [ℓ₁;…;ℓₘ]), et
                                            retourne une formule sans quantificateur sous forme d’une liste de clauses.
                                                L’étape (0) du lemme 15.12, puisque nous travaillons de manière duale, est de n’avoir plus que
                                            des littéraux négatifs.
                                              firstorder.ml
                                              let negate_oldns: clause -> clause list = fun cl ->
                                                let (posl,negl) = List.partition
                                                                       (function Pos(_,_) -> true | _ -> false) cl in
                                                let rec negative: clause -> clause list -> clause list = fun cl acc ->
                                                  match cl with
                                                  | [] -> acc (                   )
                                                  (* (y < z) ⇔ (y 6= z) ∧ (z 6< y) *)
                                                  | Pos("<",[y;z])::cl ->
                                                     cnf_or_cnf
                                                        [[Neg("=",[y;z])];[Neg("<",[z;y])]]
                                                        (negative
                                                               ( cl acc)          )
                                                  (* (y = z) ⇔ (y 6< z) ∧ (z 6< y) *)
                                                  | Pos("=",[y;z])::cl ->
                                                     cnf_or_cnf
                                                        [[Neg("<",[y;z])];[Neg("<",[z;y])]]
                                                        (negative cl acc)
                                                  | l::_ -> failwith ("invalid litteral"^(string_of_litteral l))
                                                in negative posl [negl]

                                               L’analyse des cas (A), (B), (C) et (D) de la démonstration du lemme 15.12 s’applique ensuite à
                                            cette forme duale. On utilise dans le cas (B) de cette implémentation une fonction csubst qui
                                            applique une substitution à une clause.
                                              firstorder.ml
                                              let qe_oldns: string -> clause -> clause list = fun x cl ->
                                                let rec aux: clause -> clause -> clause -> clause list =
                                                  fun less more cl -> match cl with
                                                  (* A : (∀x.x 6< x ∨ ψ) est toujours vraie : on retourne ∅ *)
                                                  | Neg("<",[Var y;Var z])::_ when (x=y && x=z) -> []
                                                  (* B : (∀x.(x 6= y) ∨ ψ) ⇔ (∀x.(x = y) ⇒ ψ) : on retourne {ψ[y/x]} *)
                                                  | Neg("=",[Var y;Var z])::cl' when (x=y) ->
                                                     [csubst [(x,Var z)] (List.rev_append (List.rev_append less more) cl')]
                                                  | Neg("=",[Var y;Var z])::cl' when (x=z) ->
                                                     [csubst [(x,Var y)] (List.rev_append (List.rev_append less more) cl')]
                                                  (* C : (∀x.x 6= x ∨ ψ) ⇔ (∀x.ψ) *)
                                                  | Neg("=",[Var y;Var z])::cl' when (x=y && x=z) -> aux less more cl'
                                                                                                   ∨                 ∨
                                                  (* D : tri des littéraux restants : less = i yi 6< x ; more = j x 6< zj *)
                                                  | Neg("<",[Var y;Var z])::cl' when (x=y) ->
                                                     aux less (Neg("<",[Var y;Var z])::more) cl'
                                                  | Neg("<",[Var y;Var z])::cl' when (x=z) ->
                                      INTRODUCTION À LA LOGIQUE                                      117


         aux (Neg("<",[Var y;Var z])::less) more cl'
      | l::_ -> failwith ("invalid litteral"^(string_of_litteral l))
                      ∨ ∨
      (* on retourne { i j yi 6< zj } *)
      | [] -> [concat_map (function Neg("<",[Var y;Var x]) ->
                            List.rev_map (function Neg("<",[Var x;Var z]) ->
                                               Neg("<",[Var y;Var z])
                                                    | _ -> failwith "invalid litteral")
                                more
                                    | _ -> failwith "invalid litteral")
                less]
    in concat_map (aux [] []) (negate_oldns cl)

15.2.3. Théorie de l’arithmétique linéaire rationnelle. La section 15.2.2 était l’occasion de montrer
la décidabilité d’une théorie axiomatique. Ici, nous allons montrer la décidabilité de la théorie
d’une structure dénotée par (Q, 1, (q·)q∈Q , +, <). Nous considérons pour cela la signature infinie
F = {1(0) , (q·(1) )q∈Q , +(2) } et P = {<(2) , =(2) }. Notre interprétation a pour domaine Q l’en-
semble des nombres rationnels. L’interprétation de la constante 1 est le nombre rationnel 1 ∈ Q,
chacune des fonctions unaires q· pour q ∈ Q est interprétée comme la fonction x 7→ q · x, la
fonction binaire + est interprétée comme l’addition entre rationnels, et les deux relations < et =
sont interprétées respectivement comme l’ordre strict et l’égalité sur Q. À noter que la structure
(Q, 1, (q·)q∈Q , +, <) est en particulier un modèle de Aodlns .
Lemme 15.15 (FouRieR-MotzKin). La théorie Th(Q, 1, (q·)q∈Q , +, <) permet effectivement l’éli-
mination des quantificateurs.
Démonstration. La démonstration procède essentiellement comme celle du lemme 15.12. Par le
lemme 15.11, il suffit de pouvoir calculer une formule qeTh(Q,1,(q·)q∈Q ,+,<) (ε) pour une formule
primitive existentielle ε = ∃x.ψ. Comme dans le lemme 15.12 (étape 0), on peut se ramener au
cas où ψ ne comprend que des littéraux positifs, qui sont donc de la forme t < t′ ou t = t′
avec x ∈ fv(t) ou x ∈ fv(t′ ). Ces inéquations et équations sur Q peuvent de plus être réécrites
de manière équivalente comme des littéraux de la forme x < t, t < x ou x = t ; par exemple,
5x + y < 2x − y + z peut se réécrire comme x < − 23 y + 13 z.
   On applique les mêmes étapes de raisonnement que dans la preuve du lemme 15.12. (A) Si ψ
contient un littéral x < x, alors qeTh(Q,1,(q·)q∈Q ,+,<) (ε) = ⊥ convient. (B) Si ψ contient un littéral
x = t pour t différent de x, alors qeTh(Q,1,(q·)q∈Q ,+,<) (ε) = ψ[t/x] convient. (C) Un littéral x = x
peut simplement être supprimé, et il nous reste donc (D) le cas où ε est de la forme
                                      ^                     ^
                                ∃x.(        ti < x) ∧ (         x < t′j )
                                    1≤i≤m               1≤j≤n

                      fv(t′j )
où x 6∈ fv(ti ) et x 6∈       pour tout i, j. Comme dans le lemme 15.12, si m = 0 ou n = 0 (D.a),
alors comme Q est non borné, qeTh(Q,1,(q·)q∈Q ,+,<) (ε) = > convient. Et comme Q est dense
                                                                             V     V
et < est transitif, dans le cas contraire (D.b), qeTh(Q,1,(q·)q∈Q ,+,<) (ε) = 1≤i≤m 1≤j≤n ti < t′j
convient.                                                                                      □
Théorème 15.16. La théorie Th(Q, 1, (q·)q∈Q , +, <) est décidable.
Démonstration. Par les lemmes 15.11 et 15.15, savoir si Th(Q, 1, (q·)q∈Q , +, <) Z= φ pour φ close
se ramène savoir si Th(Q, 1, (q·)q∈Q , +, <) Z= qeTh(Q,1,(q·)q∈Q ,+,<) (φ), donc pour une formule
sans variable. Cette formule est une combinaison booléenne de littéraux de la forme t < t′ ou
t = t′ où t et t′ n’utilisent que la constante 1, l’addition + et les multiplications par des constantes
de Q, et il suffit donc de calculer les valeurs de t et t′ dans Q.                                    □
  La démonstration du lemme 15.15 peut elle aussi être traduite en une implémentation en
OCaml de l’élimination des quantificateurs pour la théorie Th(Q, 1, (q·)q∈Q , +, <). Toujours en
                                           118                                   INTRODUCTION À LA LOGIQUE


                                           suivant la démarche de la section 15.2.1, il nous faut implémenter une fonction qeprun_lqa de
                                           type stringW -> clause -> clause list qui prend en entrée une formule primitive uni-
                                           verselle ∀x. 1≤j≤m ℓj où x ∈ fv(ℓj ) pour tout 1 ≤ j ≤ m (représentée par le nom de variable
                                           x et la liste [ℓ₁;…;ℓₘ]), et retourne une formule sans quantificateur sous forme d’une liste de
                                           clauses.
 (Goubault-LaRRecq et MacKie, 1997,       15.3. * Indécidabilité. Il existe d’autres théories décidables, dont notablement
thm. 6.20), (BÖRgeR, GRÄdel et                 — l’arithmétique de PResbuRgeR Th(Z, +, <), c.f. (HaRRisson, 2009, sec. 5.7 ; David, NouR et
GuRevich, 1997, sec. 2.1)                         Raffalli, 2003, sec. 3.7.5 ; CaRton, 2008, thm. 3.63) et
                                               — l’arithmétique des réels Th(R, +, ×), c.f. (HaRRisson, 2009, sec. 5.9 ; David, NouR et Raffalli,
                                                  2003, sec. 3.7.4).
                                           Cependant, les théories, et en particulier les théories arithmétiques, deviennent indécidables dès
                                           qu’elles sont assez « riches ». En particulier, toute théorie qui étend l’arithmétique élémentaire de
                                           la section 15.3.1 ci-dessous est indécidable. Comme le concept d’indécidabilité sera plutôt exploré
                                           en M1 dans le cours « calculabilité et complexité », dans cette section nous allons seulement
                                           donner des exemples sans faire de preuves.
                                           15.3.1. Indécidabilité de la théorie de l’arithmétique élémentaire. Posons F = {0(0) , s(1) , +(2) , ×(2) }
 (CoRi et LascaR, 2003, not. 1.5),        et P = {=(2) }. L’arithmétique élémentaire Q est l’axiomatisation finie suivante :
(DupaRc, 2015, ex. 488), (David, NouR et
Raffalli, 2003, déf. 3.4.1)                                     ∀x.                                          ¬(s(x) = 0)
                                                                ∀x.                           ¬(x = 0) ⇒ ∃y.x = s(y)
                                                              ∀x∀y.                        s(x) = s(y) ⇒ x = y
                                                                ∀x.                                          x+0=0
                                                              ∀x∀y.                                          x + s(y) = s(x + y)
                                                                ∀x.                                          x×0=0
                                                              ∀x∀y.                                          x × s(y) = (x × y) + x
                                           à laquelle on ajoute les axiomes de l’égalité Aeq de l’exemple 15.2 ainsi que les axiomes de
                                           congruence suivants :
                                                          ∀x∀x′ ∀y.               (x = x′ ∧ s(x) = y) ⇒ s(x′ ) = y
                                                       ∀x∀x′ ∀y∀z.               (x = x′ ∧ x + y = z) ⇒ x′ + y = z
                                                       ∀x∀x′ ∀y∀z.               (x = x′ ∧ y + x = z) ⇒ y + x′ = z
                                                       ∀x∀x′ ∀y∀z.               (x = x′ ∧ x × y = z) ⇒ x′ × y = z
                                                       ∀x∀x′ ∀y∀z.               (x = x′ ∧ y × x = z) ⇒ y × x′ = z
                                              Le résultat suivant énonce que cette « petite » axiomatisation définit une théorie Th(Q) qui est
                                           indécidable. Les premières démonstrations de résultats de ce type sont célèbres et ont été obte-
                                           nues par ChuRch en 1936 et par TuRing en 1937, pour des théories arithmétiques récursivement
                                           axiomatisables plus riches que Th(Q).
 (CoRi et LascaR, 2003, thm. 4.1),        Théorème 15.17 (MostowsKi, Robinson et TaRsKi). Si T est une théorie cohérente qui contient Q,
(David, NouR et Raffalli, 2003,
thm. 3.6.6)
                                           alors T est indécidable.
                                              Une conséquence de ce théorème est qu’il n’existe pas d’algorithme qui résout le problème de
                                           VALIDITÉ. En effet, si un tel algorithme existait, alors pour n’importe quelle formule close φ′ pour
                                                                                                                                  V
                                           laquelle on souhaiterait savoir si φ′ ∈ Th(Q), on pourrait donner la formule φ def = ( ψ∈Q ψ) ⇒
                                           φ′ en entrée à l’algorithme pour la validité. Comme Z= φ si et seulement si Q Z= φ′ , l’existence
                                           d’un tel algorithme contredirait le théorème de MostowsKi, Robinson et TaRsKi.
 (DupaRc, 2015, thm. 489),                Théorème 15.18 (indécidabilité de la VALIDITÉ). Il n’existe pas d’algorithme qui prend en entrée
(Goubault-LaRRecq et MacKie, 1997,
thm. 6.20), (CoRi et LascaR, 2003,
                                           une formule du premier ordre et retourne si oui ou non elle est valide.
cor. 4.2), (David, NouR et Raffalli,
2003, cor. 3.6.7)
                                       INTRODUCTION À LA LOGIQUE                                             119


15.3.2. Indécidabilité des équations diophantiennes. Une équation diophantienne est une équation
p(x1 , . . . , xn ) = 0 où p est un polynôme à coefficients dans Z pour laquelle on cherche une
solution (x1 , . . . , xn ) dans Zn . Par exemple, 3x21 − 2x1 x2 − x22 x3 − 7 = 0 est une équation
diophantienne qui a une solution (1, 2, −2), tandis que x21 + x22 + 1 = 0 n’a pas de solution. Le
problème de décision correspondant est connu comme « dixième problème de HilbeRt ».
Problème (ÉQUATION DIOPHANTIENNE).
  instance : une équation diophantienne p(x1 , . . . , xn ) = 0
  question : existe-t’il une solution dans Zn ?
Une conséquence d’un résultat de Matiassevitch en 1970 est qu’il n’existe pas d’algorithme
capable de dire s’il existe au moins une solution à une équation diophantienne.
Théorème 15.19 (Matiassevitch). Il n’existe pas d’algorithme qui prend en entrée une équation
diophantienne et retourne si oui ou non il en existe une solution.
   Une conséquence du théorème de Matiassevitch est que les théories arithmétiques sur les
entiers ou sur les naturels sont indécidables. Ici, on prend F = {+(2) , ×(2) } et P = {=(2) } et
on dénote par (Z, +, ×) l’interprétation sur les entiers de cette signature et par (N, +, ×) celle
sur les naturels.
Corollaire 15.20. Les théories Th(Z, +, ×) et Th(N, +, ×) sont indécidables.                                        Le corollaire 15.20 est aussi une
                                                                                                                   conséquence du théorème de
                                                                                                                   MostowsKi, Robinson et TaRsKi
Démonstration. Comme vu dans l’exemple 13.6, on peut exprimer par les formules zero(z) def             =           puisque Th(Z, +, ×) et Th(N, +, ×)
z + z = z et un(u) def
                     = ¬zero(u) ∧ u × u = u que les variables z et u soient valuées à 0 et 1                       sont cohérentes (ce sont des théories
                                                                                                                   d’interprétations) et contiennent Q (il
respectivement.                                                                                                    suffit de vérifier que chacun des axiomes
   Étant donnée une équation diophantienne p(x1 , . . . , xn ) = 0, on peut l’écrire de manière                    de Q est vrai dans ces interprétations) ;
équivalente comme p1 (x1 , . . . , xn ) = p2 (x1 , . . . , xn ) où tous les coefficients de p1 et p2 sont          voir (David, NouR et Raffalli, 2003,
                                                                                                                   cor. 3.6.8).
dans N. Par exemple, 3x21 − 2x1 x2 − x22 x3 − 7 = 0 s’écrit de manière équivalente comme 3x21 =                    L’intérêt de passer par le théorème de
2x1 x2 + x22 x3 + 7.                                                                                               Matiassevitch est que les formules φ
   On peut alors construire une formule universelle close                                                          pour lesquelles on ne sait pas répondre si
                                                                                                                   φ ∈ Th(Z, +, ×) ni si
  φ def
    = ∀z∀u.(zero(z) ∧ un(u)) ⇒ ∀x1 . . . ∀xn .¬(t1 (x1 , . . . , xn , z, u) = t2 (x1 , . . . , xn , z, u))         φ ∈ Th(N, +, ×) sont particulièrement
                                                                                                                   simples.
où t1 et t2 sont des termes qui représentent les polynômes p1 et p2 . Par exemple, 3x21 est repré-
senté par x1 × x1 + x1 × x1 + x1 × x1 , et 2x1 x2 + x22 x3 + 7 est représenté par x1 × x2 + x1 ×
x2 + x2 × x2 × x3 + u + u + u + u + u + u + u. La formule φ est telle que φ ∈ Th(Z, +, ×)
si et seulement si l’équation diophantienne p(x1 , . . . , xn ) = 0 n’a pas de solution. Dès lors, si
Th(Z, +, ×) était décidable, cela contredirait le théorème de Matiassevitch.
    Pour la théorie Th(N, +, ×), on fait le même raisonnement en observant que l’équation dio-
phantienne p(x1 , . . . , xn ) = 0 a une solution dans Zn si et seulement si p(y1 −z1 , . . . , yn −zn ) =
0 a une solution dans N2n .                                                                              □

   Une conséquence du corollaire 15.20 est que le problème d’ÉVALUATION DANS I ne peut pas
être résolu algorithmiquement quand I = (Z, +, ×) ou I = (N, +, ×).
Théorème 15.21 (indécidabilité de l’ÉVALUATION). Pour I = (Z, +, ×) ou I = (N, +, ×), il
n’existe pas d’algorithme qui prend en entrée une formule φ et retourne si I Z= φ ou non, et ce même
si φ est universelle.
Corollaire 15.22. Les théories Th(Z, +, ×) et Th(N, +, ×) ne sont pas récursivement axiomati-
sables.
Démonstration. Si Th(Z, +, ×) (ou Th(N, +, ×)) était récursivement axiomatisable, alors comme
elle est complète – car c’est la théorie d’une interprétation – elle serait décidable par la pro-
priété 15.10, contredisant le corollaire 15.20.                                                □
                                         120                                 INTRODUCTION À LA LOGIQUE


 Voir la page Wikipédia pour mieux      15.3.3. Théorèmes d’incomplétude. Difficile de ne pas mentionner pour finir un résultat fameux
comprendre les tenants et aboutissants
de ces théorèmes.
                                         de GÖdel : ses deux théorèmes d’incomplétude. Nous sommes armés pour démontrer le premier
                                         de ces deux théorèmes, dans une version améliorée par RosseR.
 (CoRi et LascaR, 2003, thm. 4.3),      Théorème 15.23 (d’incomplétude de GÖdel–RosseR). Soit T une théorie récursivement axioma-
(Goubault-LaRRecq et MacKie, 1997,       tisable et cohérente contenant Q. Alors T n’est pas complète.
thm. 6.36), (DupaRc, 2015, thm. 487),
(David, NouR et Raffalli, 2003,          Démonstration. Soit T une théorie récursivement axiomatisable et cohérente contenant Q. Par
thm. 3.6.9.1)                            le théorème 15.17 de MostowsKi, Robinson et TaRsKi, T est une théorie indécidable. Or, par la
                                         propriété 15.10, si T était complète, elle serait décidable : T est donc incomplète.       □
                                            Le second de ces deux théorèmes nécessiterait une démonstration un peu technique, où l’on
                                         « arithmétise » l’existence d’une preuve de cohérence de la théorie T comme une formule close
                                         Coh(T ) (dans la signature de l’arithmétique). Accessoirement, la démonstration utilise une théo-
                                         rie axiomatique plus riche que Th(Q) appelée l’arithmétique de Peano, et que l’on notera ici PA.
 (CoRi et LascaR, 2003, thm. 4.5),      Théorème 15.24 (d’incomplétude de GÖdel). Soit T une théorie récursivement axiomatisable et
(Goubault-LaRRecq et MacKie, 1997,       cohérente contenant PA. Alors T ne contient pas Coh(T ).
thm. 6.36), (DupaRc, 2015, thm. 491),
(David, NouR et Raffalli, 2003,              Autrement dit, bien qu’il soit possible d’exprimer par une formule logique Coh(T ) le fait que
thm. 3.6.9.2)                            la théorie T soit cohérente, on ne pourra pas le déduire comme une conséquence « interne » de
                                         la théorie T .
                                     INTRODUCTION À LA LOGIQUE                                     121


                              16. SatisfiabilitÉ modulo thÉoRie

   Résumé. Un solveur modulo théorie pour une théorie T est un programme qui prend en
   entrée une formule φ et répond s’il existe une interprétation I et une valuation ρ telles
   que I Z= ψ pour toute formule ψ ∈ T et I, ρ Z= φ (et retourne I et ρ le cas échéant).
      En pratique, les solveurs modulo théorie savent traiter des formules φ qui sont des
   conjonctions de littéraux, font appel à un solveur SAT pour pouvoir traiter des formules
   sans quantificateurs, et peuvent utiliser l’élimination des quantificateurs pour traiter des
   formules générales.
        Les solveurs modulo théorie utilisent un langage standard appelé SMT-LIB pour décrire
   la signature L = (F, P), la théorie T , et la formule φ.

    Rappelons qu’une formule φ est satisfiable s’il existe une interprétation I et une valuation ρ
telles que I, ρ Z= φ. Comme vu dans la section 15, savoir si une formule prise en isolation est
satisfiable n’est souvent pas suffisant, car on souhaite restreindre les interprétations possibles
des symboles de fonction et de relation utilisées par la formule. On fixe alors une théorie T pour
expliciter les propriétés de nos interprétations ; le problème considéré en pratique est donc le
suivant.
Problème (SATISFIABILITÉ MODULO T ).
    instance : une formule φ
    question : existe-t’il une interprétation I et une valuation ρ telles que I Z= T et I, ρ Z= φ ?
Un témoin de SATISFIABILITÉ MODULO T est alors une interprétation I et une valuation ρ telles
que I Z= T et I, ρ Z= φ.
   Dans beaucoup de cas d’intérêt pratique, la théorie T elle-même est la théorie Th(I) d’une
interprétation I fixée, comme (Q, 1, (q·)q∈Q , +, <) ou (R, +, ×). Dans ce cas le problème de
SATISFIABILITÉ MODULO T revient à trouver s’il existe une valuation ρ telle que I, ρ Z= φ.
16.1. Utilisation de solveurs SMT. Un solveur modulo théorie (SMT) est un programme qui
cherche à résoudre la problème de SATISFIABILITÉ MODULO T et retourne un témoin le cas
échéant. Il existe de nombreux solveurs SMT. Dans ces notes nous utiliserons le solveur Z3 12. La
lecture du tutoriel https://jfmc.github.io/z3-play/ est chaudement recommandée.
16.1.1. Principes de base des solveurs SMT. Dans leur forme la plus basique, les solveurs SMT ont
été développés pour résoudre le problème de SATISFIABILITÉ MODULO T pour des formules φ
sans quantificateur sur une théorie T fixée. Ainsi, on pourrait chercher à déterminer si la formule
                          x + y ≥ 0 ∧ (x 6= z ⇒ y + z = −1) ∧ z > 3t                              (52)
est satisfiable dans la théorie de l’arithmétique linéaire rationnelle Th(Q, 1, (q·)q∈Q , +, <).
   Les solveurs SMT implémentent en réalité des solveurs pour des formules qui sont des conjonc-
tions de littéraux. Dans le cas de la formule (52), on pourrait alors convertir la formule sous forme
normale disjonctive
            (x + y ≥ 0 ∧ ¬(x 6= z) ∧ z > 3t) ∨ (x + y ≥ 0 ∧ y + z = −1 ∧ z > 3t)
puis essayer de résoudre chacune des deux conjonctions de littéraux indépendamment. Cela re-
vient à résoudre les deux systèmes d’équation suivants dans Q, ce qui se fait aisément :
                                                       
                       x+y ≥0
                                                       
                                                            x+y ≥0
                          x−z =0                               y+z−1=0
                        
                        z − 3t > 0                        
                                                                z − 3t > 0

 12. https://github.com/Z3Prover/z3
                                            122                                  INTRODUCTION À LA LOGIQUE


                                            Solveurs SMT hors ligne. Un défaut d’une telle approche est que la mise sous forme normale
                                            disjonctive peut avoir un coût exponentiel. Les solveurs SMT s’appuient à la place sur des sol-
                                            veurs SAT pour traiter la « partie booléenne » de la formule. On procède pour cela comme suit.

                                              (1) Chaque littéral de la formule d’origine est associé à une proposition. Par exemple, pour la
                                                  formule (52), on obtient ainsi une formule P1 ∧ (P2 ⇒ P3 ) ∧ P4 où P1 représente le littéral
                                                  x + y ≥ 0, P2 représente x 6= z, P3 représente y + z = −1 et P4 représente z > 3t.

                                              (2) La formule propositionnelle est convertie en forme normale conjonctive – ce qui donne la
                                                  formule P1 ∧(¬P2 ∨P3 )∧P4 pour notre exemple – et est donnée en entrée à un solveur SAT.
                                                  Si cette formule propositionnelle est insatisfiable, alors la formule de départ l’était aussi.

                                              (3) Sinon, le solveur SAT fournit un modèle de la formule propositionnelle, par exemple l’in-
                                                  terprétation partielle [1/P1 , 0/P2 , 1/P3 , 1/P4 ]. Ce modèle correspond à une conjonction
                                                  de littéraux x + y ≥ 0 ∧ ¬(x 6= z) ∧ y + z = −1 ∧ z > 3t que le solveur SMT tente de
                                                  satisfaire dans la théorie Th(Q, 1, (q·)q∈Q , +, <) ; en l’occurrence, il s’agit simplement de
                                                  résoudre un système d’inéquations linéaires sur les rationnels :

                                                                                      
                                                                                           x+y ≥0
                                                                                      
                                                                                      
                                                                                           x−z =0
                                                                                      
                                                                                       y+z−1=0
                                                                                      
                                                                                      
                                                                                          z − 3t > 0


                                                  Si cette conjonction de littéraux est satisfiable, la formule de départ l’était aussi.

 En pratique, plutôt que de faire la         (4) Sinon, et c’est le cas de notre exemple, on fait la conjonction entre la formule d’origine et
conjonction avec ¬(x + y ≥ 0 ∧ ¬(x ̸=             la négation de notre conjonction de littéraux de l’étape (3) ; pour notre exemple, cela donne
z) ∧ y + z = −1 ∧ z > 3t) en entier,              la formule (x + y ≥ 0 ∧ (x 6= z ⇒ y + z = −1) ∧ z > 3t) ∧ ¬(x + y ≥ 0 ∧ ¬(x 6=
le solveur SMT va trouver un
sous-ensemble des littéraux qui ne peut           z) ∧ y + z = −1 ∧ z > 3t). Le résultat est une nouvelle formule qui est satisfiable si et
pas être satisfait et ajouter la négation         seulement si la formule d’origine l’était, et on recommence à l’étape (1) ci-dessus.
de ce sous-ensemble ; par exemple
¬(x+y ≥ 0∧¬(x ̸= z)∧y+z = −1).                Exemple 16.1. Si on poursuit sur notre exemple, nous avons maintenant (2) une formule pro-
 Les solveurs SAT actuels basés sur          positionnelle en forme normale conjonctive P1 ∧ (¬P2 ∨ P3 ) ∧ P4 ∧ (¬P1 ∨ P2 ∨ ¬P3 ∨ ¬P4 )
des techniques de « conflict-driven           pour laquelle un solveur SAT retourne par exemple [1/P1 , 0/P2 , 0/P3 , 1/P4 ], et (3) la conjonc-
clause learning » sont capables               tion de littéraux x + y ≥ 0 ∧ ¬(x 6= z) ∧ ¬(y + z = −1) ∧ z > 3t est maintenant satisfiable
d’ajouter des nouvelles clauses en cours      dans Th(Q, 1, (q·)q∈Q , +, <), par exemple par la valuation partielle [0/x, 0/y, 0/z, − 61 /t], qui
d’exécution, ce qui rend l’étape (4)
efficace. Les solveurs SMT actuels sont
                                              satisfait donc aussi la formule d’origine (52).
plutôt en ligne pour faire dialoguer
efficacement le solveur SAT et la           16.1.2. Élimination des quantificateurs. Dans le cas où la théorie T permet effectivement l’élimi-
recherche de modèle dans la théorie.        nation des quantificateurs, comme les théories Th(Aoldns ) des ordres linéaires denses non bornés
                                            stricts et Th(Q, 1, (q·)q∈Q , +, <) de l’arithmétique linéaire rationnelle de la section 15.2, mais
                                            aussi les théories Th(Z, +, <) de l’arithmétique de PResbuRgeR et Th(R, +, ×) de l’arithmétique
                                            des réels, on dispose d’un algorithme qui, pour une formule φ donnée, retourne une formule sans
                                            quantificateurs qeT (φ) équivalente modulo T , c’est-à-dire telle que T Z= φ ⇔ qeT (φ).
                                                Cela permet d’appliquer notre solveur SMT à la formule qeT (φ). En effet, en général si T Z=
                                            φ ⇔ ψ alors la formule φ est satisfiable modulo T si et seulement si la formule ψ l’est, et de plus
                                            les mêmes témoins I, ρ peuvent être utilisés pour les deux formules. Cela découle des définitions :
                                            si T Z= φ ⇔ ψ, c’est-à-dire si pour toute interprétation I telle que I Z= T et pour toute valuation ρ
                                            on a I, ρ Z= φ ⇔ ψ, alors pour toute interprétation I telle que I Z= T et pour toute valuation ρ,
                                            I, ρ Z= φ si et seulement si I, ρ Z= ψ.
                                     INTRODUCTION À LA LOGIQUE                                     123


16.1.3. SMT-LIB. Un solveur SMT comme Z3 peut être utilisé au travers de son API ; il en existe
pour plusieurs langages de programmation 13. Si de telles APIs rendent les solveurs SMT directe-
ment accessibles depuis un langage de programmation, elles ont le défaut de dépendre à la fois
du solveur et du langage.
    Une approche générique est d’avoir un format commun pour tous les solveurs SMT, comme le
format DIMACS l’était pour les solveurs SAT. Dans le cas des solveurs SMT, ce format commun
s’appelle SMT-LIB 14 et est en fait un langage pour définir des théories logiques et des formules,        (BaRRett, Fontaine et Tinelli, 2017)
et pour écrire des scripts très simples.
Écrire des formules en SMT-LIB. Commençons par un exemple très simple : la formule (52). Voici
le code correspondant en SMT-LIB.
 eq52.smt2
 (declare-const x Real)
 (declare-const y Real)
 (declare-const z Real)
 (declare-const t Real)
 (assert (and (>= (+ x y) 0) (=> (distinct x z) (= (+ y z) -1)) (> z (* 3 t))))
 (check-sat)
 (get-value (x y z t))
 (exit)

Dans ce code, on commence par déclarer les quatre variables libres x, y, z et t. Le langage SMT-LIB
force à donner des types à tous ses objets ; ici nous utilisons le type Real pour toutes nos va-
riables (il n’y a pas de type pour les rationnels, mais cela revient au même). Les formules dont on
souhaite vérifier la satisfiabilité sont écrites en « notation préfixe » et ajoutées par la commande
(assert φ) ; à noter que les opérateurs comme and peuvent prendre plus de deux arguments.
On vérifie la satisfiabilité par (check-sat), puis (get-value . . .) permet d’afficher la va-
luation. Si on appelle Z3 sur ce fichier, il répond correctement que la formule est satisfiable et
fournit une valuation :
 sat
 ((x   0.0)
  (y   0.0)
  (z   0.0)
  (t   (- (/ 1.0 6.0))))


Formules quantifiées en SMT-LIB. Voyons comment écrire les formules de l’exemple 12.6 en SMT-
LIB. La formule (23) ∀x∃y.y < x s’écrit comme suit.
 order.smt2
 ;; équation (23)
 (assert (forall ((x Real)) (exists ((y Real)) (< y x))))
 (check-sat-using (then qe smt))

Il y a deux différences par rapport au code précédent. D’une part, comme la formule est close, il
n’est pas nécessaire de déclarer de variables libres comme des constantes. D’autre part, comme la
formule utilise des quantificateurs, il faut indiquer à Z3 qu’il doit utiliser l’élimination des quan-
tificateurs avant de chercher un modèle : c’est ce que fait la commande (check-sat-using
(then qe smt)).

   La formule (24) ∀x∀y.x < y ⇒ ∃z.x < z ∧ z < y s’écrit comme suit.


 13. https://github.com/Z3Prover/z3#z3-bindings
 14. http://smtlib.cs.uiowa.edu/
124                                  INTRODUCTION À LA LOGIQUE


  order.smt2
  ;; équation (24) sur les réels
  (assert (forall ((x Real) (y Real)) (=> (< x y)
    (exists ((z Real)) (and (< x z) (< z y))))))
  (check-sat-using (then qe smt))

Cette formule est satisfiable dans un ordre dense comme (Q, <) ou (R, <), mais ne l’est pas dans
un ordre discret comme (Z, <) ; Z3 répond unsat pour le code SMT-LIB suivant :
  order.smt2
  ;; équation (24) sur les entiers
  (assert (forall ((x Int) (y Int)) (=> (< x y)
    (exists ((z Int)) (and (< x z) (< z y))))))
  (check-sat-using (then qe smt))


  Inversement, la formule (25) ∀x∃y∀z.x < y ∧ ¬(x < z ∧ z < y) n’est pas satisfiable
dans (R, <) ; Z3 répond unsat pour le code SMT-LIB suivant :
  order.smt2
  ;; équation (25)
  (assert (forall ((x Real)) (exists ((y Real)) (and (< x y)
    (not (exists ((z Real)) (and (< x z) (< z y))))))))
  (check-sat-using (then qe smt))


Déclarer des symboles. Reprenons maintenant la formule du buveur ∃x.B(x) ⇒ ∀y.B(y) de
l’exemple 12.3. Celle-ci est valide si et seulement si sa négation est insatisfiable, ce que nous
allons vérifier avec Z3. La formule utilise un symbole B de relation unaire non interprété, qu’il va
falloir déclarer : on déclare pour cela un nouveau type D par la commande (declare-sort D).
  buveur.smt2
  ; exemple 12.3
  ; on appelle D notre domaine
  (declare-sort D)
  ; le symbole de relation `B' prend un élément du domaine et retourne
  ; une valeur de vérité
  (declare-fun B (D) Bool)
  ; la formule du buveur est valide si et seulement si sa négation
  ; est insatisfiable
  (assert (not (exists ((x D)) (=> (B x) (forall ((y D)) (B y))))))
  (check-sat-using (then qe smt))
  ; (renvoie `unsat')
  (exit)


Définir des symboles. Considérons maintenant la théorie de l’exemple 15.8. L’axiomatisation A
que nous avions définie dans cet exemple permettait de modéliser fidèlement l’interprétation I
donnée dans l’exemple 10.5, et pourrait être écrite en SMT-LIB. Cependant, il est plus aisé pour
modéliser notre base de données d’utiliser un type énumératif pour l’ensemble des éléments du
domaine DI , ce qui crée simultanément les symboles de constantes shining, player, etc. C’est ce
que nous faisons ci-dessous, en différenciant de plus trois types d’éléments dans le domaine DI :
les titres de films, les noms de réalisateurs et d’interprètes, et les noms de cinémas.
  database.smt2
  ;; exemple 12.5
  ;; types énumératifs
  (declare-datatypes () ((Titre shining player easyrider apocalypsenow)
    (Nom kubrick altman hopper nicholson robbins coppola)
                                     INTRODUCTION À LA LOGIQUE                                   125


   (Cinema champo odeon)))
 ;; la relation `Film'
 (define-fun Film ((x Titre) (y Nom) (z Nom)) Bool
   (ite (and (= x shining)   (= y kubrick) (= z nicholson))                    true
   (ite (and (= x player)    (= y altman)   (= z robbins))                     true
   (ite (and (= x easyrider) (= y hopper)   (= z nicholson))                   true
   (ite (and (= x easyrider) (= y hopper)   (= z hopper))                      true
   (ite (and (= x apocalypsenow) (= y coppola) (= z hopper))                   true
     false))))))
 ;; la relation `Seance'
 (define-fun Seance ((x Cinema) (y Titre)) Bool
   (ite (and (= x champo) (= y shining))   true
   (ite (and (= x champo) (= y easyrider)) true
   (ite (and (= x champo) (= y player))    true
   (ite (and (= x odeon) (= y easyrider)) true
     false)))))

Plutôt que de déclarer un symbole de relation non interprété Film et d’ajouter une assertion qui
garantit que Film(x, y, z) n’est vrai que pour les bons x, y et z, on a défini ci-dessus le symbole
de relation via (define-fun Film . . .). La commande (ite cond si sinon) est un « if-then-
else » : si cond s’évalue à vrai, son résultat est celui de si, et sinon c’est le résultat de sinon.


   Nous pouvons maintenant tester les requêtes de l’exemple 12.5. La première requête (12)
cherche un titre de film présent dans la base de données et cette requête est satisfiable.
 database.smt2
 (declare-const x Titre)
 ;; équation (12)
 (assert (exists ((r Nom) (i Nom)) (Film x r i)))
 (check-sat-using (then qe smt))
 (get-value (x))

On demande ici à Z3 une valeur de x qui satisfait la requête par la commande (get-value . . .) ;
le résultat est le suivant.
 sat
 ((x repulsion))

   La requête (17) cherche des paires d’un réalisateur et d’un cinéma qui diffuse un de ses films ;
Z3 trouve que (Altman, Le Champo) satisfait la requête.
 database.smt2
 (declare-const x Nom)
 (declare-const y Cinema)
 ;; équation (17)
 (assert (exists ((t Titre) (i Nom)) (and (Film t x i) (Seance y t))))
 (check-sat-using (then qe smt))
 (get-value (x y))

  La requête (22) cherche des interprètes qui n’ont joué que dans un seul film ; Z3 trouve que
Robbins satisfait cette requête.
 database.smt2
 (declare-const x Nom)
 ;; équation (22)
 (assert (exists ((t Titre) (r Nom)) (and (Film t r x)
   (forall ((t2 Titre) (r2 Nom)) (=> (Film t2 r2 x) (= t t2))))))
126                                        INTRODUCTION À LA LOGIQUE




          FiguRe      29. Les     théories     définies     par    SMT-LIB      2.6 ;   voir   http:
          //smtlib.cs.uiowa.edu/logics.shtml.


  (check-sat-using (then qe smt))
  (get-value (x))

16.1.4. Théories usuelles. La figure 29 est tirée de la documentation de SMT-LIB et recense les
théories standardisées – mais toutes ne sont pas nécessairement implémentées dans tous les
solveurs SMT. Ces théories permettent différentes combinaisons de
    — théories arithmétiques comme par exemple (Z, +, ×) (notée NIA dans la figure 29) ou
       (R, +, ×) (notée NRA) ou leurs restrictions à leurs fragments linéaires (par exemple LIA
       pour l’arithmétique de PResbuRgeR ou LRA pour l’arithmétique linéaire sur les réels),
    — permettant des formules quantifiées ou non (les fragments sans quantificateurs sont pré-
       fixés par QF_ dans la figure 29) , et
    — permettant des symboles non interprétés (les fragments avec symboles non interprétés sont
       préfixés par UF dans la figure 29) ou non.
Par exemple, UFLRA désigne l’arithmétique linéaire sur les réels avec quantificateurs et symboles
non interprétés.
    Pour plusieurs des théories de la figure 29, il n’existe pas d’algorithme qui résout le problème
de SATISFIABILITÉ MODULO T . Cela n’empêche pas d’implémenter une procédure, qui poten-
tiellement répondra (timeout) ou (unknown) ou lieu de (sat) ou (unsat).

16.2. Exemple de modélisation : nombre de McNuggets. Voyons maintenant un exemple
complet de modélisation en logique du premier ordre et son implémentation en SMT-LIB. Le
problème est le suivant : les McNuggets sont vendus en boîtes de six, de neuf, ou de vingt Mc-
Nuggets 15 ; voir la figure 30.
    Si on souhaite acheter un nombre m ∈ N de McNuggets, cela n’est pas forcément possible. Par
exemple, on ne peut pas acheter exactement trois McNuggets ou exactement onze McNuggets. En
fait, on peut acheter exactement m McNuggets si et seulement si m est une combinaison positive
linéaire de six, neuf et vingt :
                     combinaison(m) def
                                    = (∃c1 ∃c2 ∃c3 .m = 6 · c1 + 9 · c2 + 20 · c3 )                    (53)
où c1 , c2 et c3 doivent être pris dans N.
    Cependant, si m est assez grand, de tels coefficients c1 , c2 et c3 existent nécessairement par
le théorème combinatoire de SchuR puisque 6, 9 et 20 sont premiers entre eux. Le nombre de
McNuggets est le plus grand entier m qui ne satisfait pas la formule combinaison(m) définie

  15. Auteur : Fritz Saalfeld, licence [CC BY-SA 2.5], via Wikimedia Commons.
                                   INTRODUCTION À LA LOGIQUE                                 127




                     FiguRe 30. Une boîte de vingt chicken McNuggets15 .


en (53). Dit autrement, on cherche m tel que
                     ¬combinaison(m) ∧ (∀p.p > m ⇒ combinaison(p)) .                        (54)
   Calculer le nombre de McNuggets est bien une instance de SATISFIABILITÉ MODULO T où
l’on peut prendre l’arithmétique de PResbuRgeR comme théorie T sous-jacente. On peut implé-
menter tout cela en SMT-LIB comme ci-dessous.
 mcnuggets.smt2
 ; nombre de McNuggets
 (declare-const m Int)
 (assert (>= m 0))
 ; équation (53) : n est-il une combinaison linéaire de 6, 9 et 20 ?
 (define-fun combinaison ((n Int)) Bool
   (exists ((c1 Int)(c2 Int)(c3 Int))
     (and (>= c1 0) (>= c2 0) (>= c3 0)
       (= n (+ (* 6 c1) (* 9 c2) (* 20 c3))))))
 ; équation (54)
 (assert (and
   (not (combinaison m))
   (forall ((p Int)) (=> (> p m) (combinaison p)))))
 (check-sat)
 (get-value (m))
 (exit)

  Le solveur Z3 arrive à résoudre ce problème sur ma machine de bureau, et répond correctement
que 43 est le nombre de McNuggets.

16.3. Exemple de modélisation : apprentissage d’automates séparateurs. Soient deux en-              Cette section donne un exemple
                                                                                                   d’algorithme d’apprentissage supervisé
sembles finis disjoints I et E de mots sur un alphabet fini Σ. On souhaite apprendre un automate   passif d’un classifieur – l’automate
fini déterministe A qui accepte tous les mots de I et rejette tous les mots de E : I ⊆ L(A) et     obtenu va soit accepter, soit rejeter les
E ∩ L(A) = ∅. Par exemple, sur Σ = {a, b} pour I = {ε, ab} (où ε dénote le mot vide) et            mots. Ce problème d’apprentissage, avec
                                                                                                   exemples positifs (à accepter) et négatifs
E = {aa, b}, l’automate de la figure 31 ci-dessous répond au problème.                             (à rejeter) était déjà étudiée par Gold
Modélisation du problème. Nous allons voir comment utiliser un solveur SMT pour trouver au-        en 1967.
tomatiquement un tel automate. Rappelons pour cela la définition d’un automate fini détermi-
niste complet A sur un alphabet Σ : A = (Q, Σ, δ, F, q0 ) où Q est un ensemble fini d’états,
δ : Q × Σ → Q est la fonction de transition, F ⊆ Q est l’ensemble des états acceptants et q0 ∈ Q
128                                   INTRODUCTION À LA LOGIQUE


                                                               b
                                                   1                    3     a, b
                                          a

                                      0                a
                                              b

                                                   2            a, b


                FiguRe 31. Un automate qui accepte ε et ab mais rejette b et aa.


est l’état initial. La fonction de transition peut être étendue en une fonction δ : Q × Σ∗ → Q
en posant δ(q, ε) def= q et δ(q, wa) = δ(δ(q, w), a) pour tout w ∈ Σ∗ et a ∈ Σ. Le langage de
                                      def

l’automate est L(A) = {w ∈ Σ∗ | δ(q0 , w) ∈ F }. Par exemple, le langage de l’automate de la
                        def

figure 31 est {ε} ∪ {abw | w ∈ Σ∗ }.
   Pour modéliser efficacement le problème, nous allons dans une première étape construire une
structure d’arbre préfixe (aussi appelé « trie ») pour l’ensemble de mots I ∪ E. Pour un ensemble
de mots S sur un alphabet Σ, l’arbre préfixe de S contient un nœud pour chaque mot dans
                                     = {u ∈ Σ∗ | ∃v ∈ Σ∗ .uv ∈ S}
                             Pref(S) def
l’ensemble des préfixes des mots de S. Un nœud u est le parent d’un nœud v s’il existe une
lettre a de l’alphabet Σ telle que v = ua. Par exemple, l’arbre de la figure 32 est l’arbre préfixe
de l’ensemble I ∪ E = {ε, ab, aa, b}.

                                                           ε

                                                   a               b

                                              aa       ab

                    FiguRe 32. L’arbre préfixe pour l’ensemble {ε, ab, aa, b}.

  L’idée de notre modélisation est qu’un automate A = (Q, Σ, δ, F, q0 ) est tel que I ⊆ L(A) et
E ∩ L(A) = ∅ si et seulement si il existe une fonction f : Pref(I ∪ E) → Q telle que les trois
contraintes ci-dessous soient vérifiées :
                                              f (ε) = q0                                          (55)
                                          ^
                                              δ(f (w), a) = f (wa)                                (56)
                                    w∈Σ∗ ,a∈Σ
                                   wa∈Pref(I∪E)
                                 ^                            ^                    
                                      f (w) ∈ F ∧                      f (w) 6∈ F                 (57)
                                w∈I                            w∈E


Proposition 16.2. Un automate A = (Q, Σ, δ, F, q0 ) est tel que I ⊆ L(A) et E ∩ L(A) = ∅ si et
seulement si il existe une fonction f : Pref(I ∪ E) → Q telle que (55), (56) et (57) soient vérifiées.
Démonstration. Si A = (Q, Σ, δ, F, q0 ) est un automate tel que I ⊆ L(A) et E ∩ L(A) = ∅, on
définit f (w) def
              = δ(q0 , w) pour tout mot w ∈ Pref(I ∪ E), ce qui vérifie bien (55), (56) et (57).
   Inversement, si f : Pref(I ∪ E) → Q est une fonction telle que (55) et (56) soient vérifiées,
alors
                               ∀w ∈ Pref(I ∪ E).f (w) = δ(q0 , w) .
                                     INTRODUCTION À LA LOGIQUE                                   129


Cela se vérifie par induction sur le mot w. Pour le cas de base w = ε, par (55), on a bien
f (ε) = q0 = δ(q0 , ε). Puis pour l’étape d’induction w = w′ a avec w′ ∈ Σ∗ et a ∈ Σ, comme né-
cessairement w′ ∈ Pref(I ∪ E), l’hypothèse d’induction s’applique et donc f (w′ ) = δ(q0 , w′ ) ; de
plus par (56), f (w) = f (w′ a) = δ(f (w′ ), a) = δ(δ(q0 , w′ ), a) = δ(q0 , w′ a) = δ(q0 , w) comme
désiré.
   Par suite, pour tout w ∈ I, on a w ∈ Pref(I ∪ E) donc δ(q0 , w) = f (w) et f (w) ∈ F par (57),
donc I ⊆ L(A). Et pour tout w ∈ E, on a w ∈ Pref(I ∪ E) donc δ(q0 , w) = f (w) et f (w) 6∈ F
par (57), donc E ∩ L(A) = ∅.                                                                       □


Implémentation en SMT-LIB. Voici maintenant comment exprimer notre problème en SMT-LIB.
Tout d’abord, nous allons déclarer des types énumératifs pour notre alphabet et pour notre arbre
préfixe.
 automaton.smt2
 ; définition de l'alphabet A et de l'arbre préfixe T
 (declare-datatypes () ((A a b) (T e ea eb eaa eab)))

Les symboles de constantes associés à l’arbre préfixe sont e pour ε, ea pour a, eb pour b, eaa
pour aa et eab pour ab.
   L’automate fini A utilise l’ensemble d’entiers {0, . . . , n − 1} comme ensemble d’états Q, où 0
est l’état initial.
 automaton.smt2
 ; les états de l'automate à trouver sont {0, 1, ..., n-1}
 (define-sort Q () Int)
 (declare-const n Q)
 (assert (> n 0))
 ; fonction de transition de l'automate
 (declare-fun delta (Q A) Q)
 (assert (forall ((q Q) (a A))
   (and (>= (delta q a) 0) (< (delta q a) n))))
 ; ensemble d'états acceptants de l'automate
 (declare-fun final (Q) Bool)


   Il nous reste à exprimer la fonction f : I ∪ E → Q ainsi que les contraintes des équations (55),
(56) et (57).
 automaton.smt2
 ; fonction des éléments de l'arbre préfixe vers les états
 (declare-fun f (T) Q)
 (assert (forall ((x T))
   (and (>= (f x) 0) (< (f x) n))))
 ; contrainte (55) sur l'état initial
 (assert (= 0 (f e)))
 ; contraintes (56) sur les transitions
 (assert (and (= (f ea) (delta (f e) a))
              (= (f eb) (delta (f e) b))
              (= (f eaa) (delta (f ea) a))
              (= (f eab) (delta (f ea) b))))
 ; contraintes (57) sur les états acceptants
 (assert (and (final (f e))
              (final (f eab))
              (not(final (f eb)))
              (not(final (f eaa)))))
 (check-sat-using (then qe smt))
                                              130                                  INTRODUCTION À LA LOGIQUE


                                                (get-model)
                                                (exit)

                                              La commande (get-model) demande au solveur SMT de fournir l’interprétation qu’il a trouvée
                                              (si le problème était satisfiable). Voici ce que retourne Z3.
                                                sat
                                                (model
                                                  (define-fun n () Int
                                                    2)
                                                  (define-fun k!6 ((x!0 Int)) Int
                                                    (ite (= x!0 0) 0
                                                       1))
                                                  (define-fun delta!7 ((x!0 Int) (x!1 A)) Int
                                                    (ite (and (= x!0 1) (= x!1 b)) 0
                                                       1))
                                                  (define-fun delta ((x!0 Int) (x!1 A)) Int
                                                    (delta!7 (k!6 x!0) x!1))
                                                  (define-fun final ((x!0 Int)) Bool
                                                    (ite (= x!0 1) false
                                                       true))
                                                  (define-fun f ((x!0 T)) Int
                                                    (ite (= x!0 e) 0
                                                    (ite (= x!0 eab) 0
                                                       1)))
                                                )

                                              L’interprétation trouvée met n à 2, donc l’automate a deux états 0 et 1. Les deux fonctions k!6
                                              et delta!7 sont des fonctions auxiliaires introduites par le solveur. La fonction de transition
                                              delta prend en entrée un état x!0 et une lettre de l’alphabet x!1 et envoie sur l’état 1 sauf
                                              si x!0 est l’état 1 et x!1 est la lettre b, auquel cas elle envoie sur 0. La fonction final définit
                                              l’état 1 comme rejetant et l’état 0 comme acceptant. Tout cela décrit l’automate de la figure 33.
                                              À noter que cet automate accepte le language ((a + b)a∗ b)∗ , qui n’est pas le même que celui de
 L’automate de la figure 33 est non          l’automate de la figure 31, mais qui sépare aussi I de E.
seulement plus petit, mais souffre aussi
moins de « sur-apprentissage » que
celui de la figure 31 : il généralise mieux                                                   a, b
les mots de l’ensemble d’entraînement
S = I ∪ E.                                                                               0           1      a

                                                                                               b


                                                             FiguRe 33. Un autre automate qui accepte ε et ab mais rejette aa et b.

                                              16.4. Exemple de modélisation : synthèse d’invariant de programme. Une des applica-
                                              tions informatiques des solveurs SMT est la synthèse d’invariants. Pour démontrer qu’un pro-
                                              gramme est correct, une méthode usuelle est d’écrire des annotations du programme, et en par-
                                              ticulier des invariants de boucle : une relation entre les variables du programme qui reste vraie
                                              au cours des exécutions. Il peut cependant être assez difficile de trouver de tels invariants. L’idée
                                              est donc d’automatiser la tâche, en utilisant des solveurs SMT pour synthétiser de tels invariants.
                                                    Prenons par exemple le fragment de code Java ci-dessous.
                                                int i     = 0;
                                                int j     = 1;
                                                while     (i < 10) {
                                                    i     = i + 2;
                                     INTRODUCTION À LA LOGIQUE                                   131


     j = j + 1;
 }
 assert (j < 10);

On souhaite vérifier qu’à la sortie de la boucle while, c’est-à-dire quand i >= 10, l’assertion j
< 10 est vérifiée.
Configurations accessibles. Une manière de procéder est de calculer l’ensemble des configurations
accessibles du programme, c’est-à-dire l’ensemble Reach ⊆ Z2 des valeurs de i et j qui peuvent
apparaître au cours de l’exécution, et vérifier que i ≥ 10 ⇒ j < 10 est vrai pour toutes ces
configurations. C’est bien le cas :
                      Reach = {(0, 1), (2, 2), (4, 3), (6, 4), (8, 5), (10, 6)} ,               (58)
qui est représenté dans la figure 34 ; on a bien Reach ∩ Error = ∅, où
                                Error def
                                      = {(i, j) ∈ Z2 | i, j ≥ 10}                               (59)
dénote l’ensemble des configurations interdites par l’assertion.

                                             j

                                                                          Error




                                                              Reach




                                                                                                  i



         FiguRe 34. L’ensemble d’accessibilité Reach et les configurations d’erreur Error
         du programme.

   L’ensemble des configurations accessibles était très facile à calculer pour notre exemple, mais
en général ça n’est pas faisable – par exemple parce que le programme ne termine pas sous cer-
taines conditions, or c’est justement ces situations que l’on veut éviter en vérifiant le programme     On cherche à faire une analyse
                                                                                                       statique du programme, où l’on en
sans l’exécuter !                                                                                      vérifie le comportement sans l’exécuter.
Invariants inductifs sûrs. À la place, on va chercher une sur-approximation de Reach, c’est-à-dire
un ensemble de configurations Approx ⊇ Reach. On souhaite plus précisément trouver une sur-
approximation sûre, c’est-à-dire telle que Approx ∩ Error = ∅. Puisque Reach ⊆ Approx, cela
garantira bien que Reach ∩ Error = ∅.
   Une manière d’être certain que notre ensemble Approx soit bien une sur-approximation, c’est-
à-dire que Approx ⊇ Reach, est de demander à ce que ce soit un invariant inductif : cela veut dire
d’une part, la configuration initiale est dans Approx, et d’autre part que, si on prend une configu-
ration de Approx et si on applique une étape de calcul, alors on arrive sur une configuration qui
est encore dans Approx. À noter que Reach est un invariant inductif (c’est même le plus petit :
132                                   INTRODUCTION À LA LOGIQUE


celui qui contient le moins de configurations), mais d’autres invariants inductifs existent, comme
par exemple l’ensemble
                Safe def
                     = {(i, j) ∈ Z2 | (i < 10 ∧ 2j ≤ i + 8) ∨ (i ≥ 10 ∧ j < 10)}                    (60)
représenté dans la figure 35 (qui se trouve être le plus grand).

                                              j

                                                                          Error



                                                        Safe




                                                                                                      i




      FiguRe 35. L’invariant inductif Safe et les configurations d’erreur Error du programme.

Modélisation logique. Dans l’exemple de programme ci-dessus, un invariant inductif est une re-
lation entre les variables de la boucle (ici i et j) qui, si elle est vraie à l’entrée de la boucle, sera
encore vraie à la sortie, et de plus est vraie initialement pour i = 0 et j = 1. Afin que cet
invariant inductif soit sûr, il faut aussi qu’il respecte l’assertion finale j < 10 quand i >= 10.
    On va se placer dans une signature ({+(2) , (i(0) )i∈Z }, {<(2) , =(2) , Invar(2) }) où les symboles
arithmétiques, de constantes i ∈ Z, d’ordre et d’égalité seront interprétés sur le domaine DI def   = Z,
et où le symbole de relation binaire Invar va représenter notre invariant.
    L’objectif du solveur SMT va être de fournir une interprétation I = (Z, +, (i)i∈Z , <, =, InvarI )
dans laquelle les interprétations de +, i ∈ Z, < et = sont fixées (ce sont les interprétations habi-
tuelles dans les entiers relatifs), mais l’interprétation InvarI du symbole Invar(2) n’est pas fixée
a priori et devra respecter des contraintes pour qu’elle représente bien un invariant inductif sûr
du programme ; on dit que Invar(2) est un symbole « non interprété ».
    Pour que InvarI représente un invariant inductif sûr du programme, il faut que ce soit bien un
invariant de la boucle : si on entre dans la boucle avec certaines valeurs de i et j en respectant
l’invariant, alors à la sortie de boucle l’invariant est encore respecté :
                        ∀x∀y.Invar(x, y) ∧ x < 10 ⇒ Invar(x + 2, y + 1) .                           (61)
Il faut aussi que la condition initiale i = 0 et j = 1 soit dans l’invariant :
                                             Invar(0, 1) .                                          (62)
Enfin, pour que l’invariant soit sûr, l’assertion finale j < 10 doit elle aussi être vérifiée si on
sort de la boucle, c’est-à-dire si i >= 10 :
                        ∀x∀y.Invar(x, y) ∧ (x > 10 ∨ x = 10) ⇒ y < 10 .                             (63)
                                    INTRODUCTION À LA LOGIQUE                                  133


Implémentation en SMT-LIB. On peut traduire ces équations en SMT-LIB :
 invariant.smt2
 ; synthèse d'invariant de programme
 ; on déclare le symbole non interprété de relation Invar
 (declare-fun Invar (Int Int) Bool)
 ; équation (61) : la relation Invar est un invariant de boucle
 (assert (forall (( x Int ) ( y Int ))
   (=> (and (Invar x y) (< x 10)) (Invar (+ x 2) (+ y 1)))))
 ; équation (62) : la relation Invar est vraie initialement
 (assert (Invar 0 1))
 ; équation (63) : l'assertion finale est vérifiée
 (assert (forall (( x Int ) ( y Int ))
   (=> (and (Invar x y) (>= x 10)) (< y 10))))
 ; appel au solveur
 (check-sat-using (then qe smt))
 (get-model)
 (exit)

   Encore une fois, la commande (get-model) demande au solveur SMT de fournir l’interpré-
tation qu’il a trouvée, si le problème était satisfiable. Voici ce que retourne Z3.
 sat
 (model
   (define-fun k!43 ((x!1 Int)) Int
     (let ((a!1 (ite (>= x!1 8) (ite (>= x!1 9) (ite (>= x!1 10) 10 9) 8) 7)))
     (let ((a!2 (ite (>= x!1 5) (ite (>= x!1 6) (ite (>= x!1 7) a!1 6) 5) 4)))
     (let ((a!3 (ite (>= x!1 2) (ite (>= x!1 3) (ite (>= x!1 4) a!2 3) 2) 1)))
       (ite (>= x!1 (- 1)) (ite (>= x!1 0) (ite (>= x!1 1) a!3 0) (- 1)) (- 2))))))
   (define-fun Invar!44 ((x!1 Int) (x!2 Int)) Bool
     (ite (and (= x!1 0) (= x!2 1)) true
     (ite (and (= x!1 2) (= x!2 2)) true
     (ite (and (= x!1 4) (= x!2 3)) true
     (ite (and (= x!1 6) (= x!2 4)) true
     (ite (and (= x!1 8) (= x!2 5)) true
     (ite (and (= x!1 10) (= x!2 6)) true
       false)))))))
   (define-fun k!42 ((x!1 Int)) Int
     (let ((a!1 (ite (>= x!1 8) (ite (>= x!1 9) (ite (>= x!1 10) 10 9) 8) 7)))
     (let ((a!2 (ite (>= x!1 5) (ite (>= x!1 6) (ite (>= x!1 7) a!1 6) 5) 4)))
     (let ((a!3 (ite (>= x!1 2) (ite (>= x!1 3) (ite (>= x!1 4) a!2 3) 2) 1)))
       (ite (>= x!1 1) a!3 0)))))
   (define-fun Invar ((x!1 Int) (x!2 Int)) Bool
     (Invar!44 (k!43 x!1) (k!42 x!2)))
 )

   L’interprétation InvarI du symbole Invar(2) qui a été trouvée est donnée aux deux dernières
lignes : c’est une fonction qui prend deux variables entières x!1 et x!2 et retourne une valeur de
vérité. Elle appelle pour cela une fonction auxiliaire Invar!44, à laquelle elle passe le résultat
d’un appel d’une fonction auxiliaire k!43 sur la variable x!1 et le résultat d’un appel d’une
fonction auxiliaire k!42 sur la variable x!2.
   La fonction k!43 retourne −2 si x!1 < −1, 10 si x!1 ≥ 10, et x!1 sinon. La fonction k!42
retourne 0 si x!2 < 1, 10 si x!2 ≥ 10, et x!2 sinon. Au final, la relation InvarI trouvée est
            InvarI = {(0, 1), (2, 2), (4, 3), (6, 4), (8, 5)} ∪ {(i, 6) ∈ Z2 | i ≥ 10} .      (64)
Cet invariant est représenté dans la figure 36.
                                       134                                  INTRODUCTION À LA LOGIQUE


                                                                                   j

                                                                                                                 Error




                                                                                                    InvarI




                                                                                                                                        i




                                                FiguRe 36. L’invariant inductif InvarI retourné par Z3 et les configurations
                                                d’erreur Error du programme.


                                       16.5. * Exemple de modélisation : pavage du plan. Pour finir cette section, mentionnons
                                       qu’en général, il n’existe pas d’algorithme qui résout SATISFIABILITÉ MODULO T . En effet,
                                       une formule close φ appartient à la théorie T si et seulement si sa négation ¬φ n’est pas sa-
                                       tisfiable modulo T . Un algorithme pour SATISFIABILITÉ MODULO T permettrait donc de déci-
                                       der la théorie T , or nous avons vu en section 15.3 que certaines théories comme l’arithmétique
                                       élémentaire ou Th(Z, +, ×) étaient indécidables.
                                       Problème de pavage du plan. Dans cette section, nous allons en faire une preuve directe, qui sera
                                       aussi l’occasion de modéliser un problème de plus comme un problème de satisfiabilité modulo
 (BÖRgeR, GRÄdel et GuRevich, 1997,   théorie. Le problème qui nous intéresse est le problème de pavage du plan. L’entrée du problème
sec. 3.1)                              est un catalogue, qui est un ensemble fini C de tuiles carrées avec une couleur par côté comme
                                       celles de la figure 37.




                                                                 t0         t1          t2          t3          t4

                                                              FiguRe 37. Un catalogue Cex = {t0 , t1 , t2 , t3 , t4 }.


                                          Le but pour un catalogue C donné est de déterminer s’il est possible de couvrir le plan N × N
                                       en respectant les couleurs. On peut pour cela réutiliser les tuiles du catalogue, mais celles-ci
                                       ne peuvent pas être tournées. La figure 38 montre deux exemples de pavages possibles avec le
                                       catalogue de la figure 37. Formellement, un catalogue C est associé à deux relations binaires H ⊆
                                       C × C de contraintes horizontales et V ⊆ C × C de contraintes verticales, où (t, t′ ) ∈ H si la
                                       couleur de droite de t est la même que la couleur de gauche de t′ et (t, t′ ) ∈ V si la couleur du
                                       haut de t est la même que la couleur du bas de t′ . Par exemple, pour le catalogue de la figure 37,
                                                             INTRODUCTION À LA LOGIQUE                                                     135


         ..           ..            ..        ..        ..                                ..        ..        ..        ..         ..
          .            .             .         .         .                                 .         .         .         .          .

4                                                                ···             4                                                       ···

3                                                                ···             3                                                       ···

2                                                                ···             2                                                       ···

1                                                                ···             1                                                       ···

0                                                                ···             0                                                       ···

        0            1             2          3         4                                0         1          2         3         4

              FiguRe 38. Deux pavages du plan possibles avec le catalogue Cex de la figure 37.

on a les contraintes suivantes :
              H = {(t0 , t0 ), (t0 , t1 ), (t0 , t2 ), (t0 , t3 ), (t1 , t0 ), (t1 , t1 ), (t1 , t2 ), (t1 , t3 ),
                           (t2 , t0 ), (t2 , t1 ), (t2 , t2 ), (t2 , t3 ), (t3 , t4 ), (t4 , t0 ), (t4 , t1 ), (t4 , t2 ), (t4 , t3 )}
               V = {(t0 , t2 ), (t0 , t3 ), (t1 , t4 ), (t2 , t4 ), (t3 , t2 ), (t3 , t3 ), (t4 , t4 )}
Un pavage du plan par C est alors une fonction p : N × N → C telle que
    (1) si p(i, j) = t et p(i + 1, j) = t′ alors (t, t′ ) ∈ H et
    (2) si p(i, j) = t et p(i, j + 1) = t′ alors (t, t′ ) ∈ V .
    Le problème de décision correspondant est le suivant.
Problème (PAVAGE DU PLAN).
  instance : un catalogue C et deux relations H, V ⊆ C × C
  question : est-ce qu’il existe un pavage du plan par C ?
    Le problème de PAVAGE DU PLAN n’a pas de solution algorithmique.
Théorème 16.3 (BeRgeR–GuRevich et KoRyaKov). Il n’existe pas d’algorithme qui prend en en-
trée un catalogue de tuiles C avec ses deux relations de contraintes horizontales H et de contraintes
verticales V et répond s’il existe un pavage du plan.
Modélisation en SMLT-LIB. Voyons comment modéliser le problème de PAVAGE DU PLAN comme
un problème de satisfiabilité modulo une théorie. Nous commençons par déclarer un type énu-
mératif pour le catalogue C et par définir les relations binaires H et V associées.
 tiling-int.smt2
 ; déclaration du catalogue
 (declare-datatypes () ((C t0 t1 t2 t3 t4)))
 ; les contraintes horizontales
 (define-fun H ((s C)(t C)) Bool
   (ite (and (= s t0) (= t t0)) true
   (ite (and (= s t0) (= t t1)) true
   (ite (and (= s t0) (= t t2)) true
   (ite (and (= s t0) (= t t3)) true
   (ite (and (= s t1) (= t t0)) true
136                                       INTRODUCTION À LA LOGIQUE


    (ite (and (= s t1) (= t t1)) true
    (ite (and (= s t1) (= t t2)) true
    (ite (and (= s t1) (= t t3)) true
    (ite (and (= s t2) (= t t0)) true
    (ite (and (= s t2) (= t t1)) true
    (ite (and (= s t2) (= t t2)) true
    (ite (and (= s t2) (= t t3)) true
    (ite (and (= s t3) (= t t4)) true
    (ite (and (= s t4) (= t t0)) true
    (ite (and (= s t4) (= t t1)) true
    (ite (and (= s t4) (= t t2)) true
    (ite (and (= s t4) (= t t3)) true
    false))))))))))))))))))
  ; les contraintes verticales
  (define-fun V ((s C)(t C)) Bool
    (ite (and (= s t0) (= t t2)) true
    (ite (and (= s t0) (= t t3)) true
    (ite (and (= s t1) (= t t4)) true
    (ite (and (= s t2) (= t t4)) true
    (ite (and (= s t3) (= t t2)) true
    (ite (and (= s t3) (= t t3)) true
    (ite (and (= s t4) (= t t4)) true
    false))))))))

   Il reste alors à définir la fonction de pavage p qui doit respecter les contraintes horizontales
et verticales.
  tiling-int.smt2
  ; la fonction p
  (declare-fun p (Int Int) C)
  (assert
    (forall ((i Int)(j Int))
      (=> (and (>= i 0) (>= j 0))
          (and (H (p i j) (p (+ i 1) j))
               (V (p i j) (p i (+ j 1)))))))
  (check-sat-using (then qe smt))
  (exit)

Sans surprise au vu du théorème de BeRgeR–GuRevich et KoRyaKov et sachant comment fonc-
tionnent les solveurs SMT, Z3 n’arrive pas à résoudre ce problème et répond « unknown ».
Modélisation sans théorie. On peut aussi modéliser un problème de pavage comme un problème
de satisfaction sans faire appel à une théorie sous-jacente. On utilise pour cela une relation binaire
non interprétée Pt pour chaque tuile t ∈ C du catalogue ; l’idée ici étant que (x, y) ∈ Pt si
p(x, y) = t. On écrit alors une formule close

                              = ∀x∃x′ ∀y.φ1 (x, y) ∧ φH (x, x′ , y) ∧ φV (x, x′ , y)
                           φC def                                                                 (65)
qui force les relations Pt à coder une fonction de pavage p en demandant que chaque posi-
tion (x, y) soit associée à une unique tuile par
                                   ^
                     φ1 (x, y) def
                               =     ¬Pt (x, y) ∨ ¬Pt′ (x, y) ,                      (66)
                                  t̸=t′

en vérifiant les contraintes horizontales par
                                     _
                  φH (x, x′ , y) def
                                 =       Pt (x, y) ∧ Pt′ (x′ , y) ,                               (67)
                                  (t,t′ )∈H
                                           INTRODUCTION À LA LOGIQUE                               137


et en vérifiant les contraintes verticales par
                                     _
                  φV (x, x′ , y) def
                                 =        Pt (y, x) ∧ Pt′ (y, x′ ) .                              (68)
                                      (t,t′ )∈V

Proposition 16.4. La formule φC est satisfiable si et seulement si on peut paver le plan avec les
tuiles du catalogue C.
Démonstration. Notons tout d’abord que la skolémisation de φC est la formule
                     φ′C def
                         = ∀x∀y.φ1 (x, y) ∧ φH (x, f (x), y) ∧ φV (x, f (x), y)
où l’on a introduit un nouveau symbole de fonction unaire f . La formule φ′C est équi-satisfiable
avec φ, donc il suffit de montrer que φ′C est satisfiable si et seulement si on pouvait paver le plan
avec les tuiles du catalogue C.
    Si on peut paver le plan par une fonction p : N × N → C, alors il existe une interprétation I
telle que I Z= φ′C . On définit pour cela le domaine DI def     = N où f est interprétée comme la
fonction successeur f : n 7→ n + 1 et chaque Pt pour t ∈ C est interprétée par la relation
                          I

     = {(i, j) | p(i, j) = t}. La formule φ′C est donc satisfiable dans ce cas.
PtI def
    Inversement, si φ′C est satisfiable, alors il existe une interprétation I telle que I Z= φ′C . Par
le théorème 14.15 de HeRbRand, on peut supposer sans perte de généralité que I a pour do-
maine DI def   = T (F) l’ensemble des termes clos sur l’ensemble de symboles de fonctions F =
{a(0) , f (1) } et interprète a comme le terme constitué d’une feuille étiquetée par a et f comme
la fonction f I : u 7→ f (u) qui rajoute une nouvelle racine étiquetée par f au-dessus du terme u.
On peut alors observer que I Z= φ′C implique l’existence d’un pavage du plan p : N × N → C où
p(i, j) = t pour (i, j) ∈ N × N si et seulement si la paire de termes
                                ( f (f (· · · (f (a) · · · )), f (f (· · · (f (a))) )
                                  | {z }                       | {z }
                                       i fois                     j fois

appartient à l’interprétation   PtI   de Pt .                                                      □
   On peut en déduire le corollaire suivant du théorème de BeRgeR–GuRevich et KoRyaKov –
qui pouvait aussi se déduire du théorème 15.18 d’indécidabilité de la VALIDITÉ puisque φ est
valide si et seulement si ¬φ n’est pas satisfiable.
Corollaire 16.5 (indécidabilité de la SATISFIABILITÉ). Il n’existe pas d’algorithme qui prend en
entrée une formule φ et retourne si oui ou non φ est satisfiable.
   Cette autre modélisation peut aussi être écrite en SMT-LIB comme suit.
  tiling.smt2
 ; on appelle notre domaine D
 (declare-sort D)
 ; on déclare une relation binaire non interprétée par tuile du catalogue
 (declare-fun P0 (D D) Bool)
 (declare-fun P1 (D D) Bool)
 (declare-fun P2 (D D) Bool)
 (declare-fun P3 (D D) Bool)
 (declare-fun P4 (D D) Bool)
 ; équation (66) : au plus une tuile par position
 (define-fun phi1 ((x D) (y D)) Bool
   (and (not (and (P0 x y) (P1 x y)))
        (not (and (P0 x y) (P2 x y)))
        (not (and (P0 x y) (P3 x y)))
        (not (and (P0 x y) (P4 x y)))
        (not (and (P1 x y) (P0 x y)))
        (not (and (P1 x y) (P2 x y)))
138                          INTRODUCTION À LA LOGIQUE


         (not (and (P1 x y) (P3 x y)))
         (not (and (P1 x y) (P4 x y)))
         (not (and (P2 x y) (P0 x y)))
         (not (and (P2 x y) (P1 x y)))
         (not (and (P2 x y) (P3 x y)))
         (not (and (P2 x y) (P4 x y)))
         (not (and (P3 x y) (P0 x y)))
         (not (and (P3 x y) (P1 x y)))
         (not (and (P3 x y) (P2 x y)))
         (not (and (P3 x y) (P4 x y)))
         (not (and (P4 x y) (P0 x y)))
         (not (and (P4 x y) (P1 x y)))
         (not (and (P4 x y) (P2 x y)))
         (not (and (P4 x y) (P3 x y)))))
  ; équation (67) : les contraintes horizontales
  (define-fun phiH ((x D) (xp D) (y D)) Bool
    (or (and (P0 x y) (P0 xp y))
        (and (P0 x y) (P1 xp y))
        (and (P0 x y) (P2 xp y))
        (and (P0 x y) (P3 xp y))
        (and (P1 x y) (P0 xp y))
        (and (P1 x y) (P1 xp y))
        (and (P1 x y) (P2 xp y))
        (and (P1 x y) (P3 xp y))
        (and (P2 x y) (P0 xp y))
        (and (P2 x y) (P1 xp y))
        (and (P2 x y) (P2 xp y))
        (and (P2 x y) (P3 xp y))
        (and (P3 x y) (P4 xp y))
        (and (P4 x y) (P0 xp y))
        (and (P4 x y) (P1 xp y))
        (and (P4 x y) (P2 xp y))
        (and (P4 x y) (P3 xp y))))
  ; équation (68) : les contraintes verticales
  (define-fun phiV ((x D) (xp D) (y D)) Bool
    (or (and (P0 y x) (P2 y xp))
        (and (P0 y x) (P3 y xp))
        (and (P1 y x) (P4 y xp))
        (and (P2 y x) (P4 y xp))
        (and (P3 y x) (P2 y xp))
        (and (P3 y x) (P3 y xp))
        (and (P4 y x) (P4 y xp))))
  ; la formule complète (65)
  (assert
    (forall ((x D))
      (exists ((xp D))
        (forall ((y D))
          (and (phi1 x y) (phiH x xp y) (phiV x xp y))))))
  (check-sat-using (then qe smt))
  (exit)
                                       INTRODUCTION À LA LOGIQUE                                       139


                                       17. Calcul des sÉents

    Résumé. Le calcul des séquents est un système de déduction qui manipule des séquents
    7− Γ, où Γ est un multi-ensemble fini de formules sous forme normale négative. Un séquent
   7− Γ pour lequel il existe une dérivation dans le système de preuve est dit prouvable, ce
    qui est noté « 7−LK Γ ».
       Un séquent 7− Γ est valide, si pour toute interprétation I, il existe une formule ϑ ∈
   dom(Γ) du séquent telle que I Z= ϑ. Par le théorème 17.5 de correction, si 7− Γ est prou-
   vable, alors il est valide. Inversement, par le théorème 17.17 de complétude, si 7− Γ est
   valide, alors il est prouvable, et même prouvable par une preuve qui n’utilise pas la règle
   de coupure (cut).
       Le calcul des séquents peut être enrichi par des règles admissibles, telles que si toutes
   les prémisses de la règle sont prouvables, alors sa conclusion l’est aussi ; voir la figure 40.
   Ces résultats sont démontrés de manière « syntaxique », c’est-à-dire par manipulation des
   dérivations ; un résultat majeur de ce type est le théorème 17.19 d’élimination des coupures.
       Comme dans le cas propositionnel, les règles du calcul des séquents (sauf (cut)) sont
   syntaxiquement inversibles (c.f. section 17.2.5). En revanche, au premier ordre, on n’a pas
   la propriété de branches finies (cela vient de la règle existentielle (∃)) : une recherche de
   preuve ne termine pas toujours. Comme vu avec le théorème 15.18, cela est inévitable,                       (DupaRc, 2015, sec. 12.3), (David,
   puisqu’il n’existe en effet pas d’algorithme qui résoud le problème de VALIDITÉ.                           NouR et Raffalli, 2003, ch. 5),
                                                                                                              (Goubault-LaRRecq et MacKie, 1997,
                                                                                                              fig. 6.2) pour le calcul des séquents. Voir
                                                                                                              (ibid., sec. 6.3) pour un système de
    Nous allons étendre le calcul des séquents propositionnel LK0 de la section 8.1 à la logique du           preuve à la HilbeRt, et (David, NouR et
premier ordre. Comme dans la section 8.1, nous allons travailler sur des séquents monolatères                 Raffalli, 2003, sec 1.3) et
                                                                                                              (Goubault-LaRRecq et MacKie, 1997,
7− Γ où Γ est un multi-ensemble fini de formules en forme normale négative, mais maintenant                   fig. 2.2 et 6.1) pour des systèmes de
 de formules du premier ordre plutôt que de formules propositionnelles.                                       déduction naturelle.

                                                                                                               Le calcul de la figure 39 ne contient
                                                      7− Γ, φ 7− ∆, φ                                         ni la règle structurelle d’échange, qui
                                         (ax)                                 (cut)
                          7− Γ, ℓ, ℓ                        7− Γ, ∆                                           est implicite parce que nous travaillons
                                                                                                              avec des multi-ensembles, ni la règle
                      7− Γ, φ 7− Γ, ψ                      7− Γ, φ, ψ                                         structurelle d’affaiblissement, qui est
                                                (∧)                        (∨)                                implicite dans la règle d’axiome (ax)
                         7− Γ, φ ∧ ψ                      7− Γ, φ ∨ ψ                                         (c.f. lemme 17.8), ni la règle structurelle
                                                                                                              de contraction, qui est implicite dans la
                         7− Γ, φ[y/x]                  7− Γ, φ[t/x], ∃x.φ                                     règle de l’existentielle (∃)
                                           (∀)                                 (∃)                            (c.f. lemme 17.12). La règle (ax) est
                          7− Γ, ∀x.φ                       7− Γ, ∃x.φ                                         souvent présentée sous une forme plus
                               où y ̸∈ fv(Γ, ∀x.φ)                 où t ∈ T (F , X)
                                                                                                              générale (c.f. lemme 17.9).


                           FiguRe 39. Calcul des séquents monolatère.
                                                                                      S
La notion de variable libre est étendue aux multi-ensembles de formules : fv(Γ) def
                                                                                =         φ∈dom(Γ)   fv(φ).
                                             def
On note le séquent vide 7− ⊥, où ⊥(φ) = 0 pour toute formule φ. Une règle du calcul des sé-
quents permet de déduire un séquent conclusion d’un nombre fini de séquents prémisses. Chaque
règle excepté la règle de coupure comprend une formule principale dans sa conclusion, indiquée
en orange dans les règles de la figure 39 ; la règle (cut) élimine une formule de coupure indiquée
en violet. Un séquent 7− Γ est prouvable, noté 7−LK Γ, s’il en existe une dérivation dans le système
de la figure 39.

  Exemple 17.1. La formule du buveur de l’exemple 14.1 est prouvable. Une dérivation possible
  du séquent correspondant (avec la formule principale indiquée en orange à chaque étape) est :
140                                   INTRODUCTION À LA LOGIQUE

                                                                                                   (ax)
                    7 ¬B(x), B(y), ¬B(y), ∀y.B(y), ∃x.(¬B(x) ∨ ∀y.B(y))
                     −
                                                                                                    (∨)
                   7− ¬B(x), B(y), ¬B(y) ∨ ∀y.B(y), ∃x.(¬B(x) ∨ ∀y.B(y))
                                                                                                    (∃)
                            7− ¬B(x), B(y), ∃x.(¬B(x) ∨ ∀y.B(y))
                                                                   (∀)
                          7− ¬B(x), ∀y.B(y), ∃x.(¬B(x) ∨ ∀y.B(y))
                                                                    (∨)
                         7− ¬B(x) ∨ ∀y.B(y), ∃x.(¬B(x) ∨ ∀y.B(y))
                                                                    (∃)
                                   7− ∃x.(¬B(x) ∨ ∀y.B(y))

Remarque 17.2. La condition y 6∈ fv(Γ) dans la définition de la règle (∀) est nécessaire pour la
correction du calcul des séquents. Sinon, on pourrait dériver

                                                                              (ax)
                                            7− B(x), ¬B(x)
                                       . . . . . . . . . . . . . . . . . . . . . (∀)
                                        7− ∀x.B(x), ¬B(x)
                                                                                    (∀)
                                     7− ∀x.B(x), ∀x.¬B(x)
                                                                                             (∨)
                                  7 (∀x.B(x)) ∨ (∀x.¬B(x))
                                   −

où l’étape en pointillés est incorrecte. Cette formule n’est cependant pas valide : par exemple
DI def                def
    = {a, b} avec B I = {a} en fournit un contre-modèle puisque d’une part I, [b/x] 6Z= B(x) et
donc I 6Z= ∀x.B(x), et d’autre part I, [a/x] 6Z= ¬B(x) et donc I Z=
                                                                  6 ∀x.¬B(x).

Remarque 17.3. La condition y 6∈ fv(∀x.φ) dans la définition de la règle (∀) est nécessaire pour
la correction du calcul des séquents. Sinon, comme (B(x) ∨ ¬B(y))[y/x] = B(y) ∨ ¬B(y), on
pourrait dériver

                                                                              (ax)
                                              7 B(y), ¬B(y)
                                               −
                                                                                  (∨)
                                            7− B(y) ∨ ¬B(y)
                                       . . . . . . . . . . . . . . . . . . . . . . . (∀)
                                        7− ∀x.B(x) ∨ ¬B(y)
                                                                                       (∀)
                                      7− ∀y∀x.B(x) ∨ ¬B(y)

où l’avant-dernière étape est incorrecte. Cette formule n’est cependant pas valide : par exemple
DI def                def
    = {a, b} avec B I = {a} en fournit un contre-modèle puisque I, [a/y, b/x] 6Z= B(x)∨¬B(y).

  Exemple 17.4. Voici un exemple plus compliqué. On souhaite montrer que la formule (25)
  ∀x∃y∀z.x < y ∧ ¬(x < z ∧ z < y) n’appartient pas à Th(Aoldns ) la théorie des ordres linéaires
  denses non bornés de la section 15.2.2. Comme Th(Aoldns ) est cohérente (elle a (Q, <) comme
  modèle), nous allons montrer pour cela que la formule de densité implique la négation de la
  formule (25). Concrètement, cela signifie que nous allons montrer que la formule
                                                                                        
        ∀x∀y∃z.(x < y) ⇒ (x < z ∧ z < y) ⇒ ¬ ∀x∃y∀z.x < y ∧ ¬(x < z ∧ z < y)
  est prouvable (et donc valide par le théorème 17.5 de correction que nous verrons en sec-
  tion 17.1). La première étape est de mettre cette formule sous forme normale négative ; on
  obtient la formule équivalente :
                                                                                 
          ∃x∃y∀z.x < y ∧ (¬x < z ∨ ¬z < y) ∨ ∃x∀y∃z.¬x < y ∨ (x < z ∧ z < y) .
  Dans la dérivation ci-dessous, on note par souci de lisibilité :
  φ1 (x) def
         = ∃y∀z.x < y ∧ (¬x < z ∨ ¬z < y) ,                          φ′1 (x, y) def
                                                                                = ∀z.x < y ∧ (¬x < z ∨ ¬z < y) ,
  φ2 (x) def
         = ∀y∃z.¬x < y ∨ (x < z ∧ z < y) ,                       φ′2 (x, y, z) def
                                                                               = ¬x < y ∨ (x < z ∧ z < y) ,
                        = ∃x.φ1 (x), ∃y.φ′1 (x, y), ∃z.φ′2 (x, y, z), ∃x.φ2 (x) .
                      Γ def
                                      INTRODUCTION À LA LOGIQUE                                              141



                                                                                               (ax)                                             (ax)
                                            7− Γ, ¬x < z, ¬z < y, ¬x < y, x < z          7− Γ, ¬x < z, ¬z < y, ¬x < y, z < y
                                                                                                                                                (∧)
                                                              7− Γ, ¬x < z, ¬z < y, ¬x < y, x < z ∧ z < y
                                     (ax)                                                                    (∨)
 7 Γ, x < y, ¬x < y, x < z ∧ z < y
  −                                                          7− Γ, ¬x < z ∨ ¬z < y, ¬x < y, x < z ∧ z < y
                                                                                                             (∧)
                          7− Γ, x < y ∧ (¬x < z ∨ ¬z < y), ¬x < y, x < z ∧ z < y
                                                                                     (∨)
                        7− Γ, x < y ∧ (¬x < z ∨ ¬z < y), ¬x < y ∨ (x < z ∧ z < y)
                                                                                                       (∃)
               7− ∃x.φ1 (x), ∃y.φ01 (x, y), x < y ∧ (¬x < z ∨ ¬z < y), ∃z.φ02 (x, y, z), ∃x.φ2 (x)
                                                                                                         (∀)
              7− ∃x.φ1 (x), ∃y.φ01 (x, y), ∀z.x < y ∧ (¬x < z ∨ ¬z < y), ∃z.φ02 (x, y, z), ∃x.φ2 (x)
                                                                                                         (∃)
                              7− ∃x.φ1 (x), ∃y.φ01 (x, y), ∃z.φ02 (x, y, z), ∃x.φ2 (x)
                                                                                           (∀)
                                7− ∃x.φ1 (x), φ1 (x), ∀y∃z.φ02 (x, y, z), ∃x.φ2 (x)
                                                                                         (∃)
                                         7− ∃x.φ1 (x), φ1 (x), ∃x.φ2 (x)
                                                                            (∃)
                                             7− ∃x.φ1 (x), ∃x.φ2 (x)
                                                                           (∨)
                                          7− (∃x.φ1 (x)) ∨ (∃x.φ2 (x))

17.1. Correction. Un séquent 7− Γ satisfait une interprétation I sous une valuation ρ, noté
I, ρ Z= Γ, s’il existe une formule ϑ ∈ dom(Γ) telle que I, ρ Z= ϑ ; la formule ϑ en question est
appelée formule témoin. Un séquent 7− Γ est valide, noté Z= Γ, si I, ρ Z= Γ pour tous I et ρ. La
correction d’un système de preuve consiste à montrer que toute formule prouvable est valide.
Théorème 17.5 (correction). Si 7−LK Γ, alors Z= Γ.
Démonstration. On procède par induction structurelle sur une dérivation de 7− Γ, en montrant
pour chaque règle du calcul des séquents que si les prémisses sont valides, alors la conclusion
l’est aussi. On ne traitera ici que les règles de quantification et de coupure, les autres cas ayant
été traités dans la démonstration du théorème 8.10 de correction du calcul des séquents proposi-
tionnel.
   Pour (∀) : supposons la prémisse 7− Γ, φ[y/x] valide pour y 6∈ fv(Γ, ∀x.φ). Prenons (I, ρ)
     arbitraire et montrons que I, ρ Z= Γ, ∀x.φ.
         Comme la prémisse est valide, pour tout e ∈ DI , I, ρ[e/y] Z= Γ, φ[y/x], donc il existe
     une formule témoin ϑe ∈ dom(Γ) ∪ {φ[y/x]} telle que I, ρ[e/y] Z= ϑe
         S’il existe e ∈ DI tel que ϑe ∈ dom(Γ), alors comme y 6∈ fv(Γ) et donc y 6∈ fv(ϑe ), par
     la propriété 12.1, on a aussi I, ρ Z= ϑe . Donc I, ρ Z= Γ, ∀x.φ.                                               On voit dans cette preuve que les
                                                                                                                   deux conditions nécessaires y ̸∈ fv(Γ) et
         Sinon, ϑe = φ[y/x] pour tout e ∈ DI , c’est-à-dire I, ρ[e/y] Z= φ[y/x] pour tout e ∈ DI .                 y ̸∈ fv(∀x.φ) des remarques 17.2
     Par le lemme 13.5 de substitution, on a ainsi I, (ρ[e/y])[JyKIρ[e/y] /x] Z= φ pour tout e ∈ DI ,              et 17.3 sont aussi suffisantes pour la
                                                                                                                   correction de notre calcul des séquents.
     ce qui n’est jamais que I, ρ[e/y][e/x] Z= φ pour tout e ∈ DI . On a donc I, ρ[e/y] Z= ∀x.φ,
     et comme y 6∈ fv(∀x.φ), on a même I, ρ Z= ∀x.φ par la propriété 12.1. Donc I, ρ Z= Γ, ∀x.φ.
   Pour (∃) : supposons la prémisse valide. Prenons (I, ρ) arbitraire et montrons que I, ρ Z=
     Γ, ∃x.φ.
        Si la formule témoin de I, ρ Z= Γ, φ[t/x], ∃x.φ est dans {∃x.φ} ∪ dom(Γ), alors elle
     peut aussi servir de témoin pour I, ρ Z= Γ, ∃x.φ. Si la formule témoin est φ[t/x], c’est-
     à-dire si I, ρ Z= φ[t/x], alors I, ρ[JtKIρ /x] Z= φ par le lemme 13.5 de substitution, et donc
     I, ρ Z= ∃x.φ, qui peut servir de témoin pour I, ρ Z= Γ, ∃x.φ.
   Pour (cut) : supposons les deux prémisses 7− Γ, φ et 7− ∆, φ valides. Prenons (I, ρ) arbi-
     traires et montrons que I, ρ Z= Γ, ∆.
        Comme 7− Γ, φ et 7− ∆, φ sont valides, il existe une formule témoin ϑ ∈ dom(Γ) ∪ {φ}
     et une formule témoin ϑ′ ∈ dom(∆) ∪ {φ} telles que I, ρ Z= ϑ et I, ρ Z= ϑ′ . Si ϑ ∈ dom(Γ)
     ou si ϑ′ ∈ dom(∆), alors I, ρ Z= Γ, ∆ comme désiré. Sinon, ϑ = φ et ϑ′ = φ, mais alors
     I, ρ Z= φ et I, ρ Z= φ, ce qui est absurde : ce cas ne peut pas se produire.            □
142                                       INTRODUCTION À LA LOGIQUE


17.2. * Règles admissibles. Le calcul des séquents de la figure 39 peut être enrichi par plusieurs
règles admissibles, qui n’affectent pas la prouvabilité, et récapitulées dans la figure 40 ci-dessous.
Les preuves en sont établies syntaxiquement, par manipulation des dérivations, et préfigurent les
techniques employées pour l’élimination des coupures que nous verrons en section 17.4.

         7− Γ                      7− Γ                               7− Γ
                (=α )                         (S)                             (W)                         (ax′ )
        7− ∆                      7− Γσ                             7− Γ, ∆                 7− Γ, φ, φ
            où Γ =α ∆         où σ est une substitution


       7− Γ, φ, φ             7− Γ, φ ∨ ψ                       7− Γ, φ ∧ ψ                 7− Γ, φ ∧ ψ
                    (C)                         (E∨ )                             (E1∧ )                   (E2∧ )
         7− Γ, φ               7− Γ, φ, ψ                         7− Γ, φ                     7− Γ, ψ

                             7− Γ, ∀x.φ                         7− Γ, ∃x.φ
                                         (E∀ )                                 (E∃ )
                            7− Γ, φ[y/x]                    7− Γ, φ[t/x], ∃x.φ
                                où y ̸∈ fv(Γ, ∀x.φ)                      où t ∈ T (F , X)



                    FiguRe 40. Quelques règles admissibles du calcul des séquents.

    On définit la profondeur p(π) d’une dérivation π dans le calcul des séquents comme celle de
l’arbre sous-jacent.
17.2.1. α-congruence syntaxique. Commençons par étendre l’α-congruence aux multi-ensembles :
si φi =α ψi pour tout 1 ≤ i ≤ n, alors φ1 , . . . , φn =α ψ1 , . . . , ψn . Le lemme suivant montre
l’admissibilité de la règle (=α ).
Lemme 17.6 (α-congruence syntaxique). Si 7−LK Γ par une dérivation π, alors pour tout multi-
ensemble ∆ =α Γ, 7−LK ∆ par une dérivation de profondeur p(π) et sans coupure si π était sans
coupure.
Démonstration. On montre que si 7−LK Γ, φ par une dérivation π, alors pour toute formule ψ =α
φ, 7−LK Γ, ψ par une dérivation de profondeur p(π) et sans coupure si π était sans coupure, ce
qui démontrera le lemme par induction sur la taille du séquent.
    On procède pour cela par récurrence sur la profondeur de la dérivation π de 7−LK Γ, φ. On
opère à une distinction de cas selon la dernière règle appliquée dans la dérivation π.
    Si π se termine par une règle (R) autre que (cut) où φ n’est pas principale, alors par inspection
des règles, on est nécessairement dans une situation
                                          π1                             πk
                                           ..                             ..
                                            .                              .
                                       7− Γ1 , φ            ···       7− Γk , φ
                                                                                  (R)
                                                          7− Γ, φ
où 0 ≤ k ≤ 2 (k = 0 correspondant au cas de la règle (ax)). Pour tout 1 ≤ i ≤ k, par hypothèse
de récurrence sur πi , il existe une dérivation πi′ de 7− Γi , ψ de profondeur p(πi ) et sans (cut) si πi
était sans (cut). On a donc la dérivation

                                         π1′                             πk′
                                          ..                              ..
                                           .                               .
                                      7− Γ1 , ψ             ···       7− Γk , ψ
                                                                                  (R)
                                                          7− Γ, ψ
      Si π se termine par une règle (cut), alors sans perte de généralité, on est dans une situation
                                       INTRODUCTION À LA LOGIQUE                                      143

                                           π1             π2
                                            ..             ..
                                             .              .
                                        7− Γ, φ, θ      7− ∆, θ
                                                                   (cut)
                                               7− Γ, ∆, φ
(l’autre situation étant celle où φ apparaissait dans la seconde prémisse). Par hypothèse de ré-
currence sur π1 , il existe une dérivation π1′ de 7− Γ, ψ, θ de profondeur p(π1 ), et on a donc la
dérivation
                                           π1′            π2
                                                           ..
                                            ..
                                             .              .
                                        7− Γ, ψ, θ      7− ∆, θ
                                                                   (cut)
                                               7− Γ, ∆, ψ
   Il reste à traiter les cas où φ était principale dans la dernière règle appliquée par π. On pro-
cède par induction sur la congruence φ =α ψ. Les cas de la réflexivité, de la symétrie, et de la
transitivité de =α sont triviaux.                                                                            Cette preuve serait beaucoup plus
                                                                                                            difficile si (ax) était remplacé par (ax0 ) :
   Cas de la congruence pour ∨ : alors φ = φ1 ∨ φ2 et ψ = ψ1 ∨ ψ2 avec φ1 =α ψ1 et                          avec (ax), ℓ =α ℓ0 si et seulement si
       φ2 =α ψ2 . Comme φ est principale la dernière règle appliquée dans π était (∨), et donc              ℓ = ℓ0 et est donc traité par le cas de la
       7−LK Γ, φ1 , φ2 par une dérivation de profondeur p(π) − 1. Par hypothèse de récurrence,              réflexivité ; avec (ax0 ), chacun des cas
                                                                                                            ci-dessous peut provenir d’une
        7−LK Γ, ψ1 , φ2 par une dérivation de profondeur p(π) − 1, et par une seconde application           application de l’axiome étendu.
         de l’hypothèse de récurrence, 7−LK Γ, ψ1 , ψ2 par une dérivation de profondeur p(π) − 1.
         Par une application de (∨), 7−LK Γ, ψ1 ∨ ψ2 .
   Autres cas de congruence : similaires au cas précédent.
   Cas de l’α-renommage pour ∀ : alors φ = ∀x.φ′ et ψ = ∀z.φ′ [z/x] où z 6∈ fv(∀x.φ′ )
          et [z/x] est applicable à φ′ . Comme φ est principale, la dernière règle appliquée dans π
          était (∀), et donc 7−LK Γ, φ′ [y/x] pour une variable y 6∈ fv(Γ, ∀x.φ′ ) par une dériva-
         tion π ′ de profondeur p(π) − 1. Par l’équation (27), φ′ [y/x] =α φ′ [z/x][y/z] puisque
          z 6∈ fv(φ′ ). Par hypothèse de récurrence sur π ′ , 7−LK Γ, φ′ [z/x][y/z] par une dérivation
          de profondeur p(π ′ ). Comme y 6∈ fv(Γ, φ′ [z/x][y/z]), on peut appliquer (∀) et dériver
         7−LK Γ, ∀z.φ′ [z/x].
   Cas de l’α-renommage pour ∃ : alors φ = ∃x.φ′ et ψ = ∃z.φ′ [z/x] où z 6∈ fv(∃x.φ′ )
          et [z/x] est applicable à φ′ . Comme φ est principale,la dernière règle appliquée dans π
          était (∃), et donc 7−LK Γ, φ′ [t/x] pour un terme t ∈ T (F, X) par une dérivation π ′ de pro-
          fondeur p(π) − 1. Par l’équation (27), φ′ [t/x] =α φ′ [z/x][t/z] puisque z 6∈ fv(φ′ ). Par hy-
          pothèse de récurrence sur π ′ , 7−LK Γ, φ′ [z/x][t/z] par une dérivation de profondeur p(π ′ ).
          Par une application de (∃), 7−LK Γ, ∃z.φ′ [z/x].                                            □
17.2.2. Substitution syntaxique. Une substitution σ est applicable à un multi-ensemble Γ si elle
est applicable à chacune des formules de dom(Γ). Si c’est le cas, on définit l’application d’une
substitution σ à Γ = φ1 , . . . , φn comme une application simultanée de σ à toutes les occurrences
de formules dans Γ : Γσ def
                          = φ1 σ, . . . , φn σ. Comme d’habitude, nous faisons un abus de notation
et nous écrivons « Γσ » pour un multi-ensemble ∆σ tel que ∆ =α Γ et que σ soit applicable
à ∆. Le lemme suivant montre l’applicabilité de la règle (S).
Lemme 17.7 (substitution syntaxique). Si 7−LK Γ par une dérivation π, alors pour toute substitu-
tion σ, 7−LK Γσ par une dérivation de profondeur p(π) et sans coupure si π était sans coupure.
Démonstration. Par le lemme 17.6 d’α-congruence syntaxique, on peut supposer σ applicable à Γ.
On procède par récurrence sur la profondeur de la dérivation π de 7− Γ. Considérons pour cela
la dernière règle employée dans cette dérivation.
   Cas de (ax) : alors Γ = Γ′ , ℓ, ℓ. Par la propriété 14.4, ℓσ = (ℓ)σ et (ax) permet aussi de dériver
     le séquent 7− Γ′ σ, ℓσ, (ℓ)σ en une étape.
                                    144                                      INTRODUCTION À LA LOGIQUE


                                          Cas de (cut) : alors Γ = Γ′ , ∆ et 7−LK Γ′ , φ et 7−LK φ, ∆ pour une formule φ. Par hypo-
                                             thèse de récurrence, on obtient des dérivations de même profondeur de 7− Γ′ σ, φσ et de
                                            7− (φ)σ, ∆σ, et la propriété 14.4 montre que l’on peut appliquer (cut) pour obtenir une
                                             dérivation de profondeur p(π) de 7− Γ′ σ, ∆σ.
                                          Cas de (∨) et (∧) : similairement par hypothèse de récurrence.
                                          Cas de (∀) : alors Γ = Γ′ , ∀x.φ et 7−LK Γ′ , φ[y/x] où y 6∈ fv(Γ′ , ∀x.φ) par une dérivation π ′
                                            de profondeur p(π) − 1.
                                                Par hypothèse de récurrence sur π ′ , on a une dérivation de même profondeur p(π)−1 du
                                            séquent 7− Γ′ [z/y]σ[u/z], φ[y/x][z/y]σ[u/z] où on a choisi z 6∈ fv(Γ′ σ, ∀x.φ) ∪ dom(σ) ∪
                                            rv(σ) et u 6∈ fv(Γ′ σ, ∀z.φ[z/x]σ) tels que les substitutions soient applicables. Comme y 6∈
                                            fv(Γ′ ), Γ′ [z/y] =α Γ′ par l’équation (26), et comme z 6∈ fv(Γ′ σ), de même Γ′ σ[u/z] =α
                                             Γ′ σ. Comme y 6∈ fv(∀x.φ), par l’équation (27), φ[y/x][z/y]σ[u/z] =α φ[z/x]σ[u/z]. Par
                                            le lemme d’α-congruence syntaxique, on a donc une dérivation de profondeur p(π) − 1 de
                                            7− Γ′ σ, φ[z/x]σ[u/z]. Comme u 6∈ fv(Γ′ σ, ∀z.φ[y/x][z/y]σ), on peut appliquer (∀) pour
                                             obtenir une dérivation de profondeur p(π) de 7− Γ′ σ, ∀z.(φ[z/x]σ).
                                                Finalement, comme z 6∈ fv(∀x.φ), par α-renommage (∀x.φ)σ =α (∀z.φ[z/x])σ =
                                             ∀z.(φ[z/x]σ) où σ est applicable puisque z 6∈ dom(σ) ∪ rv(σ). Par le lemme 17.6 d’α-
                                             congruence syntaxique, on a donc une dérivation de profondeur p(π) de 7− Γ′ σ, (∀x.φ)σ.
                                          Cas de (∃) : alors Γ = Γ′ , ∃x.φ et 7−LK Γ′ , φ[t/x] par π ′ de profondeur p(π) − 1.
                                                Par hypothèse de récurrence sur π ′ , on a une dérivation de profondeur p(π) − 1 du sé-
                                             quent 7− Γ′ σ, φ[t/x]σ. Observons que si on choisit z 6∈ fv(∃x.φ) ∪ dom(σ) ∪ rv(σ), alors
                                             φ[z/x]σ[tσ/z] =α φ[t/x]σ. Par le lemme d’α-congruence syntaxique, on a une dériva-
                                            tion de profondeur p(π) − 1 de 7− Γ′ σ, φ[z/x]σ[tσ/z]. On peut alors appliquer (∃) pour
                                            dériver 7− Γ′ σ, ∃z.(φ[z/x]σ). Comme z 6∈ fv(∃x.φ), ∃z.(φ[z/x]σ) =α (∃x.φ)σ et donc
                                            7−LK Γ′ σ, (∃x.φ)σ par une dérivation de profondeur p(π) par une autre application du
                                            lemme d’α-congruence syntaxique.                                                         □

                                    17.2.3. Affaiblissement. Bien que le système de la figure 39 ne comporte pas de manière explicite
                                    la règle d’affaiblissement (notée (W) pour « weakening »), celle-ci est admissible.

 (David, NouR et Raffalli, 2003,   Lemme 17.8 (affaiblissement). Si 7−LK Γ par une dérivation π, alors pour tout multi-ensemble ∆,
lem. 7.3.1), (Goubault-LaRRecq et   7−LK Γ, ∆ par une dérivation de profondeur p(π) et sans coupure si π était sans coupure.
MacKie, 1997, lem. 2.31).
                                    Démonstration. Par récurrence sur la profondeur de la dérivation de 7− Γ, on ajoute systémati-
                                    quement ∆ à tous les séquents. On fait pour cela une distinction de cas selon la dernière règle
                                    employée dans la dérivation π.
                                          Cas de (ax) : alors Γ = Γ′ , ℓ, ℓ et on a aussi une dérivation de 7− Γ′ , ℓ, ℓ, ∆ par (ax).
                                          Cas de (∀) : alors Γ = Γ′ , ∀x.φ et 7−LK Γ′ , φ[y/x] par une dérivation de profondeur p(π) − 1
                                             où y 6∈ fv(Γ′ , ∀x.φ).
                                                Soit z 6∈ fv(Γ′ , ∀x.φ, ∆). Par le lemme 17.7, 7−LK Γ′ [z/y], φ[y/x][z/y] par une dériva-
                                             tion de profondeur p(π) − 1. Comme y 6∈ fv(Γ′ ), par l’équation (26), Γ′ [z/y] =α Γ′ , et
                                             comme y 6∈ fv(∀x.φ), par l’équation (27), φ[y/x][z/y] =α φ[z/x]. Par le lemme 17.6 d’α-
                                             congruence syntaxique on peut donc dériver 7− Γ′ , φ[z/x]. Par hypothèse de récurrence,
                                            7−LK Γ′ , φ[z/x], ∆ par une dérivation de profondeur p(π)−1, et comme z 6∈ fv(Γ, ∀x.φ, ∆),
                                             une application de (∀) permet de dériver 7− Γ′ , ∀x.φ, ∆.
                                    Les autres cas découlent aisément de l’hypothèse de récurrence.                                      □
                                     INTRODUCTION À LA LOGIQUE                                  145


17.2.4. Axiome étendu. Nous sommes maintenant en mesure de démontrer l’admissibilité de la
règle d’axiome étendu (ax′ ). Cet axiome étendu est usuellement employé à la place de (ax) –
qu’il subsume – dans les calculs des séquents de la littérature (David, NouR et Raffalli, 2003 ;
Goubault-LaRRecq et MacKie, 1997).
Lemme 17.9 (axiome étendu). Pour tout multi-ensemble Γ et toute formule φ, 7−LK Γ, φ, φ.
Démonstration. On procède par récurrence sur p(φ).
   Cas de base ℓ : C’est immédiat par une application de l’axiome (ax).
   Cas de φ ∧ ψ : Alors φ ∧ ψ = φ ∨ ψ. Par hypothèse de récurrence, 7−LK Γ, φ, φ par une
     dérivation π1 et 7−LK Γ, ψ, ψ par une dérivation π2 . On a donc la dérivation
                                         π1                     π2
                                          ..                     ..
                                           .                      .
                                     7− Γ, φ, φ             7− Γ, ψ, ψ
                                                   (W)                           (W)
                                   7− Γ, φ, φ, ψ           7− Γ, ψ, ψ, φ
                                                                                 (∧)
                                             7− Γ, φ ∧ ψ, φ, ψ
                                                                  (∨)
                                            7− Γ, φ ∧ ψ, φ ∨ ψ
   Cas de φ ∨ ψ : Similaire au cas précédent.
   Cas de ∀x.φ : Alors ∀x.φ = ∃x.φ. Par hypothèse de récurrence et la propriété 14.4, on a
     7−LK Γ, φ[y/x], φ[y/x] pour y 6∈ fv(Γ, ∀x.φ) par une dérivation π. On a donc la dérivation
                                                    π.
                                                     ..
                                          7− Γ, φ[y/x], φ[y/x]
                                                                        (W)
                                       7− Γ, φ[y/x], φ[y/x], ∃x.φ
                                                                        (∃)
                                           7− Γ, φ[y/x], ∃x.φ
                                                               (∀)
                                            7− Γ, ∀x.φ, ∃x.φ
   Cas de ∃x.φ : Similaire au cas précédent.                                                     □

  Exemple 17.10. Reprenons la dérivation de l’exemple 17.4. Celle-ci devient très simple quand
  on utilise la règle (ax′ ) puisque φ1 (x) = φ2 (x).
                                                                              (ax′ )
                              7− ∃x.φ1 (x), φ1 (x), φ2 (x), ∃x.φ2 (x)
                                                                              (∃)
                                  7− ∃x.φ1 (x), φ1 (x), ∃x.φ2 (x)
                                                                    (∃)
                                      7− ∃x.φ1 (x), ∃x.φ2 (x)
                                                                   (∨)
                                   7− (∃x.φ1 (x)) ∨ (∃x.φ2 (x))

17.2.5. Inversibilité syntaxique. Une règle de déduction est syntaxiquement inversible si, quand il
existe une dérivation (que l’on supposera sans coupure grâce au théorème 17.19 d’élimination
des coupures) de son séquent conclusion, alors il existe une dérivation sans coupure de chacun
de ses séquents prémisses. La règle (ax) est bien sûr inversible, mais ce qui est plus intéressant,
c’est que toutes les autres règles sauf (cut) le sont aussi. Cela signifie que dans une recherche
de preuve sans coupure, on peut appliquer ces règles de manière « gloutonne » sans faire de
backtrack – donc sans avoir à mémoriser de points de choix – et que si l’on arrive à un séquent
pour lequel aucune règle ne s’applique, alors c’est qu’il n’y a pas de preuve. Cela démontre aussi
l’admissibilité des règles d’élimination (E∨ ), (E1∧ ), (E2∧ ), (E∀ ) et (E∃ ) de la figure 40.
Lemme 17.11 (inversibilité syntaxique). Les règles du calcul des séquents sauf (cut) sont syntaxi-
quement inversibles.
                                             146                                     INTRODUCTION À LA LOGIQUE


                                             Démonstration. On ne traite ici que les règles (∃) et (∀), les autres étant traitées dans la démons-
                                             tration du lemme 8.8 d’inversibilité syntaxique du calcul des séquents propositionnel.
                                                   Pour la règle (∃) : s’il y a une preuve sans coupure de 7− Γ, ∃x.φ, alors par affaiblissement
                                                     il en existe aussi une de 7− Γ, ∃x.φ, φ[t/x].
                                                   Pour la règle (∀) : soit π une dérivation sans coupure du séquent 7− Γ, ∀x.φ. On montre par
                                                     récurrence sur la profondeur de π que pour toute variable y 6∈ fv(Γ, ∀x.φ), 7−LK Γ, φ[y/x].
                                                     — Si π se termine par (∀) où ∀x.φ est principale, alors évidemment il existe une sous-
                                                         dérivation de π de la prémisse 7− Γ, φ[z/x] pour une certaine variable z 6∈ fv(Γ, ∀x.φ).
                                                         Par le lemme 17.7 de substitution syntaxique, il existe aussi une dérivation du séquent
                                                        7− Γ[y/z], φ[z/x][y/z] pour tout y 6∈ fv(Γ, ∀x.φ), et comme z 6∈ fv(Γ, ∀x.φ), par les
                                                        équations (26) et (27) ce dernier séquent est α-congruent à 7− Γ, φ[y/x] et est dérivable
                                                         par le lemme d’α-congruence syntaxique.
                                                     — Si π se termine par (∀) où ∀x.φ n’est pas principale, alors Γ = Γ′ , ∀z.ψ et on a la
                                                         dérivation
                                                                                                         π. ′
                                                                                                          ..
                                                                                               7− Γ′ , ψ[v/z], ∀x.φ
                                                                                                                      (∀)
                                                                                                7− Γ′ , ∀z.ψ, ∀x.φ
                                                         où v 6∈ fv(Γ′ , ∀z.ψ, ∀x.φ).
                                                        On prend une variable fraîche w 6∈ fv(Γ′ , ψ[v/z], ∀x.φ) ; par hypothèse de récurrence
                                                        appliquée à π ′ , il existe une dérivation de 7− Γ′ , ψ[v/z], φ[w/x].
                                                        Comme v 6∈ fv(Γ′ , ∀z.ψ, φ[w/x]), on peut appliquer (∀) avec ∀z.ψ comme formule
                                                         principale pour obtenir 7− Γ′ , ∀z.ψ, φ[w/x].
                                                         Par le lemme de substitution syntaxique, pour toute variable y 6∈ fv(Γ′ , ∀z.ψ, ∀x.φ) on
                                                         a donc aussi une dérivation du séquent 7− Γ′ [y/w], (∀z.ψ)[y/w], φ[w/x][y/w]. Comme
                                                         w 6∈ fv(Γ′ , ψ[v/z], ∀x.φ), w 6∈ fv(Γ′ , ∀z.ψ, ∀x.φ) et donc par les équations (26) et (27)
                                                         ce dernier séquent est α-congruent à 7− Γ′ , ∀z.ψ, φ[y/x] et est dérivable par le lemme
                                                         d’α-congruence syntaxique.
                                                     — Sinon π se termine par une règle (R) autre que (∀) où ∀x.φ n’est pas principale. Par
                                                         inspection des règles, on est nécessairement dans une situation
                                                                                         π1                             πk
                                                                                           ..                             ..
                                                                                            .                              .
                                                                                     7− Γ1 , ∀x.φ        ···      7− Γk , ∀x.φ
                                                                                                                               (R)
                                                                                                     7− Γ, ∀x.φ
                                                         où 0 ≤ k ≤ 2 (k = 0 correspondant au cas de la règle (ax)). Pour tout y 6∈ fv(Γ, ∀x.φ)
                                                         et tout 1 ≤ i ≤ k, par hypothèse de récurrence sur πi , il existe une dérivation sans
                                                         coupure πi′ de 7− Γi , φ[y/x]. On a donc la dérivation
                                                                                      π1′                            πk′
                                                                                        ..                             ..
                                                                                         .                              .
                                                                                 7 Γ1 , φ[y/x]
                                                                                  −                  ···        7 Γk , φ[y/x]
                                                                                                                 −
                                                                                                                                (R)
                                                                                                 7− Γ, φ[y/x]
                                                                                                                                                  □

 L’intérêt de définir le calcul des         17.2.6. Contraction. L’admissibilité de la règle (C) est un peu plus délicate à démontrer, et nous
séquents sans la règle de contraction est
bien sûr de diminuer le nombre de
                                             allons utiliser une stratégie de démonstration similaire à celle de l’élimination des coupures. Le
règles. Mais cela simplifie aussi la         lemme suivant, combiné au théorème 17.19, montre son admissibilité.
preuve de l’élimination des coupures, qui
nécessite sinon l’ajout d’une règle (mix).   Lemme 17.12 (contraction). Si 7−LK Γ, φ, φ par une dérivation sans coupure, alors 7−LK Γ, φ par
                                             une dérivation sans coupure.
                                      INTRODUCTION À LA LOGIQUE                                      147


Démonstration. Le rang de contraction d’une dérivation π d’un séquent 7− Γ, φ, φ est le couple
(p(φ), p(π)) dans N2 . On ordonne les rangs de contraction par l’ordre lexicographique <lex sur
N2 ; il s’agit d’un ordre bien fondé.
   On procède par induction bien fondée sur le rang de contraction de la dérivation sans coupure
π de 7− Γ, φ, φ. Si φ n’est pas principale dans la dernière règle (R) appliquée dans π, alors par
inspection des règles, cette dérivation π est nécessairement de la forme
                                    π1                            πk
                                     ..                            ..
                                      .                             .
                                7− Γ1 , φ, φ        ···       7− Γk , φ, φ
                                                                                 (R)
                                                 7− Γ, φ, φ
où 0 ≤ k ≤ 2 (k = 0 correspondant à une règle (ax)). Comme (p(φ), p(πi )) <lex (p(φ), p(π))
pour tout 1 ≤ i ≤ k, on peut appliquer l’hypothèse d’induction à chaque πi pour obtenir des
dérivations πi′ de 7− Γi , φ. Encore par inspection des règles, on obtient une nouvelle dérivation

                                      π1′                        πk′
                                       ..                         ..
                                        .                          .
                                   7− Γ1 , φ        ···       7− Γk , φ
                                                                           (R)
                                                  7− Γ, φ

   Sinon, si φ est principale dans la dernière règle appliquée dans π, on fait une distinction de
cas selon cette règle.
   Cas de (ax) : alors φ = ℓ et Γ = Γ′ , ℓ, et on a aussi une dérivation de 7− Γ′ , ℓ, ℓ par (ax).
   Cas de (∨) : alors φ = φ′ ∨ ψ et π est de la forme
                                                     π1
                                                       ..
                                                        .
                                            7− Γ, φ′ , ψ, φ′ ∨ ψ
                                                                     (∨)
                                           7− Γ, φ′ ∨ ψ, φ′ ∨ ψ
      Par le lemme 17.11 d’inversibilité syntaxique appliqué à π1 , on a aussi une dérivation π1′ de
      7− Γ, φ′ , ψ, φ′ , ψ. Comme (p(φ′ ), p(π1′ )) <lex (p(φ′ ∨ψ), p(π)), par hypothèse d’induction,
      on a une dérivation π1′′ de 7− Γ, φ′ , ψ, ψ. Comme (p(ψ), p(π1′′ )) <lex (p(φ′ ∨ ψ), p(π)), par
      hypothèse d’induction, on a une dérivation de 7− Γ, φ′ , ψ. Par une application de (∨), on
      obtient alors une dérivation de 7− Γ, φ′ ∨ ψ.
   Cas de (∧) : alors φ = φ′ ∧ ψ et π est de la forme
                                           π1                      π2
                                            ..                      ..
                                             .                       .
                                    7− Γ, φ′ , φ′ ∧ ψ       7− Γ, ψ, φ′ ∧ ψ
                                                                            (∧)
                                              7− Γ, φ′ ∧ ψ, φ′ ∧ ψ
      Par le lemme 17.11 d’inversibilité syntaxique appliqué à π1 et π2 , on a aussi une déri-
      vation π1′ de 7− Γ, φ′ , φ′ et une dérivation π2′ de 7− Γ, ψ, ψ. Comme (p(φ′ ), p(π1′ )) <lex
      (p(φ′ ∧ ψ), p(π)) et (p(ψ), p(π2′ )) <lex (p(φ′ ∧ ψ), p(π)), par hypothèse d’induction, on a
      des dérivations de 7− Γ, φ′ et de 7− Γ, ψ. Par une application de (∧), on obtient alors une
      dérivation de 7− Γ, φ′ ∧ ψ.
   Cas de (∀) : alors φ = ∀x.ψ et π est de la forme
                                                       π1
                                                        ..
                                                         .
                                               7− Γ, ψ[y/x], ∀x.ψ
                                                                    (∀)
                                                7− Γ, ∀x.ψ, ∀x.ψ
                                            148                                     INTRODUCTION À LA LOGIQUE


                                                    où y 6∈ fv(Γ, ∀x.ψ). Par le lemme 17.11 d’inversibilité syntaxique appliqué à π1 , on a aussi
                                                    une dérivation π1′ de 7− Γ, ψ[y/x], ψ[z/x] où z 6∈ {y} ∪ fv(Γ, ∀x.ψ). Par le lemme 17.7,
                                                    on a aussi une dérivation π1′′ de 7− Γ[y/z], ψ[y/x][y/z], ψ[z/x][y/z]. Comme z 6∈ {y} ∪
                                                    fv(Γ, ∀x.ψ), par les équations (26) et (27), ce dernier séquent est α-congruent au séquent 7−
                                                    Γ, ψ[y/x], ψ[y/x] et donc dérivable par le lemme 17.6 d’α-congruence syntaxique. Comme
                                                    (p(ψ[y/x]), p(π1′′ )) <lex (p(∀x.ψ), p(π)), par hypothèse d’induction on obtient une déri-
                                                    vation de 7− Γ, ψ[y/x]. Comme y 6∈ fv(Γ, ∀x.ψ), on peut appliquer (∀) et on obtient une
                                                    dérivation de 7− Γ, ∀x.ψ.
                                                  Cas de (∃) : alors φ = ∃x.ψ et π est de la forme
                                                                                                   π1
                                                                                                    ..
                                                                                                     .
                                                                                      7− Γ, ψ[t/x], ∃x.ψ, ∃x.ψ
                                                                                                                  (∀)
                                                                                           7− Γ, ∃x.ψ, ∃x.ψ
                                                    où t ∈ T (F, X). Comme (p(∃x.ψ), p(π1 )) <lex (p(∃x.ψ), p(π)), par hypothèse d’induc-
                                                    tion sur π1 on obtient une dérivation de 7− Γ, ψ[t/x], ∃x.ψ à laquelle on applique (∃) pour
                                                    obtenir 7− Γ, ∃x.ψ.                                                                         □

 La première démonstration de la           17.3. * Complétude. La complétude des systèmes de preuves en logique du premier ordre, c’est-
complétude d’un système de preuve pour
la logique du premier ordre est le
                                            à-dire que toute formule valide est dérivable dans le système de preuve en question, se montre
théorème de complétude de GÖdel, qui        par contraposée : un séquent 7− Γ non prouvable n’est pas valide, ce qui par définition signifie
démontre la complétude d’un système de      qu’il a un contre-modèle, c’est-à-dire une interprétation I et une valuation ρ telles que I, ρ 6Z= φ
preuve à la HilbeRt.
                                            pour toute formule φ ∈ dom(Γ).
 C.f. (Ebbinghaus, Flum et Thomas,            Ce contre-modèle est habituellement obtenu par la « construction de HenKin ». La construc-
1994, ch. V) pour la construction de        tion présentée ici en est une variante, qui repose plutôt sur les travaux de HintiKKa sur les
HenKin pour le calcul des séquents, et      tableaux en logique du premier ordre. Nous la voyons ici dans le cas du calcul des séquents mo-
(David, NouR et Raffalli, 2003, ch. 2) et
(Lassaigne et Rougemont, 2004,              nolatère de la figure 39, mais l’approche se généralise aisément à d’autres systèmes de preuve.
sec. 4.3) dans le cadre de la déduction     17.3.1. Lemme de HintiKKa. Le principe de la construction est de considérer des ensembles de
naturelle.
 C.f. (Fitting, 1996, sec. 3.5 et 5.6)
                                            formules suffisamment « saturés ». Comme l’objectif est de construire un contre-modèle plutôt
pour la construction de HintiKKa            qu’un modèle, la définition qui suit est duale de la définition usuelle pour les tableaux.
                                            Définition 17.13 (ensemble de HintiKKa). Un ensemble E de formules en forme normale né-
                                            gative est dualement saturé si
                                              (1) si E contient φ ∨ ψ, alors E contient φ et ψ,
                                              (2) si E contient φ ∧ ψ, alors E contient φ ou ψ,
                                              (3) si E contient ∃x.φ, alors E contient φ[t/x] pour tout terme t ∈ T (F, X), et
                                              (4) si E contient ∀x.φ, alors E contient φ[y/x] pour une variable y.
                                            Un ensemble est cohérent s’il ne contient pas une formule atomique α et sa négation ¬α. Un
                                            ensemble de HintiKKa est un ensemble dualement saturé cohérent.
                                            Lemme 17.14 (HintiKKa). Si H est un ensemble de HintiKKa, alors il existe une interprétation I
                                            et une valuation ρ telles que, pour toute formule φ ∈ H, I, ρ 6Z= φ.
 On peut remarquer que ce modèle est       Démonstration. L’interprétation I a pour domaine T (F ∪ X) l’ensemble des termes clos sur
presque une structure de HeRbRand
(voir section 14.5), si ce n’est que son
                                            l’alphabet F ∪ X, où les variables de X sont considérées comme des constantes d’arité zéro.
domaine est T (F ∪ X) et non T (F ).        L’interprétation d’un symbole de fonction f ∈ Fm est f I (t1 , . . . , tm ) def
                                                                                                                        = f (t1 , . . . , tm ). L’inter-
                                            prétation d’un symbole de relation R ∈ Pm est RI def= {(t1 , . . . , tm ) | ¬R(t1 , . . . , tm ) ∈ H}.
                                            La valuation ρ est l’identité sur X.
                                                On vérifie aisément que pour tout terme t ∈ T (F, X), JtKIρ = t. Cela implique que pour une
                                            substitution [t/x] où t est vu comme un terme de T (F, X), la valuation [t/x]ρ n’est autre que
                                            ρ[t/x] où t est vu comme un élément du domaine DI .
                                         INTRODUCTION À LA LOGIQUE                                             149


  Montrons par induction structurelle sur φ ∈ H que I, ρ 6Z= φ.
  — Pour un littéral positif R(t1 , . . . , tm ) ∈ H, comme H est cohérent, ¬R(t1 , . . . , tm ) 6∈ H
    et donc (Jt1 KIρ , . . . , Jtm KIρ ) = (t1 , . . . , tm ) 6∈ RI : on a bien I, ρ 6Z= R(t1 , . . . , tm ).
  — Pour un littéral négatif ¬R(t1 , . . . , tm ) ∈ H, (Jt1 KIρ , . . . , Jtm KIρ ) = (t1 , . . . , tm ) ∈ RI : on
    a bien I, ρ 6Z= ¬R(t1 , . . . , tm ).
  (1) Pour une formule φ ∨ ψ ∈ H, comme H est dualement saturé il contient φ et ψ, donc par
      hypothèse d’induction I, ρ 6Z= φ et I, ρ 6Z= ψ : on a bien I, ρ 6Z= φ ∨ ψ.
  (2) Pour une formule φ ∧ ψ ∈ H, comme H est dualement saturé il contient φ ou ψ, donc par
      hypothèse d’induction I, ρ 6Z= φ ou I, ρ 6Z= ψ : on a bien I, ρ 6Z= φ ∧ ψ.
  (3) Pour une formule ∃x.φ ∈ H, comme H est dualement saturé il contient φ[t/x] pour
      tout terme t, donc par hypothèse d’induction I, ρ 6Z= φ[t/x] pour tout terme t et par le
      lemme 13.5, I, ρ[t/x] 6Z= φ pour tout t ∈ DI : on a bien I, ρ 6Z= ∃x.φ.
  (4) Pour une formule ∀x.φ ∈ H, comme H est dualement saturé il contient φ[y/x] pour une
      variable y, donc par hypothèse d’induction I, ρ 6Z= φ[y/x] et par le lemme 13.5, I, ρ[y/x] 6Z=
      φ où y ∈ DI : on a bien I, ρ 6Z= ∀x.φ.                                                       □
17.3.2. Théorème de complétude. Un ensemble E de formules en forme normale négative est prou-
vable s’il existe un multi-ensemble fini Γ avec dom(Γ) ⊆ E tel que 7−LK Γ par une dérivation
sans coupure, et non prouvable sinon.
Lemme 17.15 (propagation). Soit E un ensemble non prouvable :                                                         Le lemme de propagation est une
                                                                                                                     forme d’inversibilité sémantique du
  (1) si E contient φ ∨ ψ, alors E ∪ {φ, ψ} est non prouvable,                                                       calcul des séquents du premier ordre au
  (2) si E contient φ ∧ ψ, alors E ∪ {φ} est non prouvable ou E ∪ {ψ} est non prouvable,                             sens du lemme 8.12.

  (3) si E contient ∃x.φ, alors E ∪ {φ[t/x]} est non prouvable pour tout terme t ∈ T (F, X), et
  (4) si E contient ∀x.φ, alors E ∪ {φ[y/x]} est non prouvable pour toute variable y 6∈ fv(E).
Démonstration. On procède dans chaque cas par l’absurde.
  (1) Si E ∪ {φ, ψ} est prouvable mais E n’est pas prouvable, alors nécessairement {φ, ψ} 6⊆
      E et cette dérivation doit faire intervenir φ ou ψ. Sans perte de généralité, supposons
      7−LK Γ, φm , ψ n pour un multi-ensemble fini Γ avec dom(Γ) ⊆ E et m + n > 0. Par
       affaiblissement, on a aussi 7−LK Γ, φmax(m,n) , ψ max(m,n) . Par max(m, n) applications de (∨),
      on a donc 7−LK Γ, (φ ∨ ψ)max(m,n) et E prouvable, contradiction.
  (2) Si E ∪ {φ} et E ∪ {ψ} sont tous les deux prouvables mais E n’est pas prouvable, alors
      nécessairement φ 6∈ E et ψ 6∈ E et ces dérivations doivent faire intervenir φ et ψ : 7−LK
      Γ, φm et 7−LK ∆, ψ n pour des multi-ensemble finis Γ et ∆ avec dom(Γ) ∪ dom(∆) ⊆ E et
      m, n > 0. Par affaiblissement et contraction, on a aussi 7−LK Γ, ∆, φ et 7−LK Γ, ∆, ψ. Par
      une application de (∧), on a donc 7−LK Γ, ∆, φ ∧ ψ et E prouvable, contradiction.
  (3) Si E ∪{φ[t/x]} est prouvable pour un terme t mais E n’est pas prouvable, alors φ[t/x] 6∈ E
      et on a 7−LK Γ, (φ[t/x])m pour un multi-ensemble fini Γ avec dom(Γ) ⊆ E et m > 0. Par
      affaiblissement, 7−LK Γ, (φ[t/x])m , (∃x.φ)m . Par m applications de (∃), on a donc 7−LK
      Γ, (∃x.φ)m et E prouvable, contradiction.
  (4) Si E ∪ {φ[y/x]} est prouvable pour une variable y 6∈ fv(E), alors φ[y/x] 6∈ E et 7−LK
      Γ, (φ[y/x])m pour un multi-ensemble fini Γ avec dom(Γ) ⊆ E et m > 0. Par contraction,                           Le cas (4) est le seul où l’admissibilité
                                                                                                                     de la contraction soit vraiment utile.
      on a aussi 7−LK Γ, φ[y/x], et comme dom(Γ) ⊆ E et ∀x.φ ∈ E, y 6∈ fv(Γ, ∀x.φ), donc on
      peut appliquer (∀) pour dériver 7−LK Γ, ∀x.φ : E est prouvable, contradiction.      □
  Le cœur de la preuve du théorème de complétude est le lemme suivant :
Lemme 17.16 (saturation). Tout ensemble fini non prouvable est inclus dans un ensemble de HintiKKa.
                                           150                                   INTRODUCTION À LA LOGIQUE


 La preuve du lemme de saturation         Démonstration. Appelons une tâche une formule qui n’est pas de la forme ∃x.φ ou une paire
correspond intuitivement à la
construction d’une branche infinie d’une
                                           (∃x.φ, t) où t ∈ T (F, X). Comme il n’y a qu’un nombre dénombrable de formules φ et de termes
recherche de preuve pour un séquent non    t ∈ T (F, X), il y a un nombre dénombrable de tâches. Fixons une énumération θ0 , θ1 , . . . de
prouvable.                                 toutes les tâches, telle que chaque tâche apparaisse infiniment souvent.
                                               Soit E0 un ensemble fini non prouvable. On construit une séquence croissante d’ensembles
                                           finis non prouvables E0 ⊆ E1 ⊆ · · · . Étant donné En , on construit En+1 en utilisant θn la nième
                                           tâche.
                                              (1) Si θn = φ ∨ ψ : si φ ∨ ψ ∈ En , alors par le lemme 17.15.(1), En+1 def
                                                                                                                      = En ∪ {φ, ψ} est non
                                                  prouvable ; sinon on pose En+1 def= En .
                                              (2) Si θn = φ ∧ ψ : si φ ∧ ψ ∈ En , alors par le lemme 17.15.(2), En ∪ {φ} ou En ∪ {ψ} est non
                                                  prouvable et on pose En+1 def                                          def
                                                                              = En ∪ {φ} dans le premier cas et En+1 = En ∪ {ψ} dans le
                                                                                def
                                                  second ; sinon on pose En+1 = En .
                                             (3) Si θn = (∃x.φ, t) : si ∃x.φ ∈ En , alors par le lemme 17.15.(3), En+1 def
                                                                                                                        = En ∪ {φ[t/x]} est
                                                                                        def
                                                 non prouvable ; sinon on pose En+1 = En .
 La restriction à un ensemble initial       (4) Si θn = ∀x.φ : si ∀x.φ ∈ En , alors il existe y 6∈ fv(En ) puisque ce dernier est fini, et par
fini est importante pour ce cas (4).
                                                 le lemme 17.15.(4) En+1 def
                                                                           = En ∪ {φ[y/x]} est non prouvable ; sinon on pose En+1 = En .
                                                                                                                                        def

                                                                 S
                                              Définissons H def
                                                              = n∈N En . Il reste à montrer que H est dualement saturé et cohérent. Com-
                                           mençons par vérifier qu’il est dualement saturé :
                                             (1) Si H contient φ ∨ ψ, alors il existe m ∈ N tel que φ ∨ ψ ∈ Em et n > m tel que θn = φ ∨ ψ,
                                                 donc En+1 et donc H contiennent φ et ψ.
                                             (2) Si H contient φ ∧ ψ, alors il existe m ∈ N tel que φ ∧ ψ ∈ Em et n > m tel que θn = φ ∧ ψ,
                                                 donc En+1 et donc H contiennent φ ou ψ.
                                             (3) Si H contient ∃x.φ et t ∈ T (F, X), alors il existe m ∈ N tel que ∃x.φ ∈ Em et n > m tel
                                                 que θn = (∃x.φ, t), donc En+1 et donc H contiennent φ[t/x].
                                             (4) Si H contient ∀x.φ, alors il existe m ∈ N tel que ∀x.φ ∈ Em et n > m tel que θn = ∀x.φ,
                                                 donc il existe y ∈ X telle que En+1 et donc H contiennent φ[y/x].
                                           L’ensemble H est de plus cohérent : si α et ¬α appartenaient à H, alors il existerait n ∈ N tel
                                           que {α, ¬α} ⊆ En , mais alors En serait prouvable par une application de la règle d’axiome. □
                                           Théorème 17.17 (complétude). Si Z= Γ, alors 7−LK Γ par une dérivation sans coupure.
                                             Démonstration. Par contraposée, supposons que le séquent 7− Γ ne soit pas dérivable sans cou-
                                             pure. Alors l’ensemble dom(Γ) n’est pas prouvable : si ∆ est un multi-ensemble fini tel que
                                             dom(∆) ⊆ dom(Γ), alors 7− ∆ n’est pas dérivable sans coupure, sans quoi on pourrait aussi
                                             dériver 7− Γ par affaiblissement et contraction.
                                                Par le lemme 17.16 de saturation, dom(Γ) est inclus dans H un ensemble de HintiKKa. Par le
                                             lemme 17.14 de HintiKKa, il existe une interprétation I et une valuation ρ telles que, pour toute
                                             formule φ de H (et donc en particulier pour toute formule φ de dom(Γ)), I, ρ 6Z= φ : on a bien
                                           6Z= Γ.                                                                                           □

 (David, NouR et Raffalli, 2003,          17.4. * Élimination des coupures. Les théorèmes 17.5 et 17.17 montrent que la règle de cou-
sec. 5.4). Le théorème d’élimination des
coupures est originellement dû à
                                           pure est inutile dans le calcul des séquents : si 7−LK Γ en utilisant (cut), alors Z= Γ par le théorème
Gentzen.                                   de correction, et donc 7−LK Γ par une dérivation sans coupure par le théorème de complétude.
                                              On peut cependant faire une preuve directe de ce résultat, sans faireappel à des notions séman-
                                           tiques. La stratégie générale est de réécrire les dérivations du calcul des séquents avec coupure
                                           en des dérivations sans coupure, en faisant « remonter » les instances de (cut) vers les axiomes.
                                           L’intérêt de cette preuve syntaxique est qu’étant donné une preuve avec coupure, elle construit
                                           une preuve sans coupure. La difficulté principale est de montrer que ce processus termine.
                                              Une coupure maximale est une dérivation π finissant par une règle (cut) de la forme
                                     INTRODUCTION À LA LOGIQUE                                    151

                                          π1            π2
                                           ..            ..
                                            .             .
                                        7− Γ, φ      7− φ, ∆
                                                               (cut)
                                               7− Γ, ∆
où π1 et π2 sont sans coupure. Son rang de coupure est r(π) def
                                                            = (p(φ), p(π1 )+p(π2 )). On ordonne
les rangs de coupure dans N2 lexicographiquement ; il s’agit d’un ordre bien fondé.
Lemme 17.18. Soit π une coupure maximale. Alors il existe une dérivation π ′ sans coupure du
même séquent.
Démonstration. On procède par induction bien fondée sur r(π). Rappelons qu’une telle dériva-
tion π est de la forme
                                      π1           π2
                                       ..           ..
                                        .            .
                                   7− Γ, φ      7− φ, ∆
                                                        (cut)
                                          7− Γ, ∆
où π1 et π2 sont sans coupure.
   On procède à une première analyse par cas, selon que φ soit principale dans la dernière règle
de π1 ou φ dans la dernière règle de π2 .
   cas « np1 » : si φ n’est pas principale dans la dernière règle (R) de π1 . Alors π1 était de la
      forme
                                            π1′                       πk′
                                               ..                      ..
                                                .                       .
                                         7− Γ1 , φ          ···   7− Γk , φ
                                                                                (R)
                                                         7− Γ, φ
      pour un certain 0 ≤ k ≤ 2, où k = 0 correspond au cas de la règle (ax). Par inspection
      des règles (R) du calcul des séquents, comme φ n’est pas principale, elle apparaît en effet
      dans toutes les prémisses de (R). Encore par inspection des règles, on observe que l’on peut
      transformer π en
                           π1′             π2                             πk′            π2
                            ..              ..                             ..             ..
                             .               .                              .              .
                        7− Γ1 , φ       7− φ, ∆                      7− Γk , φ        7− φ, ∆
                                                   (cut)                                      (cut)
                                7− Γ1 , ∆                     ···             7− Γk , ∆
                                                                                         (R)
                                                          7− Γ, ∆
      Les k nouvelles instances de (cut) entre πi′ et π2 sont maximales et de rangs respectifs
      (p(φ), p(πi′ ) + p(π2 )) pour 1 ≤ i ≤ k, où p(πi′ ) < p(π1 ). On peut donc appliquer l’hypo-
      thèse d’induction pour obtenir des dérivations sans coupure de chaque 7− Γi , ∆. La déri-
      vation résultante de 7− Γ, ∆ est sans coupure.
   cas « np2 » : si φ n’est pas principale dans la dernière règle de π2 . Similaire au cas précédent.
   On peut donc supposer maintenant que φ est principale dans la dernière règle de π1 et φ dans
la dernière de π2 . Nous faisons une nouvelle distinction de cas selon que ces dernières règles
soient (ax) ou non.
   cas « ax1 » : si φ est principale dans π1 finissant par (ax). Alors φ = ℓ, Γ = Γ′ , ℓ et π était
      de la forme
                                                           π2
                                                             ..
                                                   (ax)
                                                              .
                                           ′
                                       7− Γ , ℓ, ℓ       7− ℓ, ∆
                                                                       (cut)
                                               7− Γ′ , ℓ, ∆
152                                      INTRODUCTION À LA LOGIQUE


         Par le lemme 17.8, on aurait pu obtenir le même résultat par affaiblissement de π2 . On
         obtient alors directement une preuve sans coupure de 7− Γ, ∆.
      cas « ax2 » : si φ est principale dans π2 finissant par (ax). Similaire au cas précédent.
   Il reste maintenant le cas où π1 et π2 ont pour dernières règles (∨) et (∧), ou (∃) et (∀) : ce sont
les seules paires possibles puisque φ et φ sont principales et que (ax) a déjà été traité.
      cas « ∨∧ » : φ = φ′ ∨ ψ est principale dans la dernière règle (∨) de π1 et φ = φ′ ∧ ψ dans
         la dernière règle (∧) de π2 . La dérivation π est donc de la forme

                                         π1′                 π2′             π3′
                                          ..                  ..              ..
                                           .                   .               .
                                     7− Γ, φ′ , ψ         7− φ′ , ∆       7− ψ, ∆
                                                    (∨)                                   (∧)
                                    7− Γ, φ′ ∨ ψ               7− φ′ ∧ ψ, ∆
                                                                                 (cut)
                                                     7− Γ, ∆
         On transforme cette dérivation en
                                        π1′              π2′
                                         ..               ..
                                          .                .                π3′
                                                                             ..
                                    7− Γ, φ′ , ψ     7− φ′ , ∆                .
                                                               (cut)
                                            7− Γ, ψ, ∆                   7− ψ, ∆
                                                                                         (cut)
                                                        7− Γ, ∆, ∆
         La coupure entre π1′ et π2′ est maximale et de rang (p(φ′ ), p(π1′ ) + p(π2′ )) où p(φ′ ) < p(φ) ;
         on peut donc appliquer l’hypothèse d’induction pour obtenir une dérivation π ′ sans cou-
         pure de 7− Γ, ψ, ∆. La dérivation résultante est maintenant

                                                 π. ′             π3′
                                                                   ..
                                                  ..                .
                                             7− Γ, ψ, ∆        7− ψ, ∆
                                                                         (cut)
                                                      7− Γ, ∆, ∆
          La coupure y est maximale et de rang (p(ψ), p(π ′ )+p(π3′ )) où p(ψ) < p(φ) ; on peut encore
          appliquer l’hypothèse d’induction pour obtenir une dérivation sans coupure de 7− Γ, ∆, ∆.
         Enfin, par le lemme 17.12 de contraction, puisque 7− Γ, ∆, ∆ est dérivable sans coupure,
         7− Γ, ∆ l’est aussi.
      cas « ∧∨ » : φ = ψ ∧ ψ ′ est principale dans la dernière règle (∧) de π1 et φ = ψ ∨ ψ ′ dans
         la dernière règle (∨) de π2 . Similaire au cas précédent.
      cas « ∃∀ » : φ = ∃x.ψ est principale dans la dernière règle (∃) de π1 et φ = ∀x.ψ dans la
         dernière règle (∀) de π2 . La dérivation π est donc de la forme

                                            π1′                      π2′
                                             ..                       ..
                                              .                        .
                                    7− Γ, ψ[t/x], ∃x.ψ        7 − (ψ)[y/x], ∆
                                                        (∃)                     (∀)
                                        7− Γ, ∃x.ψ               7 ∀x.ψ, ∆
                                                                  −
                                                                             (cut)
                                                      7− Γ, ∆
         où y 6∈ fv(∀x.ψ, ∆). Par le lemme 17.7, il existe une dérivation sans coupure π2′′ du séquent
         7− (ψ)[y/x][t/y], ∆[t/y]. Comme y 6∈ fv(∀x.ψ), par l’équation (27), (ψ)[y/x][t/y] =α
          (ψ)[t/x] et comme y 6∈ fv(∆), par l’équation (26), ∆[t/y] =α ∆. De plus, par la pro-
          priété 14.4, (ψ)[t/x] = (ψ[t/x]). On obtient donc une nouvelle dérivation par le lemme 17.6
          d’α-congruence syntaxique
                                     INTRODUCTION À LA LOGIQUE                                    153


                               π1′                   π2
                                                       ..
                                ..
                                 .                      .                   π2′′
                                                                             ..
                       7− Γ, ψ[t/x], ∃x.ψ        7− ∀x.ψ, ∆                   .
                                                              (cut)
                                   7− Γ, ψ[t/x], ∆                    7− (ψ[t/x]), ∆
                                                                                       (cut)
                                                      7− Γ, ∆, ∆
      La coupure entre π1′ et π2 est maximale et de rang (p(φ), p(π1′ )+p(π2 )) où p(π1′ ) < p(π1 ) ;
      on peut donc appliquer l’hypothèse d’induction pour obtenir une dérivation π ′ sans cou-
      pure de 7− Γ, ψ[t/x], ∆. La dérivation résultante est

                                          π. ′                π2′′
                                                               ..
                                           ..                   .
                                   7− Γ, ψ[t/x], ∆      7− (ψ[t/x]), ∆
                                                                         (cut)
                                               7− Γ, ∆, ∆
      La coupure y est maximale et de rang (p(ψ[t/x]), p(π ′ ) + p(π2′′ )) où p(ψ[t/x]) = p(ψ) <
      p(φ) ; on peut encore appliquer l’hypothèse d’induction pour obtenir une dérivation sans
      coupure de 7− Γ, ∆, ∆. Enfin, par le lemme 17.12 de contraction, 7− Γ, ∆ est dérivable sans
      coupure.
   cas « ∀∃ » : φ = ∀x.ψ est principale dans la dernière règle (∀) de π1 et φ = ∃x.ψ dans la
      dernière règle (∃) de π2 . Similaire au cas précédent.                              □
Théorème 17.19 (élimination des coupures). Soit π une dérivation du calcul des séquent. Alors il
existe une dérivation sans coupure du même séquent.
Démonstration. On procède par récurrence sur le nombre n d’instances de la règle (cut) dans
π. Pour le cas de base n = 0, π est déjà une dérivation sans coupure. Supposons donc n > 0.
Il existe donc une coupure maximale π ′ qui est une sous-dérivation de π. Par le lemme 17.18,
il existe une dérivation sans coupure équivalente à π ′ ; on remplace π ′ par celle-ci dans π pour
obtenir une dérivation équivalente à π avec n−1 instances de (cut). Par hypothèse de récurrence,
cette nouvelle dérivation a une dérivation sans coupure équivalente.                            □
   L’élimination des coupures est souvent combinée avec la propriété de sous-formule : pour une
formule φ en forme normale négative, son ensemble de sous-formules sub(φ) est défini inducti-
vement par
     sub(ℓ) def
            = {ℓ} ,
sub(φ ∨ ψ) def
           = {φ ∨ ψ} ∪ sub(φ) ∪ sub(ψ) ,              sub(φ ∧ ψ) def
                                                                 = {φ ∧ ψ} ∪ sub(φ) ∪ sub(ψ) ,
 sub(∃x.φ) def                                           def
           = {∃x.φ} ∪ {φ[t/x] | t ∈ T (F, X)}, sub(∀x.φ) = {∀x.φ} ∪ {φ[y/x] | y ∈ X} .
Propriété 17.20 (sous-formule). Dans toutes les règles du calcul des séquents sauf (cut), toutes les
formules apparaissant dans les prémisses sont des sous-formules de formules apparaissant dans la
conclusion.
154                                 INTRODUCTION À LA LOGIQUE


Références
Quelques ouvrages sur la logique.
Ben-ARi, Mordechai (2012). Mathematical Logic for Computer Science. 3e édition. Springer. doi :
   10.1007/978-1-4471-4129-7.
BÖRgeR, Egon, Erich GRÄdel et Yuri Sh. GuRevich (1997). The Classical Decision Problem. Pers-
   pectives in Mathematical Logic. Springer-Verlag.
Chang, Chen C. et Howard J. KeisleR (1990). Model Theory. 3e édition. Studies in Logic and the
   Foundations of Mathematics 73. North Holland. doi : 10.1016/S0049-237X(08)70077-6.
Chang, Chin-Liang et Richard Char-Tung Lee (1973). Symbolic Logic and Mechanical Theorem
   Proving. Computer Science and Applied Mathematics. Academic Press. doi : 10.1016/B978-
   0-08-091728-3.50001-1.
Conchon, Sylvain et Laurent Simon (2018). « Satisfaisabilité propositionnelle (SAT) et modulo
   théories (SMT) ». Dans : Informatique Mathématique. Une photographie en 2018. Sous la dir.
   d’Emmanuel Jeandel et Laurent VigneRon. CNRS Éditions. Chap. 2, pp. 43-86. uRl : https:
   //ejcim2018.sciencesconf.org/data/pages/ejcim2018-2.pdf.
CoRi, René et Daniel LascaR (2003). Logique mathématique. 2e édition. Volume II. Fonctions ré-
   cursives, théorème de GÖdel, théorie des ensembles, théorie des modèles. Dunod.
David, René, Karim NouR et Christophe Raffalli (2003). Introduction à la logique. 2e édition.
   Dunod.
DupaRc, Jacques (2015). La logique pas à pas. Presses polytechniques et universitaires romandes.
Ebbinghaus, Heinz-Dieter, Jörg Flum et Wolfgang Thomas (1994). Mathematical Logic. 2e édi-
   tion. Undergraduate Texts in Mathematics. Springer. doi : 10.1007/978-1-4757-2355-7.
Fitting, Melvin (1996). First-Order Logic and Automated Theorem Proving. 2e édition. Graduate
   Texts in Computer Science. Springer. doi : 10.1007/978-1-4612-2360-3.
Goubault-LaRRecq, Jean et Ian MacKie (1997). Proof Theory and Automated Deduction. Applied
   Logic Series 6. Kluwer Academic Publishers.
HaRRisson, John (2009). Handbook of Practical Logic and Automated Reasoning. Cambridge Uni-
   versity Press.
Knuth, Donald E. (2008). The Art of Computer Programming. Volume 4, fascicule 0 : Introduction
   to Combinatorial Algorithms and Boolean Functions. Addison-Wesley. uRl : https : / / cs .
   stanford.edu/~knuth/fasc0b.ps.gz.
          (2015). The Art of Computer Programming. Volume 4, fascicule 6 : Satisfiability. Addison-
   Wesley. uRl : https://cs.stanford.edu/~knuth/fasc6a.ps.gz.
Lassaigne, Richard et Michel de Rougemont (2004). Logic and Complexity. Discrete Mathematics
   and Theoretical Computer Science. Springer. doi : 10.1007/978-0-85729-392-3.
LibKin, Leonid (2004). Elements of Finite Model Theory. Texts in Theoretical Computer Science.
   Springer. doi : 10.1007/978-3-662-07003-1.
Quelques textes fondateurs.
BeRgeR, Robert (1966). The Undecidability of the Domino Problem. Memoirs of the American Ma-
  thematical Society 66. American Mathematical Society. doi : 10.1090/memo/0066.
ChuRch, Alonzo (1936a). « A note on the Entscheidungsproblem ». Dans : Journal of Symbolic
  Logic 1(1), pp. 40-41. doi : 10.2307/2269326. Correction en 1936 dans : Journal of Symbolic
  Logic 1(3), pp. 101–102. doi : 10.2307/2269030.
         (1936b). « An unsolvable problem of elementary number theory ». Dans : American
  Journal of Mathematics 58(2), pp. 345-363. doi : 10.2307/2371045.
CooK, Stephen A. (1971). « The complexity of theorem proving procedures ». Dans : Actes de
  STOC ’71. ACM, pp. 151-158. doi : 10.1145/800157.805047.
                                     INTRODUCTION À LA LOGIQUE                                    155


CooK, Stephen A. et Robert A. RecKhow (1979). « The relative efficiency of propositional proof
  systems ». Dans : Journal of Symbolic Logic 44(1), pp. 36-50. doi : 10.2307/2273702.
CRaig, William (1957). « Three uses of the Herbrand-Gentzen Theorem in relating model theory
  and proof theory ». Dans : Journal of Symbolic Logic 22(3), pp. 269-285. doi : 10 . 2307 /
  2963594.
Davis, Martin, George Logemann et Donald Loveland (1961). « A machine program for theorem
  proving ». Dans : Communications of the ACM 5(7), pp. 394-397. doi : 10.1145/368273.
  368557.
Davis, Martin et Hilary Putnam (1960). « A computing procedure for quantification theory ».
  Dans : Journal of the ACM 7(3), pp. 201-215. doi : 10.1145/321033.321034.
Gentzen, Gerhard (1935). « Untersuchungen über das logische Schließen. I ». Dans : Mathema-
  tische Zeitschrift 39, pp. 176-210. doi : 10.1007/BF01201353. Suivi par « Untersuchungen
  über das logische Schließen. II », pp. 405–431. doi : 10.1007/BF01201363.
GÖdel, Kurt (1929). « Über die Vollständigkeit des Logikkalküls ». Thèse de doctorat. Universität
  Wien.
         (1931). « Über formal unentscheidbare Sätze der Principia Mathematica und verwandter
  Systeme, I ». Dans : Monatshefte für Mathematik und Physik 38, pp. 173-198. doi : 10.1007/
  BF01700692.
HenKin, Leon (1949). « The completeness of the first-order functional calculus ». Dans : Journal
  of Symbolic Logic 14(3), pp. 159-166. doi : 10.2307/2267044.
HeRbRand, Jacques (1930). « Recherches sur la théorie de la démonstration ». Dans : Travaux de
  la société des Sciences et des Lettres de Varsovie. Classe III, Sciences Mathématiques et Physiques
  33.
HoRn, Alfred (1951). « On sentences which are true of direct unions of algebras ». Dans : Journal
  of Symbolic Logic 16(1), pp. 14-21. doi : 10.2307/2268661.
Levin, Leonid (1973). « Universal sequential search problems ». Dans : Problems of Information
  Transmission 9(3), pp. 115-116. uRl : http://mi.mathnet.ru/eng/ppi914.
Matiassevitch, Iouri V. (1970). « Les ensembles énumerables sont diophantiens ». Dans : Comptes
  rendus de l’Académie des sciences de l’URSS 191(2). En russe orginal : Матиясевич, Юрий
  В. (1970). « Диофантовость перечислимых множеств ». Dans : Доклады Академии наук
  СССР 191(2), pp. 279-282. uRl : http://mi.mathnet.ru/dan35274.
MostowsKi, Andrzej, Raphael M. Robinson et Alfred TaRsKi (1953). « Undecidability and Essen-
  tial Undecidability in Arithmetic ». Dans : Undecidable Theories. Sous la dir. d’Alfred TaRsKi.
  Studies in Logic and the Foundations of Mathematics 13. North-Holland. Chap. II, pp. 37-73.
  doi : 10.1016/S0049-237X(09)70293-9.
Robinson, J. Alan (1965). « A machine-oriented logic based on the resolution principle ». Dans :
  Journal of the ACM 12(1), pp. 23-41. doi : 10.1145/321250.321253.
RosseR, J. Barkley (1936). « Extensions of some theorems of Gödel and Church ». Dans : Journal
  of Symbolic Logic 1(3), pp. 87-91. doi : 10.2307/2269028.
SKolem, Thoralf (1934). « Über die Nicht-charakterisierbarkeit der Zahlenreihe mittels endlich
  oder abzählbar unendlich vieler Aussagen mit ausschliesslich Zahlenvariablen ». Dans : Fun-
  damenta Mathematicae 23, pp. 150-161. doi : 10.4064/fm-23-1-150-161.
Tseitin, Grigori S. (1966). « On the complexity of derivation in propositional calculus ». Dans :
  Actes du Séminaire de Leningrad sur la logique mathématique. uRl : http://www.decision-
  procedures.org/handouts/Tseitin70.pdf.
TuRing, Alan M. (1937). « On computable numbers, with an application to the Entscheidung-
  sproblem ». Dans : Proceedings of the London Mathematical Society. 2e sér. 42(1), pp. 230-265.
156                                 INTRODUCTION À LA LOGIQUE


      doi : 10.1112/plms/s2-42.1.230. Correction en 1938 dans : Proceedings of the London
      Mathematical Society 2e sér. 43(1), pp. 544–546. doi : 10.1112/plms/s2-43.6.544.
Autres ouvrages.
ARoRa, Sanjeev et Boaz BaRaK (2009). Computational Complexity: A Modern Approach. Cam-
   bridge University Press. doi : 10.1017/CBO9780511804090.
CaRton, Olivier (2008). Langages formels, calculabilité et complexité. Vuibert.
HaRRison, Michael A. (1978). Introduction to Formal Language Theory. Addison-Wesley.
KRoening, Daniel et Ofer StRichman (2016). Decision Procedures. An Algorithmic Point of View.
   2e édition. Texts in Theoretical Computer Science. Springer. doi : 10.1007/978- 3- 662-
   50497-0.
PapadimitRiou, Christos (1993). Computational Complexity. Addison-Wesley.
PeRifel, Sylvain (2014). Complexité algorithmique. Ellipses. uRl : https: // www .irif . fr/
   ~sperifel/complexite.pdf.
Sippu, Seppo et Eljas Soisalon-Soininen (1988). Parsing Theory. Volume I : Languages and Par-
   sing. Springer-Verlag.
Autres références.
BaRRett, Clark, Pascal Fontaine et Cesare Tinelli (2017). The SMT-LIB Standard: Version 2.6.
  Rapp. tech. Department of Computer Science, The University of Iowa. uRl : http://smtlib.
  cs.uiowa.edu/papers/smt-lib-reference-v2.6-r2017-07-18.pdf.
Dowling, William F. et Jean H. GallieR (1984). « Linear-time algorithms for testing the satisfia-
  bility of propositional Horn formulæ ». Dans : The Journal of Logic Programming 1(3), pp. 267-
  284. doi : 10.1016/0743-1066(84)90014-1.
Gold, E. Mark (1967). « Language identification in the limit ». Dans : Information and Control
  10(5), pp. 447-474. doi : 10.1016/S0019-9958(67)91165-5.
GoldbeRg, Evgueni et Yakov NoviKov (2003). « Verification of proofs of unsatisfiability for CNF
  formulas ». Dans : Actes de DATE ’03, pp. 886-891.
GuRevich, Yuri Sh. et I. O. KoRyaKov (1972). « Remarks on Berger’s paper on the domino pro-
  blem ». Dans : Siberian Mathematics Journal 13, pp. 319-321. doi : 10.1007/BF00971620.
Mancinelli, Fabio, Jaap BoendeR, Roberto Di Cosmo, Jérôme Vouillon, Berke DuRaK, Xa-
  vier LeRoy et Ralf TReinen (2006). « Managing the complexity of large free and open source
  package-based software distributions ». Dans : Actes de ASE ’06. IEEE, pp. 199-208. doi : 10.
  1109/ASE.2006.49. uRl : https://hal.archives-ouvertes.fr/hal-00149566/.
WetzleR, Nathan, Marijn J. H. Heule et Warren A. Hunt (2014). « DRAT-trim: Efficient checking
  and trimming using expressive clausal proofs ». Dans : Actes de SAT ’14. Lecture Notes in
  Computer Science 8561. Springer, pp. 422-429. doi : 10.1007/978-3-319-09284-3_31.
Zhang, Lintao, C.F. Madigan, M.H. MosKewicz et S. MaliK (2001). « Efficient conflict driven
  learning in a Boolean satisfiability solver ». Dans : Actes de ICCAD ’01, pp. 279-285. doi :
  10.1109/ICCAD.2001.968634.
